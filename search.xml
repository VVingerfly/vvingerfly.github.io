<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客网站]]></title>
    <url>%2F2019%2F02-18-Mis-HexoBlog%2F</url>
    <content type="text"><![CDATA[¶准备工作 首先下载nodejs,一路next安装即可。验证是否安装成功： 12node -v # 输出 v10.15.1npm -v # 输出 6.8.0 接下来更改npm的安装源，这能大大加快安装包的速度。 123npm get registry # 输出默认源 https://registry.npmjs.org/npm config set registry http://registry.npm.taobao.orgnpm get registry # 输出 http://registry.npm.taobao.org/，说明已更改为淘宝源 再运行npm install hexo-cli -g。 如果出现permission error，不要急着用sudo npm install hexo-cli -g，运行命令 sudo chown -R 'whoami' /usr/local/lib/node_modules，'whoami'即你的用户名，通过whoami命令查看。 然后再运行npm install hexo-cli -g。 验证是否安装成功，命令行输入node -v，输出hexo-cli等众多包即对应的版本则OK。 ¶创建本地博文服务 在本地新建你的博客文件夹如blog_hexo，进入该文件夹执行下列命令： 123hexo initnpm installhexo server 此时访问http://localhost:4000就能打开博文了，Ctrl+C关闭服务器。 ¶添加新页面 如要添加tags页面，首先运行下面命令 1hexo new page tags 这时会在sources/tags里面生成index.md的文件，打开这个文件编辑，添加type: tags，即 12345---title: tagsdate: 2016-11-11 21:40:58type: tags--- 最后再在主题配置文件中，在menu项下，把tags页打开。 1234menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags ¶emoji支持 Hexo默认是采用hexo-renderer-marked，这个渲染器不支持插件扩展，还有一个支持插件扩展的是 hexo-renderer-markdown-it，可以使用这个渲染引擎来支持emoji表情，具体实现过程如下： 首先进入blog跟目录，执行如下命令 12npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --save 再安装emoji插件，执行如下命令 1npm install markdown-it-emoji --save 最后再编辑站点配置文件，就是编辑根目录的_config.yml文件，添加如下内容 1234567891011121314151617181920212223# Markdown-it config## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wikimarkdown: render: html: true xhtmlOut: false breaks: true linkify: true typographer: true quotes: '“”‘’' plugins: - markdown-it-abbr - markdown-it-footnote - markdown-it-ins - markdown-it-sub - markdown-it-sup - markdown-it-emoji # add emoji anchors: level: 2 collisionSuffix: 'v' permalink: true permalinkClass: header-anchor permalinkSymbol: ¶ ¶关联github 首先在GitHub中新建username.github.io仓库，其中username为自己的用户名。 再进入blog_hexo根目录，安装npm install hexo-deployer-git --save，然后打开根目录下的_config.yml，拉到最下面, 修改Deployment设置： 123456# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repository: https://github.com/username/username.github.io branch: master 再进入根目录执行如下命令 123hexo cleanhexo generatehexo deploy 第一次上传可能会让你输入git的用户名和密码。 如果成功，就可以打开http://username.github.io,username替换成自己用户名。 ¶Hexo命令 ¶常用命令 123hexo n '文章名' == hexo new '文章名' #新建文章hexo g == hexo generate #生成静态页hexo d == hexo deploy #部署发布 #可与hexo g合并为hexo d -g ¶服务器 1234hexo s == hexo server # Hexo会监视文件变动并自动更新，您无须重启服务器。hexo s -s #静态模式hexo s -p 5000 #更改端口hexo s -i 192.168.1.1 #自定义 ip ¶模板 123hexo n '文章名' #新建文章hexo n page '页面名' #新建页面hexo n photo '页面名' #新建photo页面 ¶参考 Hexo awesome-hexo Hexo部署github博客 亲测Hexo+Github个人博客搭建 HEXO+Github,搭建属于自己的博客 搭建Hexo博客进阶篇–API和一些小部件（四） 使用hexo+github搭建免费个人博客详细教程]]></content>
      <categories>
        <category>tutorials</category>
        <category>miscellaneous</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习中的数据标准化]]></title>
    <url>%2F2018%2F08-18-ML-DataNormalization%2F</url>
    <content type="text"><![CDATA[¶标准化方法 ¶Z-score Normalization Z-score normalization又叫 standardization(规范化)，将特征进行缩放使得其具有均值为0，方差为1的标准正态分布的特性。 $$ z = \frac{x-\mu}{\sigma} $$ 其中均值$\mu = \frac{1}{N} \sum_{i=1}^N (x_i)$，方差$\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^N (x_i - \mu)^2}$。 标准化特征使其具有0均值1方差不仅对于比较单位不同的测量有用，而且还是众多机器学习算法的普遍要求。如果特征在不同的尺度下，不同的权重更新的速率会差异很大，不利于算法的收敛。 ¶Mix-max Normalization 另一种常用的标准化叫Mix-max normalization，通常被简称为normalization(标准化)。这种方法将数据放缩到一个固定的区间，通常是0到1之间。 $$ z = \frac{x-\min{(x)}}{\max{(x)}-\min{(x)}} $$ ¶Constant Normalization 将数据除以一个固定的常数，比如最大值： $$ z = \frac{x}{\max{(|x|)}} $$ ¶Binary Encoding 类别值(Categorical values)例如性别可以编码为0和1，如男性为1，女性为0，也可以编码为-1和1. ¶Manhattan Encoding 如果是不能二进制编码的类别值，可以使用曼哈顿编码Manhattan encoding，使用0或1来表示特征是否被包含： 例如：在宗教类别中，可以将穆斯林(Muslim)、印度教(Hindu)和基督教(Christian)分别编码为 [1 0 0]、[0 1 0] 和 [0 0 1]。 ¶示例代码 代码参考自About Feature Scaling and Normalization 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import pandas as pdimport numpy as npdf = pd.io.parsers.read_csv( 'https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/wine_data.csv', header=None, usecols=[0,1,2] )df.columns=['Class label', 'Alcohol', 'Malic acid']df.head()from sklearn import preprocessing# Compute the mean and std to be used for later scaling.std_scale = preprocessing.StandardScaler().fit(df[['Alcohol', 'Malic acid']]) # Perform standardization by centering and scalingdf_std = std_scale.transform(df[['Alcohol', 'Malic acid']]) minmax_scale = preprocessing.MinMaxScaler().fit(df[['Alcohol', 'Malic acid']])df_minmax = minmax_scale.transform(df[['Alcohol', 'Malic acid']])print('Mean after standardization:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;' .format(df_std[:,0].mean(), df_std[:,1].mean()))print('\nStandard deviation after standardization:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;' .format(df_std[:,0].std(), df_std[:,1].std()))print('\nMin-value after min-max scaling:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;' .format(df_minmax[:,0].min(), df_minmax[:,1].min()))print('Max-value after min-max scaling:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;' .format(df_minmax[:,0].max(), df_minmax[:,1].max()))from sys import platform as _platformif _platform == "darwin": import matplotlib matplotlib.use('TkAgg')from matplotlib import pyplot as pltdef plot(): plt.figure(figsize=(8,6)) plt.scatter(df['Alcohol'], df['Malic acid'], color='green', label='input scale', alpha=0.5) plt.scatter(df_std[:,0], df_std[:,1], color='red', label='Standardized [$N (\mu=0, \; \sigma=1)$]', alpha=0.3) plt.scatter(df_minmax[:,0], df_minmax[:,1], color='blue', label='min-max scaled [min=0, max=1]', alpha=0.3) plt.title('Alcohol and Malic Acid content of the wine dataset') plt.xlabel('Alcohol') plt.ylabel('Malic Acid') plt.legend(loc='upper left') plt.grid() plt.tight_layout()plot()plt.show() 结果 ¶Reference Preprocessing data A Dummies Guide to Data Normalization About Feature Scaling and Normalization]]></content>
      <categories>
        <category>algorithm</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Network in TensorFlow]]></title>
    <url>%2F2018%2F07-19-ML-TensorFlowConv%2F</url>
    <content type="text"><![CDATA[翻译自Build a Convolutional Neural Network using Estimators TensorFlow的layer模块提供了一个轻松构建神经网络的高端API，它提供了创建稠密（全连接）层和卷积层，添加激活函数，应用dropout regularization的方法。本教程将介绍如何使用layer来构建卷积神经网络来识别MNIST数据集中的手写数字。 MNIST数据集由60,000训练样例和10,000测试样例组成，全部都是0-9的手写数字，每个样例由28x28大小的图片构成。 ¶Getting Started 首先来搭建TensorFlow程序的骨架，创建一个叫cnn_mnist.py的文件，并在其中添加下面代码： 1234567891011121314from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_function# Importsimport numpy as npimport tensorflow as tftf.logging.set_verbosity(tf.logging.INFO)# Our application logic will be added hereif __name__ == "__main__": tf.app.run() 下面的教程将指导如何在该文件中添加代码来构建、训练、评价卷积神经网络。最终完成代码可以在这里下载。 ¶Intro to Convolutional Neural Networks 卷积神经网络（Convolutional Neural Networks, CNNs）是图像分类任务的主流架构，CNNs通过对图像的原始像素数据作用一系列的滤波来提取并学习高阶特征，然后模型使用该特征来进行分类。CNNs包含三个部分： 卷积层（Convolutional layers）：卷积层在图像上应用一定数目的卷积滤波。对于图像的每一个子区域，该层使用一些数学运算来产生输出特征图中的一个值。然后卷积层一般会继续对输出结果使用ReLU激活函数以在模型中引入非线性性。 池化层（Pooling layers）：池化层对卷积层提取的图像数据进行下采样，来减小特征图的维度以减少处理时间。一个广泛使用的池化算法是最大池化，最大池化提取特征图的一个子区域（如2x2的子像素块），只保留其最大值。 全连接层（Dense (fully connected) layers）：全连接层在通过卷积层和池化层处理后得到的特征中进行分类，在全连接层中，该层的每一个节点与下一层的每一个节点都有连接。 通常，一个卷积神经网络由一堆进行特征提取的卷积模块组成，每一个模块由一个卷积层，紧接着一个池化层组成，最后一个卷积模块后面接着一个或多个全连接层来进行分类。最后一个全连接层的每一个节点对应模型目标类别中的每一个分类，并借助一个softmax激活函数来为每一个节点产生一个0到1之间的值（所有节点值的和为1），可以借助softmax得到的值来解释目标图像落在每个类别中的相对概率。 Note：斯坦福大学的Convolutional Neural Networks for Visual Recognition课程资料有关于CNN架构的更详细的介绍。 ¶Building the CNN MNIST Classifier 接下来使用下面的CNN架构来构建一个模型对MNIST数据集中的图像进行分类： Convolutional Layer #1: 应用32个5x5的滤波（提取5x5的像素块），并使用ReLU激活函数 Pooling Layer #1: 使用最大池化，滤波大小为2x2，stride为2（使得被池化的区域不会重叠） Convolutional Layer #2: 应用64个5x5的滤波，并使用ReLU激活函数 Pooling Layer #2: 同样，使用最大池化，滤波大小为2x2，stride为2 Dense Layer #1: 1024个神经元，dropout regularization rate为0.4（在训练的过程中每个元素有0.4的概率被丢弃） Dense Layer #2 (Logits Layer): 10个神经元，每个代表数字的类别（0到9） tf.layers模块提供了创建这三个神经网络层的方法： conv2d(). 创建一个2维的卷积层，参数包括滤波个数，滤波核大小，padding，激活函数。 max_pooling2d(). 使用最大池化算法构建一个2维的池化层。参数包括池化滤波大小和strides。 dense(). 构建一个全连接层，参数包括神经元的个数和激活函数。 这些方法的输入都是一个张量（Tensor），输出是一个变换的张量，这也使得层与层之间的连接变得简单，即只需将一层的输出当作下一层的输入。 打开cnn_mnist.py文件并添加下面符合TensorFlow的Estimator API接口的cnn_model_fn函数。cnn_mnist.py将MINIST特征数据、标记和模型模式（TRAIN，EVAL，PREDICT）作为参数，配置CNN，然后返回预测、损失和一个训练操作： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def cnn_model_fn(features, labels, mode): """Model function for CNN.""" # Input Layer input_layer = tf.reshape(features["x"], [-1, 28, 28, 1]) # Convolutional Layer #1 conv1 = tf.layers.conv2d( inputs=input_layer, filters=32, kernel_size=[5, 5], padding="same", activation=tf.nn.relu) # Pooling Layer #1 pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) # Convolutional Layer #2 and Pooling Layer #2 conv2 = tf.layers.conv2d( inputs=pool1, filters=64, kernel_size=[5, 5], padding="same", activation=tf.nn.relu) pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2) # Dense Layer pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64]) dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu) dropout = tf.layers.dropout( inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN) # Logits Layer logits = tf.layers.dense(inputs=dropout, units=10) predictions = &#123; # Generate predictions (for PREDICT and EVAL mode) "classes": tf.argmax(input=logits, axis=1), # Add `softmax_tensor` to the graph. It is used for PREDICT and by the # `logging_hook`. "probabilities": tf.nn.softmax(logits, name="softmax_tensor") &#125; if mode == tf.estimator.ModeKeys.PREDICT: return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions) # Calculate Loss (for both TRAIN and EVAL modes) loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) # Configure the Training Op (for TRAIN mode) if mode == tf.estimator.ModeKeys.TRAIN: optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001) train_op = optimizer.minimize( loss=loss, global_step=tf.train.get_global_step()) return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op) # Add evaluation metrics (for EVAL mode) eval_metric_ops = &#123; "accuracy": tf.metrics.accuracy( labels=labels, predictions=predictions["classes"])&#125; return tf.estimator.EstimatorSpec( mode=mode, loss=loss, eval_metric_ops=eval_metric_ops) 下面的章节将更加详细的介绍创建每一层的tf.layers代码，还有怎样计算损失，配置训练操作，生成预测。熟悉CNN的可以直接跳到Training and Evaluating the CNN MNIST Classifier章节. ¶Input Layer 在layers模块中创建二维图像数据的卷积和池化层的方法期望输入张量默认的形状是[batch_size, image_height, image_width, channels]，这个行为可以通过使用data_format参数来改变， batch_size.在训练中进行梯度下降时使用的样例子集的大小。 image_height.样例图像的高度。 image_width. 样例图像的宽度。 channels. 样例图像的颜色通道数。对于彩色图像，通道数是3(red, green, blue)，对于黑白图像monochrome images，通道数是1(black)。 data_format. 一个字符串，channels_last和channels_first中的一个值，默认是channels_last，其中channels_last对应输入形状(batch, ..., channels)，channels_first对应输入形状(batch, channels, ...)。 在这个例子中，MNIST数据集由28x28的黑白图像组成，所以输入层的目标形状是[batch_size, 28, 28, 1]。为了将输入的特征图转化为这个形状，可以使用下面的reshape操作： 1input_layer = tf.reshape(features["x"], [-1, 28, 28, 1]) 注意这里将batch size指定为-1，表示这个维度将根据features[&quot;x&quot;]中输入值的个数来动态计算，其他维度的大小均设置为常量。这样可以将batch_size当作一个可以调节的超参数。例如，如果按照5个batches传递样例，features[&quot;x&quot;]将包含3,920个值，输入层的形状是[5, 28, 28, 1]。同样，如果传递100个batches的样例，features[&quot;x&quot;]将包含78,400个值，输入层的形状是[100, 28, 28, 1]。 ¶Convolutional Layer #1 在第一个卷积层，这里对输入层使用32个5x5的滤波，并使用ReLU激活函数，可以使用layers模块中的conv2d()方法来创建该层： 123456conv1 = tf.layers.conv2d( inputs=input_layer, filters=32, kernel_size=[5, 5], padding="same", activation=tf.nn.relu) 参数inputs指定输入张量，形状必须是[batch_size, image_height, image_width, channels]。这里将第一个卷积层与形状为[batch_size, 28, 28, 1]的输入层input_layer连接。 注意：当传入的参数data_format=channels_first时，conv2d()的输入张量形状必须是[batch_size, channels, image_height, image_width]。 参数filters指定使用滤波的数目，kernel_size通过[height, width]的形式指定滤波的维度，如果滤波的height和width的值相同，可以直接使用一个整数来设置kernel_size参数，如kernel_size=5。 参数padding指定两个枚举变量中的一个，valid或same，大小写不敏感，默认值为valid。如果需要输出张量与输入张量有相同的height和width值，设置padding=same，TensorFlow将在输入张量的边缘添加0值，以确保输出张量的height和width为28.（如果不设置为padding，在28x28的张量上进行5x5的卷积操作将产生一个24x24的张量，因为在28x28的格子上只有24x24个位置能够提取5x5的小块。） 参数activation指定作用在卷积输出张量上的激活函数，这里借助tf.nn.relu来指定ReLU激活函数。 这里通过conv2d()生成的输出张量的形状为[batch_size, 28, 28, 32]：跟输入有着同样的height和width维度，但是现在有32个通道，其来自于32个滤波。 ¶Pooling Layer #1 下面将第一个池化层连接到刚刚创建的卷积层，这里使用layers中的max_pooling2d()方法来创建一层来进行滤波大小为2x2，stride为2的最大池化： 1pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) 同样，inputs指定输入张量，形状是[batch_size, image_height, image_width, channels]，这里输入的张量是conv1，即第一个卷积层的输出，其形状为[batch_size, 28, 28, 32]。 注意：跟conv2d()一样，如果传入参数data_format=channels_first，max_pooling2d()也必须接受形状为[batch_size, channels, image_height, image_width]的张量。 参数pool_size指定最大池化滤波大小[height, width]，如果两个维度的值一样，可以直接用一个整数值代替，如pool_size=2。 参数strides指定stride的大小。这里将stride设为2，表示滤波提取的子区域在height和width方向应该相差2个像素间隔（对于2x2滤波，这意味着被提取的区域都不会有交叠）。如果想为height和width设置不同的stride值，可以通过指定一个元组或列表如stride=[3, 6]来实现。 由max_pooling2d()产生的输出张量pool1的形状为[batch_size, 14, 14, 32]：这里2x2的滤波将height和width分别减少了50%。 ¶Convolutional Layer #2 and Pooling Layer #2 和之前一样，可以通过conv2d()和max_pooling2d()将第二个卷积层和池化层连接到已有的CNN上。对于第二个卷积层，这里使用64个5x5的滤波，并同样使用ReLU激活函数。对于第二个池化层，这里使用和第一个池化层同样的配置，即2x2的最大池化，stride为2。 12345678conv2 = tf.layers.conv2d( inputs=pool1, filters=64, kernel_size=[5, 5], padding="same", activation=tf.nn.relu)pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2) 注意第二个卷积层将第一个池化层的输出张量作为输入，并输出张量conv2，conv2的形状为[batch_size, 14, 14, 64]，和pool1具有同样的height和width（由于padding=&quot;same&quot;），64个通道是由于有64个滤波作用。 第二个池化层将conv2作为输入，输出pool2，其形状为[batch_size, 7, 7, 64]。 ¶Dense Layer 接下来，在当前CNN上添加一个全连接层（包括1,024个神经元，使用ReLU激活函数），以在前面卷积层和池化层提取的特征上做分类。在连接该层之前，需要将特征图pool2展开成[batch_size, features]的形状，这样该张量便只有两个维度： 1pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64]) 在上面的reshape()运算中，-1表示batch_size维度将根据输入数据的样例个数来动态计算，每个样例有7 (pool2 height) * 7 (pool2 width) * 64 (pool2 channels)个特征，因此特征的维度是7764（总共3136）。输出张量pool2_flat的形状为[batch_size, 3136]。 现在可以通过layers中的dense()方法来连接全连接层： 1dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu) 参数inputs指定输入张量：展开的特征图pool2_flat。参数units指定全连接层中的神经元数目。参数activation指定激活函数，这里同样使用tf.nn.relu来添加ReLU激活函数。 为了改进模型的结果，这里对全连接层使用dropout正则化，使用layers中的dropout方法： 12dropout = tf.layers.dropout( inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN) 同样，inputs表示输入张量，这里是全连接层的输出。参数rate指定dropout rate，这里使用0.4，表示在训练过程中有40%的元素会被随机丢弃。参数training由一个布尔值指定当前是否是训练模式。dropout只在training是True的情况下使用。这里检查传入模型函数cnn_model_fn的模式是否是TRAIN模式。 输出的张量dropout的形状是[batch_size, 1024]。 ¶Logits Layer 神经网络的最后一层是logits layer，该层将返回预测的原始值。这里创建一个有10个神经元（每个神经元表示0-9的目标类别）的全连接层，使用默认的线性激活函数： 1logits = tf.layers.dense(inputs=dropout, units=10) CNN最终的输出张量logits的形状为[batch_size, 10]。 ¶Generate Predictions 模型的logits layer返回一个形状为[batch_size, 10]的张量作为预测的原始值，接下来将这些原始值转换为2种不同的格式使得模型函数能够返回： 每个样例预测的类别：0-9的一个数字 一个样例属于每个类别的概率，如某个样例是0的概率、1的概率等等。 给定一个类别，所预测的类别是logits张量所对应行中的最大值，可以通过tf.argmax函数找到该最大值的索引： 1tf.argmax(input=logits, axis=1) 参数input指定需要提取最大值的张量，即logits。参数axis指定需要寻找最大值的输入张量的轴，这里需要沿着索引为1的维度，即对应我们的预测结果来找最大值（注意张量logits的形状为[batch_size, 10]）。 通过使用softmax函数tf.nn.softmax从logits layer得到概率： 1tf.nn.softmax(logits, name="softmax_tensor") 注意：这里使用参数name来显示地命名这个运算为softmax_tensor，这样后面可以引用它。（后面要为softmax值设置记录（logging）） 这里将预测结果编制进一个词典，返回一个EstimatorSpec对象： 123456predictions = &#123; "classes": tf.argmax(input=logits, axis=1), "probabilities": tf.nn.softmax(logits, name="softmax_tensor")&#125;if mode == tf.estimator.ModeKeys.PREDICT: return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions) ¶Calculate Loss 对于训练和评价，都需要定义一个损失函数来估计模型预测的值与实际的目标类别的接近程度。对于多目标分类问题如MNIST，一般用交叉熵来作为损失度量。下面的代码计算模型在TRAIN或EVAL模式下的交叉熵： 1loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) 张量labels包含样例预测索引的列表，如[1, 9, …]。logits包含最后一层的线性输出。函数tf.losses.sparse_softmax_cross_entropy从这两个输入以高效、数值稳定的方式计算softmax crossentropy，也叫categorical crossentropy或negative log-likelihood。 ¶Configure the Training Op 在前面的小节中，已经将CNN的损失定义为logits层和已知labels的softmax cross-entropy，下面配置模型在训练过程中去优化该损失函数，这里将使用0.001的学习率、随机梯度下降法作为优化算法： 123456if mode == tf.estimator.ModeKeys.TRAIN: optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001) train_op = optimizer.minimize( loss=loss, global_step=tf.train.get_global_step()) return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op) 注意：需要更深入地了解为Estimator模型函数配置训练运算，参考Defining the training op for the model. ¶Add evaluation metrics 为了在模型中增加准确度量，这里在EVAL模式下定义一个eval_metric_ops字典： 12345eval_metric_ops = &#123; "accuracy": tf.metrics.accuracy( labels=labels, predictions=predictions["classes"])&#125;return tf.estimator.EstimatorSpec( mode=mode, loss=loss, eval_metric_ops=eval_metric_ops) ¶Training and Evaluating the CNN MNIST Classifier MNIST CNN模型的函数已经完成，下面准备训练并评价该模型。 ¶Load Training and Test Data 首先载入训练和测试数据，在cnn_mnist.py文件中添加一个main()函数： 1234567def main(unused_argv): # Load training and eval data mnist = tf.contrib.learn.datasets.load_dataset("mnist") train_data = mnist.train.images # Returns np.array train_labels = np.asarray(mnist.train.labels, dtype=np.int32) eval_data = mnist.test.images # Returns np.array eval_labels = np.asarray(mnist.test.labels, dtype=np.int32) 这里将训练特征数据（55,000张手写数字图像的原始像素值）和训练标签（每张图像对应的从0到9的值）作为numpy arrays的形式分别存储在train_data和train_labels中。同样，评价特征数据（10,000张图像）和评价标签被分别存储在eval_data和eval_labels中。 ¶Create the Estimator 接下来为模型创建一个Estimator（一个进行高端模型训练、评价和推断的TensorFlow类）。在 main()中添加如下代码： 123# Create the Estimatormnist_classifier = tf.estimator.Estimator( model_fn=cnn_model_fn, model_dir="/tmp/mnist_convnet_model") 参数model_fn指定用于训练、评价和预测的模型函数，这里传入前面创建的cnn_model_fn函数。参数model_dir指定模型数据(checkpoints)存储的路径。 ¶Set Up a Logging Hook 由于CNNs需要花费一定的时间去训练，这里设置一些记录以能够追踪训练的过程。可以使用TensorFlow的tf.train.SessionRunHook创建一个tf.train.LoggingTensorHook来记录softmax layer得到的概率值。在main()中添加如下代码： 1234# Set up logging for predictionstensors_to_log = &#123;"probabilities": "softmax_tensor"&#125;logging_hook = tf.train.LoggingTensorHook( tensors=tensors_to_log, every_n_iter=50) 这里在tensors_to_log中存储想要记录的张量的字典，每个key是记录输出中要打印的标签，对应的标签是张量在TensorFlow图中的名字，这里probabilities可以在softmax_tensor中找到，前面在cnn_model_fn中生成概率时在softmax运算中指定的名字。 注意：如果不显示地通过name参数来给一个运算命名，TensorFlow会指定一个默认的名字。通过TensorBoard可视化运算图或者打开TensorFlow Debugger (tfdbg)可以发现每个运算的名字。 接下来创建LoggingTensorHook，并将tensors_to_log传入tensors参数，这里设置every_n_iter=50表示在训练中每50步输出一次probabilities。 ¶Train the Model 接下来创建train_input_fn函数并在mnist_classifier中调用train()来准备训练模型。在main()中添加下面代码： 1234567891011# Train the modeltrain_input_fn = tf.estimator.inputs.numpy_input_fn( x=&#123;"x": train_data&#125;, y=train_labels, batch_size=100, num_epochs=None, shuffle=True)mnist_classifier.train( input_fn=train_input_fn, steps=20000, hooks=[logging_hook]) 在numpy_input_fn的调用中，训练特征数据和标签分别被传入x（作为一个dict）和y。batch_size被设置为100，表示在每一步中模型训练100个样例批次。num_epochs=None表示模型会一直训练直到达到给定的步数。shuffle=True表示随机改组训练数据。 在train的调用中，设置steps=20000表示模型将会训练20,000步。将logging_hook传入参数hooks使得在训练的过程中其可以被触发。 ¶Evaluate the Model 一旦训练完成，便可以计算其在MNIST测试集上的准确率来评价模型，这里调用evaluate方法来评价在model_fn的eval_metric_ops参数中指定的度量，在main()中添加如下代码： 12345678# Evaluate the model and print resultseval_input_fn = tf.estimator.inputs.numpy_input_fn( x=&#123;"x": eval_data&#125;, y=eval_labels, num_epochs=1, shuffle=False)eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)print(eval_results) 为了创建eval_input_fn，设置num_epochs=1，这样模型可以在每个epoch评价度量并返回结果，这里设置shuffle=False以在数据中依次迭代。 ¶Run the Model 到目前为止，CNN模型函数、Estimator、训练/评价逻辑都编码完成，接下来看看结果。运行cnn_mnist.py。 注意：训练CNNs非常耗时。cnn_mnist.py的估计完成时间取决于处理器，但在CPU上一般需要1小时以上。为了更快速地训练，可以减小传入train()的步数，但这会影响准确率。 随着模型训练，可以看到如下输出记录： 12345678910111213INFO:tensorflow:loss = 2.36026, step = 1INFO:tensorflow:probabilities = [[ 0.07722801 0.08618255 0.09256398, ...]]...INFO:tensorflow:loss = 2.13119, step = 101INFO:tensorflow:global_step/sec: 5.44132...INFO:tensorflow:Loss for final step: 0.553216.INFO:tensorflow:Restored model from /tmp/mnist_convnet_modelINFO:tensorflow:Eval steps [0,inf) for training step 20000.INFO:tensorflow:Input iterator is exhausted.INFO:tensorflow:Saving evaluation summary for step 20000: accuracy = 0.9733, loss = 0.0902271&#123;'loss': 0.090227105, 'global_step': 20000, 'accuracy': 0.97329998&#125; 可以看到最终在测试集上可以达到97.3%的准确率。 ¶Additional Resources To learn more about TensorFlow Estimators and CNNs in TensorFlow, see the following resources: Creating Estimators in tf.estimator provides an introduction to the TensorFlow Estimator API. It walks through configuring an Estimator, writing a model function, calculating loss, and defining a training op. Advanced Convolutional Neural Networks walks through how to build a MNIST CNN classification model without estimators using lower-level TensorFlow operations. 上次更新日期：七月 19, 2018 ¶Reference Build a Convolutional Neural Network using Estimators]]></content>
      <categories>
        <category>translation</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow Funstions for Tensor Operations]]></title>
    <url>%2F2018%2F07-19-TF-Functions%2F</url>
    <content type="text"><![CDATA[¶形状相关 Tensor Shape ¶tf.reshape 12345tf.reshape( tensor, shape, name=None) 给定一个tensor，该函数返回一个与输入tensor具有相同值且形状为shape的张量。 如果shape中有一个特殊值-1，则该维度的大小通过整个tensor的尺寸计算得到，特殊情况下shape为[-1]时则将tensor摊平成1-D。shape最多有一个值为-1。 如果shape是一维或更高维度，该函数返回的形状为shape的张量中的值由tensor的值填充，在这种情况下，由shape决定的元素个数必须与输入tensor中的元素个数一致。 Ref tf.reshape Args: tensor: 一个Tensor张量 。 shape: 一个Tensor张量，必须是int32或int64类型，决定了输出张量的形状。 name: 操作的名字，可选参数。 Returns: 一个 Tensor张量，和输入tensor具有相同的数据类型。 ¶tf.expand_dims 123456tf.expand_dims( input, axis=None, name=None, dim=None) 给定一个张量input，该函数在input的形状中维度索引为axis的位置插入一个维度为1的维度，维度索引axis从0开始，如果你为axis指定一个负数，则其从后往前数。 这个操作在你想要在某个元素上加入一个batch维度时非常有用。例如有一个形状为[height, width, channels]的图像，通过expand_dims(image, 0)可以使其成为一个只有一张图片的batch，其形状为[1, height, width, channels]。 Ref tf.expand_dims Args: input: 一个张量. axis: 0-D (标量)，指定扩展张量input形状的维度索引，必须位于[-rank(input) - 1, rank(input)]之间。 name: 输出张量的名字。 dim: 0-D (标量)，等价于 axis，将会被废弃。 Returns: 和输入张量input具有相同数据的张量，但其形状多了一个大小为1的维度。 ¶tf.squeeze 1234tf.squeeze(input, axis=None, name=None, squeeze_dims=None) 给定一个张量input，该函数返回一个在移除所有大小为1的维度后，与输入张量具有相同数据类型的张量。如果你不想移除所有大小为1的维度，可以通过指定axis来移除部分大小为1的维度。 Ref tf.squeeze Args: input: 一个张量。A Tensor. The input to squeeze. axis: 一个可选的ints列表，默认为[]。如果指定，则只压缩列表中的维度，维度索引从0开始。当压缩大小不是1的维度时会产生错误。必须在 [-rank(input), rank(input))之间。 name: 操作的名字，可选参数。 squeeze_dims: 废弃的参数，现在改为axis。 Returns: 和输入张量input具有相同类型、相同数据的张量，但是有一个或多个大小为1的维度被移除。 ¶tf.transpose 123456tf.transpose( a, perm=None, name='transpose', conjugate=False) 对张量a进行转秩操作，根据参数perm重新排列各个维度。 返回的张量的第i个维度对应输入张量的第perm[i]个维度，如果perm参数没有指定，其默认会被设为 (n-1…0)，其中n是输入张量的秩。所以默认情况下，该操作进行一个常规的矩阵转秩操作。如果参数conjugate设置为True，a.dtype 是 complex64 或者 complex128 ，则返回输入张量的共轭转秩。 Ref tf.transpose Args: a: A Tensor. perm: A permutation of the dimensions of a. name: A name for the operation (optional). conjugate: Optional bool. Setting it to True is mathematically equivalent to tf.conj(tf.transpose(input)). Returns: A transposed Tensor. Numpy Compatibility In numpy transposes are memory-efficient constant time operations as they simply return a new view of the same data with adjusted strides. TensorFlow does not support strides, so transpose returns a new tensor with the items permuted. ¶tf.concat ¶tf.stack ¶tf.tile ¶特殊矩阵 ¶tf.one_hot ¶tf.eye ¶运算 Arithmetic Operators ¶tf.add ¶tf.subtract ¶tf.tensordot ¶tf.matmul ¶tf.multiply 12345tf.multiply( x, y, name=None) Returns x * y element-wise. Args: x: A Tensor. Must be one of the following types: bfloat16, half, float32, float64, uint8, int8, uint16, int16, int32, int64, complex64, complex128. y: A Tensor. Must have the same type as x. name: A name for the operation (optional). Returns: A Tensor. Has the same type as x. Ref tf.multiply ¶tf.scalar_mul ¶tf.div ¶tf.divide ¶tf.truediv ¶tf.floordiv ¶tf.realdiv ¶tf.truncatediv ¶tf.floor_div ¶tf.truncatemod ¶tf.floormod ¶tf.mod ¶tf.cross ¶tf.einsum 1tf.einsum(equation, *inputs) Ref tf.einsum ¶图像 Images ¶tf.image ¶Ref Upgrade to TensorFlow 1.0 Arithmetic Operators]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS10.13.2配置TensorFlow]]></title>
    <url>%2F2018%2F07-08-Mac-ConfigureTensorFlow%2F</url>
    <content type="text"><![CDATA[¶安装Python python3是通过Homebrew安装的，默认安装的是3.7.0版本，但TensorFlow目前只能在3.4，3.5，3.6上安装，因此首先需要安装3.6版本的python。 首先运行命令 1brew unlink python3 然后通过https://github.com/Homebrew/homebrew-core/commits/master/Formula/python.rb 找到要需要安装的python版本，我这里选择python:3.6.5_1 bottle，再用如下命令安装 1brew install https://raw.githubusercontent.com/Homebrew/homebrew-core/f2a764ef944b1080be64bd88dca9a1d80130c558/Formula/python.rb 此时输入 1python3 --version 发现得到 1Python 3.6.5 则安装成功，/usr/local/Cellar/python中有3.6.5_1和3.7.0两个文件夹。 ¶安装Virtualenv TensorFlow的官方教程推荐使用Virtualenv的方式安装TensorFlow。 Virtualenv是一个与其他Python开发相互隔离的虚拟Python环境，它无法干扰同一计算机上的其他Python程序，也不会受其影响。要开始使用TensorFlow，只需要“激活”虚拟环境。总而言之，Virtualenv提供一种安全可靠的机制来安装和运行TensorFlow。 Virtualenvwrapper则是对Virtualenv提供了简易的命令行封装，可以更方便地管理虚拟环境。 首先安装Virtualenv和Virtualenvwrapper： 12pip3 install virtualenvpip3 install virtualenvwrapper 然后查找virtualenvwrapper.sh的位置： 1which virtualenvwrapper.sh 得到 1/usr/local/bin/virtualenvwrapper.sh 安装完成后先设置WORKON_HOME，即环境的存储路径，并且运行source /usr/local/bin/virtualenvwrapper.sh，注意，如果你的virtualenv和virtualenvwrapper安装在Homebrew安装的Python3中，还需要设置VIRTUALENVWRAPPER_PYTHON路径，否则会报No module named 'virtualenvwrapper'的错误。 123export WORKON_HOME=~/myLibs/pyenvsexport VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3source /usr/local/bin/virtualenvwrapper.sh 把export命令和source命令加入到~/.bash_profile文件中，每次打开终端就无需初始化了。 一些常用的命令 12345workon 显示所有的环境名称workon 环境名 进入/切换到该环境deactivate 返回到系统环境mkvirtualenv 环境名 新建环境rmvirtualenv 移除环境 ¶安装TensorFlow ¶安装 接下来安装TensorFlow，参考官方安装教程。 首先输入下面的命令创建Virtualenv环境： 1virtualenv --system-site-packages -p python3 ~/myLibs/pyenvs/tensorflow 然后输入下面命令激活Virtualenv环境： 12cd ~/myLibs/pyenvs/tensorflowsource ./bin/activate # If using bash, sh, ksh, or zsh 执行上述source命令后，提示符应该会变成如下内容： 1(tensorflow)$ 接下来将TensorFlow及其所需的所有软件包安装到活动Virtualenv环境中： 1(tensorflow)$ pip3 install --upgrade tensorflow 稍等片刻，TensorFlow就会安装完毕。 注意：每次在新的shell中使用TensorFlow时，都必须激活Virtualenv环境。 如果Virtualenv环境当前未处于活动状态（即提示符不是(tensorflow) $），需调用以下命令： 12cd ~/myLibs/pyenvs/tensorflowsource ./bin/activate 或者，找到activate文件所在的目录即~/myLibs/pyenvs/tensorflow/bin，在当前工作目录下直接执行下面命令也可快速进入虚拟环境，更方便快捷： 1source ~/myLibs/pyenvs/tensorflow/bin/activate 进入虚拟环境后命令提示符将变成如下所示，则表示的tensorflow环境已处于活动状态： 1(tensorflow) $ 当Virtualenv环境处于活动状态时，就可以从该shell运行TensorFlow程序了。 用完TensorFlow后，可以通过发出以下命令来停用此环境： 1(tensorflow)$ deactivate 提示符将恢复为默认提示符。 ¶测试 下面再运行一个简短的TensorFlow程序来测试其是否正确安装。 首先激活 从shell中调用Python，如下所示： 1$ python3 在Python交互式shell中输入以下几行简短的程序代码： 12345&gt;&gt;&gt; # python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')&gt;&gt;&gt; sess = tf.Session()&gt;&gt;&gt; print(sess.run(hello)) 如果系统输出以下内容，则说明TensorFlow已加被正确安装： 1Hello, TensorFlow! 如果发生错误，你就需要继续折腾了。 ¶用PyCharm测试 新建PyCharm项目，一般需要做一番配置才可运行TensorFlow项目。 打开Preference，按照如下步骤操作即可。 ¶卸载 如果需要卸载TensorFlow，只需移除之前创建的~/myLibs/pyenvs/tensorflow文件夹即可。 ¶参考 在 macOS 上安装 TensorFlow Mac下安装Python虚拟环境Virtualenv No module named ‘virtualenvwrapper’ 为什么pycharm中无法import tensorflow？]]></content>
      <categories>
        <category>tutorials</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3D变换]]></title>
    <url>%2F2018%2F06-10-CG-Transformation3D%2F</url>
    <content type="text"><![CDATA[¶三维矩阵变换 你可以使用一个4×4的矩阵将任何点变换到另一个点。下面的例子中，我们用一个矩阵对点$(x, y, z)$进行变化，产生了一个新的点$(x’, y’, z’)$： $$ \begin{bmatrix} x’ &amp; y’ &amp; z’ &amp; 1 \end{bmatrix}= \begin{bmatrix} x &amp; y &amp; z &amp; 1 \end{bmatrix} \begin{bmatrix} M_{11} &amp; M_{12} &amp; M_{13} &amp; M_{14} \ M_{21} &amp; M_{22} &amp; M_{23} &amp; M_{24} \ M_{31} &amp; M_{32} &amp; M_{33} &amp; M_{34} \ M_{41} &amp; M_{42} &amp; M_{43} &amp; M_{44} \end{bmatrix} $$ 最常用的变换包括：平移（translation），旋转（rotation）和缩放（scaling）。你可以将这些变换合并起来，组成一个矩阵，同时进行几种变换。 ¶平移 将一个点$(x, y, z)$平移到另一个点$(x’, y’, z’)$： $$ \begin{bmatrix} x’ &amp; y’ &amp; z’ &amp; 1 \end{bmatrix}= \begin{bmatrix} x &amp; y &amp; z &amp; 1 \end{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \ 0 &amp; 1 &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; 1 &amp; 0 \ T_x &amp; T_y &amp; T_z &amp; 1 \end{bmatrix} $$ ¶旋转 将一个点$(x, y, z)$沿$x-$轴进行旋转，得到了一个新的点$(x’, y’, z’)$： $$ \begin{bmatrix} x’ &amp; y’ &amp; z’ &amp; 1 \end{bmatrix}= \begin{bmatrix} x &amp; y &amp; z &amp; 1 \end{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \ 0 &amp; \cos\theta &amp; \sin\theta &amp; 0 \ 0 &amp; -\sin\theta &amp; \cos\theta &amp; 0 \ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} $$ 沿$y-$轴进行旋转： $$ \begin{bmatrix} x’ &amp; y’ &amp; z’ &amp; 1 \end{bmatrix}= \begin{bmatrix} x &amp; y &amp; z &amp; 1 \end{bmatrix} \begin{bmatrix} \cos\theta &amp; 0 &amp; \sin\theta &amp; 0 \ 0 &amp; 1 &amp; 0 &amp; 0 \ -\sin\theta &amp; 0 &amp; \cos\theta &amp; 0 \ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} $$ 沿$z-$轴进行旋转： $$ \begin{bmatrix} x’ &amp; y’ &amp; z’ &amp; 1 \end{bmatrix}= \begin{bmatrix} x &amp; y &amp; z &amp; 1 \end{bmatrix} \begin{bmatrix} \cos\theta &amp; \sin\theta &amp; 0 &amp; 0 \ -\sin\theta &amp; \cos\theta &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} $$ ¶缩放 $$ \begin{bmatrix} x’ &amp; y’ &amp; z’ &amp; 1 \end{bmatrix}= \begin{bmatrix} x &amp; y &amp; z &amp; 1 \end{bmatrix} \begin{bmatrix} s_x &amp; 0 &amp; 0 &amp; 0 \ 0 &amp; s_y &amp; 0 &amp; 0 \ 0 &amp; 0 &amp; s_z &amp; 0 \ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} $$ ¶矩阵旋转 ¶欧拉角旋转 ¶偏航角：yaw 偏航角yaw是绕$z$轴逆时针旋转$\alpha$，对应的旋转矩阵是 $$ R_z(\alpha)= \begin{bmatrix} \cos\theta &amp; \sin\theta &amp; 0\ -\sin\theta &amp; \cos\theta &amp; 0 \ 0 &amp; 0 &amp; 1 \end{bmatrix} $$ ¶俯仰角: pitch 俯仰角pitch是绕$y$轴逆时针旋转$\beta$，对应的旋转矩阵是 $$ R_y(\beta)= \begin{bmatrix} \cos\theta &amp; 0 &amp; \sin\theta \ 0 &amp; 1 &amp; 0 \ -\sin\theta &amp; 0 &amp; \cos\theta \end{bmatrix} $$ ¶滚转角: roll 滚转角roll是绕$x$轴逆时针旋转$\gamma$，对应的旋转矩阵是 $$ R_x(\gamma)= \begin{bmatrix} 1 &amp; 0 &amp; 0 \ 0 &amp; \cos\theta &amp; \sin\theta \ 0 &amp; -\sin\theta &amp; \cos\theta \end{bmatrix} $$ ¶刚体变换 这三个旋转矩阵合起来便可以表达一个刚体变换[[3]][Yaw, pitch, and roll rotations] $$ R(\alpha,\beta,\gamma)=R_z(\alpha)R_y(\beta)R_x(\gamma) $$ ¶四元数旋转 ¶四元数、欧拉角、旋转矩阵的优点和缺点 矩阵旋转 优点： 旋转轴可以是任意向量； 缺点： 旋转其实只需要知道一个向量+一个角度，一共4个值的信息，但矩阵法却使用了16个元素； 而且在做乘法操作时也会增加计算量，造成了空间和时间上的一些浪费； 欧拉旋转 优点： 很容易理解，形象直观； 表示更方便，只需要3个值（分别对应x、y、z轴的旋转角度）；但按我的理解，它还是转换到了3个3*3的矩阵做变换，效率不如四元数； 缺点： 之前提到过这种方法是要按照一个固定的坐标轴的顺序旋转的，因此不同的顺序会造成不同的结果； 会造成万向节锁（Gimbal Lock）的现象。这种现象的发生就是由于上述固定坐标轴旋转顺序造成的。理论上，欧拉旋转可以靠这种顺序让一个物体指到任何一个想要的方向，但如果在旋转中不幸让某些坐标轴重合了就会发生万向节锁，这时就会丢失一个方向上的旋转能力，也就是说在这种状态下我们无论怎么旋转（当然还是要原先的顺序）都不可能得到某些想要的旋转效果，除非我们打破原先的旋转顺序或者同时旋转3个坐标轴。这里有个视频可以直观的理解下； 由于万向节锁的存在，欧拉旋转无法实现球面平滑插值。 四元数旋转 优点： 可以避免万向节锁现象； 只需要一个4维的四元数就可以执行绕任意过原点的向量的旋转，方便快捷，在某些实现下比旋转矩阵效率更高； 可以提供平滑插值。 缺点： 比欧拉旋转稍微复杂了一点点，因为多了一个维度； 理解更困难，不直观； ¶参考 矩阵与变换 图形学复习要点 Yaw, pitch, and roll rotations Creating a rotation matrix with pitch, yaw, roll using Eigen]]></content>
      <categories>
        <category>algorithm</category>
        <category>cg</category>
      </categories>
      <tags>
        <tag>cg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS项目属性配置简介]]></title>
    <url>%2F2018%2F06-09-VS-ProjectConfiguration%2F</url>
    <content type="text"><![CDATA[转载自 Visual Studio项目属性的一些配置项的总结 ¶VS项目的文件组织方式 VC6.0之后的VC (VS)系列使用解决方案(Solution)来替代原来的工作空间，用于组织和管理多个相关的项目(Project)。VS中的每个管理器(解决方案或项目)都会对应一个总的文件夹，这个管理器文件夹下存放本管理器的配置文件以及子管理器。以C#项目为例，解决方案管理器总文件夹下包含解决方案配置文件*.sln和项目子管理器文件夹，而项目子管理器文件夹下包含C#源文件*.cs、项目配置文件*.csproj、Properties属性文件夹、obj文件夹和bin文件夹。其中obj和bin文件夹下各包含debug和release两个文件夹。obj文件夹下存放中间编译结果，bin文件夹下存放最终生成的exe或dll文件。 ¶常用项目属性和系统默认配置变量 通常程序开发步骤包括编辑程序、编译程序、装配链接程序、程序调试测试、安装部署。表1给出了程序开发过程中常用的系统变量名和意义： 系统变量 变量含义 $(ConfigurationName) 配置名，通常是debug或release $(IntDir) 编译器使用的中间目录，产出obj文件 $(OutDir) 链接器使用的输出目录 $(ProjectDir) 项目目录 $(ProjectName) 项目名 $(SolutionDir) 解决方案目录 $(TargetDir) 目标输出文件所在的目录，产生exe文件 $(TargetExt) 目标输出的扩展名 $(TargetFileName) 目标输出文件名，包括扩展名 $(TargetName) 目标输出名，不包括扩展名 $(TargetPath) 目标输出文件的全路径名 ¶常规—&gt;输出目录 项目属性的“常规”栏目中“输出目录(OutDir)”的作用是给$(OutDir)系统变量赋值，其默认属性值为$(SolutionDir)$(ConfigurationName)，$(SolutionDir)表示解决方案目录，$(ConfigurationName)的值为debug或release。启动编译后会在解决方案文件夹下建立debug文件夹。 也就是说默认情况下的输出目录是在解决方案目录下的debug或release文件夹下，当然这是针对C++型项目而言，C#型项目不一样。 ¶常规—&gt;中间目录 项目属性的“常规”栏目中，“中间目录(IntDir)”的作用是存储链接器所需的输入文件，默认属性为(ProjectDir)(ConfigurationName)，编译后会在MyProject项目文件夹下建立一个debug文件夹，并在该文件夹下生成MyProject.obj二进制文件。 ¶接器—&gt;常规—&gt;输出文件 项目属性的“链接器”栏目下，“常规”选项下，“输出文件”默认属性为$(OutDir)$(ProjectName).exe，其中$(OutDir)指的是输出目录，启动链接后，在输出目录下生成MyProject.exe文件。$(TargetDir)的值是由“输出文件”指定的目录决定的。也就是链接器最后生成的*.exe文件所在位置。 “输出目录”和“输出文件”两个属性对应的目录默认情况下是一样的，这样用着方便。如果两个不一样，则链接器所需的*.ilk和*.pdb等中间文件在“输出目录”，而最终生成的exe文件在“输出文件”属性设置的目录中。 ¶调试—&gt;命令 项目的“输出目录”属性值决定着系统变量$(OutDir)的值，而项目的“输出文件”的属性值决定着$(TargetDir)和$(TargetPath)的值。程序调试时，系统变量$(OutDir)的值是最先确定的，而$(TargetDir)和$(TargetPath)的值是在链接器生成exe文件后才确定的。 “调试”栏目中的“命令(Command)”属性项，这个属性表示启动调试器时执行的exe文件“全路径名+文件名”，默认为链接器生成的$(TargetPath)目录，当然你也可以手动更改“命令”属性的值。 单击调试按钮(VS中的那个小三角形按钮)，VS会起动图中所示目录下的exe文件。一般来说“链接器”—&gt;“输出文件”与“调试”—&gt;“命令”中的文件位置、名称是相同，以表示链接器生成的文件和调试时使用的文件一样。一言以蔽之，①&lt;“调试”—&gt;“命令”&gt;、②TargetPath、③输出文件，④输出目录(OutDir) 默认情况下是处于同一个目录，并呈现出前一个紧密依赖于后一个的关系。 ¶调试—&gt;工作目录 工作目录(WorkingDirection )与执行目录(Command)可以不同，它是程序工作运行过程中默认读取的目录，调试时是将工作目录下的文件作为附加参数添加到执行目录的exe文件中去调试执行。“调试”栏目中的“工作目录”项，默认属性值为$(ProjectDir)，即工程配置文件MyProject.vcproj所在目录，调试过程中它会随着OpenFileDialog、SaveFileDialog等对象所确定的目录而改变。对于静态链接的lib和dll库文件可以放入exe所在的执行目录，而动态加载的dll一般放在工作目录，比如插件就放在工作目录。此外，程序运行过程中生成一个txt文本文件或读取一些配置文件，如果在创建或读取过程中未指定绝对路径，只指定其文件名，那么默认的路径就是工作目录。 VS中工作目录是用于调试过程，只有在调试时，VS才会把项目配置属性中的工作目录设置为执行进程的工作目录，然后再启动对应的exe程序。如果用户选择直接双击一个exe程度启动新进程，VS会自动把exe文件所在的目录设置为新进程的工作目录。因此，在软件部署发布的时候，需把工作目录内的文件拷贝到exe所在的执行目录内，否则就会运行出错。 ¶链接器—&gt;输入—&gt;附加依赖项 “链接器”栏目下，“输入”选项下，“附加依赖项”属性。此项是设置程序链接时使用的静态库的名称。相当于链接已经编译好了的“代码”。由此我们可以简单的认为这些库就相当于我们自己写的源文件，只不过这些库是编译好了的源文件而已。 ¶参考 Visual Studio项目属性的一些配置项的总结]]></content>
      <categories>
        <category>tools</category>
        <category>IDEs</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>vs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Triangulation of Simple Polygons]]></title>
    <url>%2F2018%2F06-09-CG-PolygonsTriangulation%2F</url>
    <content type="text"><![CDATA[Triangulation of Simple Polygons Ben Discoe, notes from 2001.02.11, updated through 2009.01 I needed some code for tessellating polygons, which could be integrated into the VTP libraries, with the following desirable traits: portable no dependencies on large external libraries free (no restrictive license) in C/C++ easy to use preferably, handles ‘holes’ in the polygon Here are each of the options i found. ¶OpenGL contains functionality (in the glu library) which is capable of tessellation problem: requires a complicated system of registering 6 callback functions problem: not easy to use, no example code in Red Book problem: has large external dependency (OpenGL, with a valid context) Extracting the gluTessellate functionality from the SGI OpenGL® Sample Implementation one developer has done this, and says “It was very easy”, which seems rather surprising! Valéry Moya wrote in July 2009: &quot;I wrote my own glu tesselator. Grabbing the tessellation from the callbacks isn’t all that hard and doesn’t require too much code to get working. (In fact, I got it working with just 2 of the callbacks registered: GLU_TESS_BEGIN and GLU_TESS_VERTEX.) In my trial, I was able to get tessellations from lists verts that make up the contour of the polygon I wanted to tessellate (with no overlapping edged, but allowing holes defined as counterclockwise list of verts). The “hard” part is that you need to handle getting the triangulated verts as triangles, triangle fans and triangle strip order but this not as bad as it sounds to keep track of. &quot; Val’s code: glu_tesselation.c ¶Fast Polygon Triangulation based on Seidel’s Algorithm (1995) has C code available problem: small Unix dependency (&lt;sys/time.h&gt;), calls nonstandard stdlib function “log2” problem: in the function add_segment(), a variable is used without being initialized - i.e. it’s questionable code problem? the README written in 1995 says “for non-commercial use only” the author Atul Narkhede, who went from CMU to SGI, refers to the code on a more current website as specifically “Public Domain”, so the latest status is apparently non-restrictive 2008, received an email from another guy trying the code, and he found the code was too buggy ¶Efficient Polygon Triangulation, by John W. Ratcliff on flipcode C++ code, very small and easy to use! Uses STL, but this dependency was easy to remove Tested it on my own data, it worked very well. Add it to vtdata. Only one problem: doesn’t handle holes (and doesn’t claim to) ¶GPC does clipping and boolean operations in addition to triangulation problem: reportedly “uses a simple trapezoidal decomposition that introduces lots of t-junctions” problem: prohibitive license restricts usage ¶“Triangle” by Jonathan Shewchuk Can produce Delaunay triangulations, which apparently have desirable traits for some purposes, but are a bit overkill for the general case. For our simpler case it can produce “Constrained Delaunay”, which means no extraneous triangles. Supports holes! Source is free and portable, only one source file (triangle.c) which makes it easy to integrate with. One small drawback: You can’t just tell it which segments are the edges of your hole. Instead, you must supply some point that lies within the hole. Triangle triangulate the hole, then does some kind of “flood fill” to empty it. It’s inefficient, but what’s worse is it requires the caller to compute a point-in-polygon for the hole. This is a non-trivial algorithm for an arbitrary complex polygon. In 2008.01, i adapted the Triangle code with a wrapper to call it from vtlib. It works quite well, for a very large number of polygons. However, there are some (rare) cases of degenerate geometry where it will crash. In particular: It does not like duplicate vertices or duplicate edges. ‘Duplicate’ in this case is relative to numeric precision: For a building 10-100 meters in size, two vertices within 8cm of each other, defining a very short edge, can cause Triangle to crash. It does not like it when a hole (inner ring) in the polygon has a vertex in the same location as one in the outer ring (crash). ¶TerraGear a Free library which contains a cleaned-up version of the Narkhede implementation of the Seidel algorithm (above)? No. Perhaps it did back in 2001, but as of 2007, it contains code to call “Triangle”. It is actually useful as good example code of how to call Triangle. ¶Panda3d A huge, free software stack used by Disney’s VR group, which includes triangulation adapted from “Narkhede A. and Manocha D., Fast polygon triangulation algorithm based on Seidel’s Algorithm” The triangulation is buried deep in the C++ part of its code, underneath a massive mess of python, tcl, cross-platform abstraction, and custom build tools used to build custom build tools! On 2008.01.30, i lifted the ‘Triangulate’ module out of Panda, made it standalone, and ran the provided test (test_tri.cxx). It crashed, with a negative array index. I also spent 3 hours trying to build Panda itself (with most dependencies including Python disabled.) No luck, it is just too complex. There were some implications that the Panda version of Narkhede-Manocha might be cleaned up or fixed. However, since it crashes (for me) on a simple test outside of Panda, this is not encouraging. From: Sébastien Berthet [mailto:sbrt@yahoo.fr] Sent: Friday, February 01, 2008 12:56 AM I assume that you used the last version on CVS (commited 3 weeks ago), right ? http://panda3d.cvs.sourceforge.net/panda3d/panda/src/mathutil/triangulator.cxx?revision=1.5&amp;view=markup The thread on the forum mentions a few fixes… ¶Poly2Tri (Liang / Kittelman, 2005) “Subdivision using monotone polygons and a sweep line algorithm, O(n log n) time and O(n) storage” Supports holes, makes a lot of very skinny triangles. It compares the speed of Poly2Tri vs. some other triangulation implementations, and it claims to be faster, although the triangles produced are very skinny slivers. Another open source implementation is available at PolygonTriangulator.cxx (google it), by Thomas Kittelmann, which says it is adapted from the implementation by Wu Liang (2005), which appears to be part of a project called “Atlas LXR” ¶poly2tri (Mason Green?, 2009-) Says it is “Based on the paper Sweep-line algorithm for constrained Delaunay triangulation by V. Domiter and and B. Zalik” Handles holes. BSD license. Lives on google-code. I evaluated it on 2011-07-19. It managed to tessellate some input which Shewchuk’s Triangle couldn’t not. However, it still crashed on some input, like the polygon to the right. Notice how, once again, one of the polygon’s holes (inner rings) exactly touches the outer ring. The algorithm seems to regard this as degenerate (and does not even detect it to avoid crashing) but it is unfortunately a commonly encountered shape. ¶JTS The Java Topology Suite (JTS) as of 2011 will apparently do reasonable quality triangulation and support holes, see Polygon Triangulation via Ear-Clipping with Delaunay Refinement. JTS is a very large package (as is its C++ sibling, GEOS) but if you are already using it, then this might be an option. ¶Others Triangulating a Simple Polygon in Linear Time (Chazelle 1991) M. Held (2001): “FIST: Fast Industrial-Strength Triangulation of Polygons”. FIST is not open source nor allows unrestricted use. ¶Reference Triangulation of Simple Polygons]]></content>
      <categories>
        <category>repost</category>
        <category>cv/cg</category>
      </categories>
      <tags>
        <tag>triangulation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提取HTML中的文本]]></title>
    <url>%2F2018%2F06-08-Py-ExtractTextFromHTML%2F</url>
    <content type="text"><![CDATA[¶提出HTML中的文本 使用NTLK，参考自Shatu的代码如下: 1234567import nltkfrom urllib import urlopenurl = "http://news.bbc.co.uk/2/hi/health/2284783.stm"html = urlopen(url).read()raw = nltk.clean_html(html)print(raw) ¶将HTML文件转化为Markdown 参考aaronsw/html2text/html2text.py ¶参考 Extracting text from HTML file using Python aaronsw/html2text]]></content>
      <categories>
        <category>tools</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>python</tag>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tips for macOS]]></title>
    <url>%2F2018%2F06-08-Mac-Tips4Mac%2F</url>
    <content type="text"><![CDATA[¶当前文件夹打开Terminal或VS Code[1] 在Applications文件夹下，按住Command，点击Terminal或VS Code拖动到上面的工具栏，出现绿色➕号，即可将其添加到工具栏，如下图所示： 下次在Finder中将文件夹拖动到工具栏的Terminal或VS Code图标上，即可在当前文件夹下打开。 ¶更改文件的默认打开方式[2] ¶方法一：更改某一个文件的默认打开方式 第一步：右键单击该文件。 第二步：按下Option键，你会看到Open With [打开方式]选项变成了Always Open With [始终以此方式打开]。 第三步：选择Always Open With [始终以此方式打开]列表内的某一个应用程序。 注：它仅适用于你所选择的这一个文件，并不适用于其他文件，包括同一类型的文件。 ¶方法二：更改同类型文件的默认打开方式 第一步：右键单击该文件，然后选择Get Info [显示简介]选项。 第二步：找到Open with [打开方式]项目，点击倒三角选择你想指定的默认应用程序。 第三步：单击Change All [全部更改]按钮即可生效。 注：要恢复到系统原来指定的默认应用程序，只需再次按照上述步骤，并选择原来的应用程序即可。 ¶参考 Mac OS X: Open in Visual Studio Code 基础教程：如何更改 Mac 文件的默认打开方式]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[径向基函数]]></title>
    <url>%2F2018%2F05-31-Alg-RBF%2F</url>
    <content type="text"><![CDATA[¶径向基函数简介 径向基(Radial Basis Function, RBF)函数是一个取值仅仅依赖于离原点距离的实值函数，也就是$\phi(x) = \phi(||x||)$,或者还可以是到任意一点$c$的距离，$c$点即为中心点，也就是$\phi(x,c) = \phi(||x-c||)$。 任意一个满足$\phi(x) = \phi(||x||)$特性的函数$\phi$都叫做径向量函数，标准的一般使用欧氏距离，尽管其他距离函数也是可以的。 ¶常用RBF函数 常用径向基函数包括（$r=||x-x_i||$）： Gaussian: $$ \phi ®=e^{-(\varepsilon r)^{2}} $$ Multiquadric: $$ \phi® = \sqrt{(1+(\epsilon r)^2)} $$ Inverse Quadraic: $$ \phi® = \frac{1}{1+(\epsilon r)^2} $$ Inverse Multiquadric: $$ \phi® = \frac{1}{\sqrt{(1+(\epsilon r)^2)}} $$ Polyharmonic spline: $$ \phi ®=r^{k},;k=1,3,5,\dots $$ $$ \phi ®=r^{k}\ln{®},;k=2,4,6,\dots $$ Thin plate spline (a special polyharmonic spline): $$ \phi ®=r^{2}\ln® $$ ¶函数逼近 RBF函数一般用来逼近其他复杂的函数，逼近函数$y(\mathbf x)$用$N$个RBF的加权和来表示，每个RBF有不同的中心$\mathbf x_i$，其一般形式如下： $$ y(\mathbf x) = \sum_{i=1}^N w_i \phi( || \mathbf x - \mathbf x_i || ) $$ 理论上来说，只要$N$足够大，$y(\mathbf x)$能够以任意的精度逼近在某个区间的任意连续函数。 ¶RBF网络 函数 $$ y(\mathbf x) = \sum_{i=1}^N w_i \phi( || \mathbf x - \mathbf x_i || ) $$ 还可以通过一个简单的单层人工神经网络来表达，即RBF网络，径向基函数作为网络的激活函数。 因为$y(\mathbf x)$相对于$w_i$是可微的，所有这些权重可以通过神经网络中标准的迭代法来学习得到。 通过这种方式使用径向基函数在收敛后可以在拟合集中得到一个合理的结果，但是在拟合集外面表现会很差，除非添加一个垂直于径向基函数的多项式项。 ¶Reference WIKIPEDIA-Radial basis function 径向基函数(RBF)]]></content>
      <categories>
        <category>algorithm</category>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[颜色插值]]></title>
    <url>%2F2018%2F05-10-ColorInterpolate%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556Eigen::Vector3f colorMapping_B2R(float value, float min, float max)&#123; // from blue to red float mid1 = (max + 3 * min) / 4.0; float mid2 = (max + min) / 2.0; float mid3 = (3 * max + min) / 4.0; Eigen::Vector3f color; //Eigen::Vector3f blue = Eigen::Vector3f(0.0, 0.0, 1.0); //Eigen::Vector3f cyan = Eigen::Vector3f(0.0, 1.0, 1.0); //Eigen::Vector3f green = Eigen::Vector3f(0.0, 1.0, 0.0); //Eigen::Vector3f yellow = Eigen::Vector3f(1.0, 1.0, 0.0); //Eigen::Vector3f red = Eigen::Vector3f(1.0, 0.0, 0.0); // blue to cyan if (value &gt;= min &amp;&amp; value &lt; mid1) &#123; float temp = (value - min) / (mid1 - min); color = Eigen::Vector3f(0.0, temp, 1.0); &#125; // cyan to green else if (value &gt;= mid1 &amp;&amp; value &lt; mid2) &#123; float temp = (value - mid1) / (mid2 - mid1); color = Eigen::Vector3f(0.0, 1.0, 1.0 - temp); &#125; // green to yellow else if (value &gt;= mid2 &amp;&amp; value &lt; mid3) &#123; float temp = (value - mid2) / (mid3 - mid2); color = Eigen::Vector3f(temp, 1.0, 0.0); &#125; // yellow to red else if (value &gt;= mid3 &amp;&amp; value &lt;= max) &#123; float temp = (value - mid3) / (max - mid3); color = Eigen::Vector3f(1.0, 1.0 - temp, 0.0); &#125; // handle color beyond red else if (value &gt; max) &#123; color = Eigen::Vector3f(1.0, 0.0, 0.0); &#125; // handle color beyond blue else if (value &lt; min) &#123; color = Eigen::Vector3f(0.0, 0.0, 1.0); &#125; return color;&#125; ¶Reference Grayscale to Red-Green-Blue (MATLAB Jet) color scale]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tips for vcpkg]]></title>
    <url>%2F2018%2F05-08-Cpp-Tips4vcpkg%2F</url>
    <content type="text"><![CDATA[¶概述 vcpkg是微软开发的在Windows, Linux和MacOS平台管理C/C++库的开源工具。 ¶快速开始 ¶要求 使用vcpkg需满足如下条件： Windows 10, 8.1, 7, Linux, or MacOS Visual Studio 2017 or Visual Studio 2015 Update 3 (on Windows) Git CMake 3.10.2 (optional) ¶安装vcpkg 12345&gt; git clone https://github.com/Microsoft/vcpkg&gt; cd vcpkgPS&gt; .\bootstrap-vcpkg.batUbuntu:~/$ ./bootstrap-vcpkg.sh 为了让计算机的所有用户都可以使用vcpkg，运行如下命令（首次运行需管理员权限）： 12PS&gt; .\vcpkg integrate installUbuntu:~/$ ./vcpkg integrate install ¶安装库 通过如下命令便可以安装库： 12PS&gt; .\vcpkg install sdl2 curlUbuntu:~/$ ./vcpkg install sdl2 curl 对于Windows平台，vcpkg默认安装32位库，如果想要设置为默认安装64位库，在环境变量中加上VCPKG_DEFAULT_TRIPLET=x64-windows即可。 如果你在安装库时下载速度非常慢甚至下载失败，可以拷贝下载链接自行下载好库的压缩包，然后放在downloads文件夹，这样vcpkg便直接使用下载好的库来编译安装。 对于有些库，默认可能不是所有的依赖都安装，如ceres-solver，默认不支持suitesparse,cxsparse，此时可以通过命令.\vcpkg install ceres[suitesparse,cxsparse]:x64-windows --recurse重新安装，其中--recurse表示可以卸载之前的库。更多install参数可以通过命令.\vcpkg help install查看。 再比如支持cuda的opencv版本，可以通过命令.\vcpkg install opencv[cuda]:x64-windows来安装。 ¶卸载vcpkg 直接删除vcpkg的文件夹即可。 ¶使用库 ¶CMake 在CMake中使用通过vcpkg安装的库的最佳方式是通过工具链文件(toolchain file) scripts/buildsystems/vcpkg.cmake，让安装的库通过find_package()被发现。 要使用这个文件，只需通过命令-DCMAKE_TOOLCHAIN_FILE=[vcpkg root]/scripts/buildsystems/vcpkg.cmake将其加入CMake命令行中即可。例如 12cmake .. -DCMAKE_TOOLCHAIN_FILE=vcpkg/scripts/buildsystems/vcpkg.cmake (Linux/MacOS)cmake .. -DCMAKE_TOOLCHAIN_FILE=vcpkg\scripts\buildsystems\vcpkg.cmake (Windows) 再比如，如果要用VS2017编译器，输入下面命令即可： 1cmake .. -DCMAKE_TOOLCHAIN_FILE=D:\vcpkg\scripts\buildsystems\vcpkg.cmake -G "Visual Studio 15 2017 Win64" 还有一种方法，直接在CMakeLists.txt文件中指定CMAKE_TOOLCHAIN_FILE，即 12set(CMAKE_TOOLCHAIN_FILE "D:\vcpkg\scripts\buildsystems\vcpkg.cmake")project(PROJECT_NAME) 这里需要注意的是，设置CMAKE_TOOLCHAIN_FILE要在project()命令之前**。另外多说一句，类似CMAKE_TOOLCHAIN_FILE, CMAKE_SYSTEM_NAME, CMAKE_C_COMPILER等这些变量都要在project()命令之前设定，不然CMake仍然会按照默认的设置来。 ¶VisualStudio 在VS中，所有已经安装的库都被VS项目自动包含（通过前面提到的vcpkg integrate install命令实现），无需配置便可直接使用。 ¶CLion 在CLion中的配置如下File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake，在CMake Options中添加-DCMAKE_TOOLCHAIN_FILE=[vcpkg root]/scripts/buildsystems/vcpkg.cmake ¶vcpkg命令 vcpkg help： 帮助 vcpkg search： 搜索库 vcpkg install： 安装库 对于Windows平台 .\vcpkg install openmesh:x86-windows：安装32位库 .\vcpkg install openmesh:x64-windows：安装64位库 .\vcpkg install openmesh:x64-windows-static 安装64位静态库 vcpkg list：列出所有已经安装的库 vcpkg upgrade：列出所有可以升级的库，如果需要升级，需额外添加--no-dry-run命令 vcpkg update vcpkg remove：移除某个已经安装的库，如果需要移除依赖该库的其他库，添加--recurse命令 ¶vcpkg文件夹构成 buildtrees – contains subfolders of sources from which each library is built docs – documentation and examples downloads – cached copies of any downloaded tools or sources. vcpkg searches here first when you run the install command installed– Contains the headers and binaries for each installed library. When you integrate with Visual Studio, you are essentially telling it add this folder to its search paths packages – Internal folder for staging between installs ports – Files that describe each library in the catalog, its version, and where to download it. You can add your own ports if needed scripts – Scripts (cmake, powershell) used by vcpkg toolsrc – C++ source code for vcpkg and related components triplets – Contains the settings for each supported target platform (for example, x86-windows or x64-uwp) ¶更新vcpkg 在vcpkg根目录下的ports文件夹中可以看到当前版本包含的所有库，但由于vcpkg项目正在活跃开发中，有时候有些库在你当前的版本中并没有加入，这时可以考虑更新vcpkg。首先拉取vcpkg的远程仓库，更新本地仓库： 1234git fetch origin master:temp // 从远程的origin仓库的master分支下载到本地并新建一个分支tempgit diff temp // 比较本地的仓库和远程仓库的区别git merge temp // 合并temp分支到master分支git branch -d temp // 如果不想要temp分支了，可以删除此分支 然后重新编译生成vcpkg.exe工具 12PS&gt; .\bootstrap-vcpkg.batLinux:~/$ ./bootstrap-vcpkg.sh 然后可以通过命令.\vcpkg update .\vcpkg upgrade更新已经安装好的库。再通过install命令安装新的库。 ¶参考 vcpkg-github vcpkg-docs Vcpkg: a tool to acquire and build C++ open source libraries on Windows CMAKE_TOOLCHAIN_FILE only recognized on command line]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码的多平台支持]]></title>
    <url>%2F2018%2F05-03-Cpp-CrossPlatform%2F</url>
    <content type="text"><![CDATA[¶c++ 123456789101112131415161718192021222324252627#ifdef _WIN32 //define something for Windows (32-bit and 64-bit, this part is common) #ifdef _WIN64 //define something for Windows (64-bit only) #else //define something for Windows (32-bit only) #endif#elif __APPLE__ #include "TargetConditionals.h" #if TARGET_IPHONE_SIMULATOR // iOS Simulator #elif TARGET_OS_IPHONE // iOS device #elif TARGET_OS_MAC // Other kinds of Mac OS #else # error "Unknown Apple platform" #endif#elif __linux__ // linux#elif __unix__ // all unices not caught above // Unix#elif defined(_POSIX_VERSION) // POSIX#else# error "Unknown compiler"#endif ¶python 判断系统信息的代码 123import platformprint(platform.system())print(platform.release()) 123456789101112from sys import platform as _platformif _platform == "linux" or _platform == "linux2": # linuxelif _platform == "darwin": # MAC OS Xelif _platform == "win32": # Windowselif _platform == "win64": # Windows 64-bitelse # others ¶cmake 1234567if(WIN32) aux_source_directory(os/win SOURCES)elseif(APPLE) aux_source_directory(os/mac SOURCES)else(UNIX) aux_source_directory(os/linux SOURCES)endif(WIN32) ¶qmake 123456789macx &#123;# mac only&#125;unix:!macx&#123;# linux only&#125;win32&#123;&#125; ¶Reference How to detect reliably Mac OS X, iOS, Linux, Windows in C preprocessor? 编译系统对跨平台代码的支持 Adding Libraries to Projects Python: What OS am I running on?]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tips for CMake]]></title>
    <url>%2F2018%2F04-22-Tips4CMake%2F</url>
    <content type="text"><![CDATA[¶Reference What’s the CMake syntax to set and use variables?]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMake语言]]></title>
    <url>%2F2018%2F04-15-CMakeLanguage%2F</url>
    <content type="text"><![CDATA[翻译自cmake-language ¶Organization CMake输入文件是用CMake Language写的源文件，包括名叫CMakeLists.txt的文件和以.cmake作为扩展名的文件。 一个项目中的CMake源文件被组织成三部分： Directories (CMakeLists.txt), Scripts (&lt;script&gt;.cmake), Modules (&lt;module&gt;.cmake). ¶Directories 当CMake处理一个项目的源代码树时，入口点是最上层源目录里的CMakeLists.txt文件，这个文件可能包含整个构建规范(build specification)，或者通过使用add_subdirectory()命令来添加需要构建的子目录，每个通过该命令添加的子目录中也必须含有一个CMakeLists.txt文件来作为该路径的入口点。对于CMakeLists.txt文件处理的每一个源目录都会在构建树(build tree)中生成一个对应的目录，来作为默认的工作和输出目录。 ¶Scripts 一个单独的&lt;script&gt;.cmake源文件可以在script模式下通过使用cmake(1)命令行工具中的-P选项来被处理，Script模式只是简单地运行该源文件中用CMake Language写的命令，不会生成一个构建系统。它不允许包含有定义构建目标或行为的CMake命令。 ¶Modules 在Directories或者Scripts中的CMake Language代码可以在包含环境中使用include()命令来载入一个&lt;script&gt;.cmake源文件，可以通过查看cmake-modules(7)来了解CMake包含的所有模块。 项目源代码树可能也提供它们自己的模块，并在CMAKE_MODULE_PATH变量中指定它们的位置。 ¶Syntax ¶Encoding 为了最大化在所有支持平台的可移植性，一个CMake语言的源文件由7-bit ASCII文本写成，换行可以被编码成\n或\r\n，但在读入输入文件时会被转化为\n。 注意实现是8-bit clean，所以源文件在系统API支持UTF-8编码的平台上可能会使用UTF-8编码。此外，CMake 3.2及以上支持在Windows上使用UTF-8编码源文件（使用UTF-16调用系统API）。CMake 3.0及以上allow a leading UTF-8 Byte-Order Mark in source files。 ¶Source Files 一个CMake语言的源文件由零个或更多的由换行和可选的空格分隔开的命令调用(Command Invocations)和注释(Comments)组成： 123456file ::= file_element*file_element ::= command_invocation line_ending | (bracket_comment|space)* line_endingline_ending ::= line_comment? newlinespace ::= &lt;match &apos;[ \t]+&apos;&gt;newline ::= &lt;match &apos;\n&apos;&gt; Note that any source file line not inside Command Arguments or a Bracket Comment can end in a Line Comment. ¶Command Invocations A command invocation is a name followed by paren-enclosed arguments separated by whitespace: 123456command_invocation ::= space* identifier space* '(' arguments ')'identifier ::= &lt;match '[A-Za-z_][A-Za-z0-9_]*'&gt;arguments ::= argument? separated_arguments*separated_arguments ::= separation+ argument? | separation* '(' arguments ')'separation ::= space | line_ending 例如： 1add_executable(hello world.c) 命令的名字对大小写不敏感。参数中嵌套的圆括号必须对称，每个(或者)作为一个literal Unquoted Argument传递给命令调用。这可以在调用if()命令时包围条件使用。例如： Command names are case-insensitive. Nested unquoted parentheses in the arguments must balance. Each ( or ) is given to the command invocation as a literal Unquoted Argument. This may be used in calls to the if() command to enclose conditions. For example: 1if(FALSE AND (FALSE OR TRUE)) # evaluates to FALSE Note CMake versions prior to 3.0 require command name identifiers to be at least 2 characters. CMake versions prior to 2.8.12 silently accept an Unquoted Argument or a Quoted Argument immediately following a Quoted Argument and not separated by any whitespace. For compatibility, CMake 2.8.12 and higher accept such code but produce a warning. ¶Command Arguments 命令调用中有三种形式的参数： 1argument ::= bracket_argument | quoted_argument | unquoted_argument ¶Bracket Argument 括号参数，受启发于Lua的长括号语法，将内容装入拥有同样长度的开始和结束括号： 12345bracket_argument ::= bracket_open bracket_content bracket_closebracket_open ::= '[' '='* '['bracket_content ::= &lt;any text not containing a bracket_close with the same number of '=' as the bracket_open&gt;bracket_close ::= ']' '='* ']' 开始括号首先是一个[，后面跟着0个或多个=，最后再跟着]，与此对应的结束括号也以[开头，后面跟着同样数量的=，然后再跟着]。括号不嵌套， Brackets do not nest. A unique length may always be chosen for the opening and closing brackets to contain closing brackets of other lengths. Bracket argument content consists of all text between the opening and closing brackets, except that one newline immediately following the opening bracket, if any, is ignored. No evaluation of the enclosed content, such as Escape Sequences or Variable References, is performed. A bracket argument is always given to the command invocation as exactly one argument. 例如： 1234567message([=[This is the first line in a bracket argument with bracket length 1.No \-escape sequences or $&#123;variable&#125; references are evaluated.This is always one argument even though it contains a ; character.The text does not end on a closing bracket of length 0 like ]].It does end in a closing bracket of length 1.]=]) Note CMake versions prior to 3.0 do not support bracket arguments. They interpret the opening bracket as the start of an Unquoted Argument. ¶Quoted Argument A quoted argument encloses content between opening and closing double-quote characters: 12345quoted_argument ::= '"' quoted_element* '"'quoted_element ::= &lt;any character except '\' or '"'&gt; | escape_sequence | quoted_continuationquoted_continuation ::= '\' newline Quoted argument content consists of all text between opening and closing quotes. Both Escape Sequences and Variable References are evaluated. A quoted argument is always given to the command invocation as exactly one argument. For example: 123456message("This is a quoted argument containing multiple lines.This is always one argument even though it contains a ; character.Both \\-escape sequences and $&#123;variable&#125; references are evaluated.The text does not end on an escaped double-quote like \".It does end in an unescaped double quote.") The final \ on any line ending in an odd number of backslashes is treated as a line continuation and ignored along with the immediately following newline character. For example: 12345message("\This is the first line of a quoted argument. \In fact it is the only line but since it is long \the source code uses line continuation.\") Note CMake versions prior to 3.0 do not support continuation with . They report errors in quoted arguments containing lines ending in an odd number of \ characters. ¶Unquoted Argument An unquoted argument is not enclosed by any quoting syntax. It may not contain any whitespace, (, ), #, &quot;, or \except when escaped by a backslash: 1234unquoted_argument ::= unquoted_element+ | unquoted_legacyunquoted_element ::= &lt;any character except whitespace or one of '()#"\'&gt; | escape_sequenceunquoted_legacy ::= &lt;see note in text&gt; Unquoted argument content consists of all text in a contiguous block of allowed or escaped characters. Both Escape Sequences and Variable References are evaluated. The resulting value is divided in the same way Lists divide into elements. Each non-empty element is given to the command invocation as an argument. Therefore an unquoted argument may be given to a command invocation as zero or more arguments. For example: 12345678foreach(arg NoSpace Escaped\ Space This;Divides;Into;Five;Arguments Escaped\;Semicolon ) message("$&#123;arg&#125;")endforeach() Note To support legacy CMake code, unquoted arguments may also contain double-quoted strings (&quot;…&quot;, possibly enclosing horizontal whitespace), and make-style variable references ($(MAKEVAR)). Unescaped double-quotes must balance, may not appear at the beginning of an unquoted argument, and are treated as part of the content. For example, the unquoted arguments -Da=&quot;b c&quot;, -Da=$(v), and a&quot; &quot;b&quot;c&quot;d are each interpreted literally. They may instead be written as quoted arguments &quot;-Da=\&quot;b c\&quot;&quot;, &quot;-Da=$(v)&quot;, and &quot;a\&quot; \&quot;b\&quot;c\&quot;d&quot;, respectively. Make-style references are treated literally as part of the content and do not undergo variable expansion. They are treated as part of a single argument (rather than as separate $, (, MAKEVAR, and ) arguments). The above “unquoted_legacy” production represents such arguments. We do not recommend using legacy unquoted arguments in new code. Instead use a Quoted Argument or a Bracket Argument to represent the content. ¶Escape Sequences An escape sequence is a \ followed by one character: 1234escape_sequence ::= escape_identity | escape_encoded | escape_semicolonescape_identity ::= '\' &lt;match '[^A-Za-z0-9;]'&gt;escape_encoded ::= '\t' | '\r' | '\n'escape_semicolon ::= '\;' A \ followed by a non-alphanumeric character simply encodes the literal character without interpreting it as syntax. A \t, \r, or \n encodes a tab, carriage return, or newline character, respectively. A \; outside of any Variable References encodes itself but may be used in an Unquoted Argument to encode the ; without dividing the argument value on it. A \; inside Variable References encodes the literal ; character. (See also policy CMP0053 documentation for historical considerations.) ¶Variable References A variable reference has the form ${variable_name} and is evaluated inside a Quoted Argument or an Unquoted Argument. A variable reference is replaced by the value of the variable, or by the empty string if the variable is not set. Variable references can nest and are evaluated from the inside out, e.g. ${outer_${inner_variable}_variable}. Literal variable references may consist of alphanumeric characters, the characters /_.±, and Escape Sequences. Nested references may be used to evaluate variables of any name. (See also policy CMP0053 documentation for historical considerations.) The Variables section documents the scope of variable names and how their values are set. An environment variable reference has the form $ENV{VAR} and is evaluated in the same contexts as a normal variable reference. ¶Comments 注释从一个#字符开始，但#不能在Bracket Argument、Quoted Argument或者作为Unquoted Argument一部分的转义字符\中。注释有两种类型：Bracket Comment和Line Comment。 ¶Bracket Comment 如果#后面紧跟着一个Bracket Argument则括号中包含的内容构成一个bracket comment： 1bracket_comment ::= '#' bracket_argument 例如： 123#[[This is a bracket comment.It runs until the close bracket.]]message("First Argument\n" #[[Bracket Comment]] "Second Argument") 注意CMake 3.0之前的版本不支持bracket comments，这时将#解释为一个Line Comment的开头。 ¶Line Comment 如果#后面没有紧跟着一个Bracket Argument，则构成一个line comment，直到行尾结束： 12line_comment ::= '#' &lt;any text not starting in a bracket_argument and not containing a newline&gt; 例如： 123# This is a line comment.message("First Argument\n" # This is a line comment :) "Second Argument") # This is a line comment. ¶Control Structures ¶Conditional Blocks if()/elseif()/else()/endif()命令使得代码块有条件地执行。 ¶Loops foreach()/endforeach() and while()/endwhile()命令界定代码块循环执行。在每个这样的快中，break()命令可以终止循环，continue()命令可以让下一次迭代马上进行。 ¶Command Definitions macro()/endmacro()和function()/endfunction()命令界定代码块可以在后面作为命令被调用。 ¶Variables 变量是CMake语言中存储的基本单元，它们的值永远是字符串类型，虽然有些命令会将字符串解释为其他类型的值。set()和unset()命令显示地设置或取消设置一个变量，但是其他命令同样也有修改变量的语义。变量名是大小写敏感的，几乎可以由任意文本组成，但是一般推荐使用只包含字母数字外加_和-的变量名。 变量有动态的作用域，每个变量“set”或者“unset”在当前的作用域创建一个绑定： Variables have dynamic scope. Each variable “set” or “unset” creates a binding in the current scope: Function Scope 通过function()命令创建的Command Definitions生成一个命令，当 Command Definitions created by the function() command create commands that, when invoked, process the recorded commands in a new variable binding scope. A variable “set” or “unset” binds in this scope and is visible for the current function and any nested calls within it, but not after the function returns. Directory Scope Each of the Directories in a source tree has its own variable bindings. Before processing the CMakeLists.txt file for a directory, CMake copies all variable bindings currently defined in the parent directory, if any, to initialize the new directory scope. CMake Scripts, when processed with cmake -P, bind variables in one “directory” scope. A variable “set” or “unset” not inside a function call binds to the current directory scope. Persistent Cache CMake stores a separate set of “cache” variables, or “cache entries”, whose values persist across multiple runs within a project build tree. Cache entries have an isolated binding scope modified only by explicit request, such as by the CACHE option of the set() and unset() commands. When evaluating Variable References, CMake first searches the function call stack, if any, for a binding and then falls back to the binding in the current directory scope, if any. If a “set” binding is found, its value is used. If an “unset” binding is found, or no binding is found, CMake then searches for a cache entry. If a cache entry is found, its value is used. Otherwise, the variable reference evaluates to an empty string. The cmake-variables(7) manual documents many variables that are provided by CMake or have meaning to CMake when set by project code. ¶Lists Although all values in CMake are stored as strings, a string may be treated as a list in certain contexts, such as during evaluation of an Unquoted Argument. In such contexts, a string is divided into list elements by splitting on ; characters not following an unequal number of [ and ] characters and not immediately preceded by a . The sequence ; does not divide a value but is replaced by ; in the resulting element. A list of elements is represented as a string by concatenating the elements separated by ;. For example, the set() command stores multiple values into the destination variable as a list: 1set(srcs a.c b.c c.c) # sets "srcs" to "a.c;b.c;c.c" Lists are meant for simple use cases such as a list of source files and should not be used for complex data processing tasks. Most commands that construct lists do not escape ; characters in list elements, thus flattening nested lists: 1set(x a "b;c") # sets "x" to "a;b;c", not "a;b\;c" ¶Reference cmake-language]]></content>
      <categories>
        <category>translation</category>
        <category>cmake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMake构建系统]]></title>
    <url>%2F2018%2F04-15-CMakeBuildSystem%2F</url>
    <content type="text"><![CDATA[翻译自cmake-buildsystem ¶Introduction 一个基于CMake的构建系统由一套高层次的逻辑目标(high-level logical targets)组成，每个目标对应一个可执行文件或库，或者作为一个包含自定义命令的自定义目标。目标之间的依赖在构建系统中表达出来，来决定构建顺序和改变之后的再生成规则。 ¶Binary Targets 可执行文件和库通过使用add_executable()和add_library()命令来定义，产生的二进制文件有当前目标平台合适的前缀(prefixes)、后缀(suffixes)和扩展名(extensions)。二进制目标之间的依赖通过命令target_link_libraries()来表达： 123add_library(archive archive.cpp zip.cpp lzma.cpp)add_executable(zipapp zipapp.cpp)target_link_libraries(zipapp archive) archive被定义为一个静态库，包含由archive.cpp、zip.cpp和lzma.cpp编译而来的目标。zipapp是一个可执行文件，由编译和链接zipapp.cpp构成。当链接zipapp可执行文件时，archive静态库即被链接。 ¶Binary Executables 命令add_executable()定义一个可执行目标： 1add_executable(mytool mytool.cpp) 有些命令，如在构建时生成运行时规则的add_custom_command()命令，可以显式地使用一个EXECUTABLE target作为COMMAND executable。构建系统的规则会保证在尝试运行命令前构建好可执行文件。 ¶Binary Library Types ¶Normal Libraries 默认情况下，add_library()命令定义一个静态库，除非有具体类型指明。类型可以通过下面的命令指定： 1add_library(archive SHARED archive.cpp zip.cpp lzma.cpp) 1add_library(archive STATIC archive.cpp zip.cpp lzma.cpp) 通过开启BUILD_SHARED_LIBS变量，能够改变add_library()的行为，使得默认构建共享库。 在构建系统定义的环境中，库是SHARED或者STATIC并没有什么关系，命令依赖和其他的API的工作方式一样，和库的类型无关。 MODULE库不一样，一般它不会被链接进去，它不会在target_link_libraries()命令的右侧使用。MODULE库通过运行时技术当作一个插件载入。如果一个库不导出任何非托管的符号(unmanaged symbols)（如Windows resource DLL, C++/CLI DLL），要求这个库不是SHARED库，因为CMake期待SHARED库至少导出一个符合。 1add_library(archive MODULE 7z.cpp) ¶Apple Frameworks 一个共享库可能会被标记为FRAMEWORK目标属性来创建一个OS X或者iOS Framework Bundle，MACOSX_FRAMEWORK_IDENTIFIER设置CFBundleIdentifier键值来唯一地识别一个bundle。 123456add_library(MyFramework SHARED MyFramework.cpp)set_target_properties(MyFramework PROPERTIES FRAMEWORK TRUE FRAMEWORK_VERSION A MACOSX_FRAMEWORK_IDENTIFIER org.cmake.MyFramework) ¶Object Libraries OBJECT库同样不会被链接，它定义了从给定的源文件编译生成的一些未归档的目标文件(object files)。这些目标文件可以作为其他目标的源输入使用： 12345add_library(archive OBJECT archive.cpp zip.cpp lzma.cpp)add_library(archiveExtras STATIC $&lt;TARGET_OBJECTS:archive&gt; extras.cpp)add_executable(test_exe $&lt;TARGET_OBJECTS:archive&gt; test.cpp) OBJECT库可能不会在target_link_libraries()的右端项使用，它们也可能不作为TARGET在add_custom_command(TARGET)命令签名中使用。它们可能会被安装，并作为一个INTERFACE库导出。 虽然在调用target_link_libraries()命令时目标库不会被直接命名，但是它们能够通过使用一个Interface Library间接地被链接，但Interface Library的INTERFACE_SOURCES。 虽然在使用add_custom_command(TARGET)命令签名时目标库可能不会被当作TARGET使用，但使用$&lt;TARGET_OBJECTS:objlib&gt;可以让目标列表可以被add_custom_command(OUTPUT)或file(GENERATE)使用。 ¶Build Specification and Usage Requirements 命令target_include_directories()、target_compile_definitions()和target_compile_options()明确二进制目标的构建规范和使用需求，这些命令分别填入(populate)INCLUDE_DIRECTORIES、COMPILE_DEFINITIONS和COMPILE_OPTIONS目标属性，和/或INTERFACE_INCLUDE_DIRECTORIES、INTERFACE_COMPILE_DEFINITIONS和INTERFACE_COMPILE_OPTIONS目标属性。 每个命令都有PRIVATE、PUBLIC和INTERFACE三种模式。PRIVATE模式只填入(populate)目标属性非INTERFACE_变体(variant)，INTERFACE模式只填入INTERFACE_变体，PUBLIC模式同时填入各自目标属性的变体。每个命令可以通过使用这些关键词的组合： 1234target_compile_definitions(archive PRIVATE BUILDING_WITH_LZMA INTERFACE USING_ARCHIVE_LIB) 注意 使用要求 Note that usage requirements are not designed as a way to make downstreams use particular COMPILE_OPTIONS or COMPILE_DEFINITIONS etc for convenience only. The contents of the properties must be requirements, not merely recommendations or convenience. See the Creating Relocatable Packages section of the cmake-packages(7) manual for discussion of additional care that must be taken when specifying usage requirements while creating packages for redistribution. ¶Target Properties ¶Transitive Usage Requirements ¶Compatible Interface Properties ¶Property Origin Debugging ¶Build Specification with Generator Expressions ¶Include Directories and Usage Requirements ¶Link Libraries and Generator Expressions ¶Output Artifacts ¶Runtime Output Artifacts ¶Library Output Artifacts ¶Archive Output Artifacts ¶Directory-Scoped Commands ¶Pseudo Targets ¶Imported Targets ¶Alias Targets ¶Interface Libraries ¶Reference cmake-buildsystem]]></content>
      <categories>
        <category>translation</category>
        <category>cmake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++函数参数传递详解]]></title>
    <url>%2F2018%2F04-14-Cpp-FunctionParameters%2F</url>
    <content type="text"><![CDATA[转载自 C/C++中函数参数传递详解 ¶参数传递 C++中函数的参数传递方式包括：值传递、指针传递、引用传递这三种方法。下面的代码使用这三种方式，来实现a和b值的交换。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std; //值传递void swap1(int p,int q)&#123; int temp; temp=p; p=q; q=temp;&#125;//指针传递，函数体内只有指针值的变化void swap2(int *p,int *q)&#123; int temp; temp=*p; *p=*q; *q=temp;&#125;//指针传递，函数体内只有指针的变化void swap3(int *p,int *q)&#123; int *temp; temp=p; p=q; q=temp;&#125;//引用传递void swap4(int &amp;p,int &amp;q)&#123; int temp; temp=p; p=q; q=temp;&#125;int main()&#123; int a=1,b=2; swap1(a,b); //swap2(&amp;a,&amp;b); //swap3(&amp;a,&amp;b); //swap4(a,b); cout &lt;&lt; a &lt;&lt; " " &lt;&lt; b&lt;&lt; endl; return 0;&#125; 代码中一共有四个函数，其中有两个是指针传递，但函数体内的实现不一样。下面具体分析： ¶值传递 swap1函数实现的值传递，值传递传递的是实际参数的一个副本，形参p与q的地址和实参a与b的地址不一样，参数传递时只是把a与b的值拷贝过去了，在swap1中对p和q操作只是对临时分配的栈中内容进行操作，函数执行完后形参就消失了，对原来的a和b不产生任何影响。所以swap1不能完成交换a和b值的功能。 ¶指针传递 swap2和swap3都是指针传递，swap2函数体内交换了p和q指向地址的值，swap3函数体内交换了p和q指向的地址。 先说swap2，形参指针p和q指向的是a和b的地址，而不是像值传递那样将实参的值拷贝到另外分配的地址中，运行到函数尾时，指针p和q指向的地址没变，但地址中的值变了，也即a和b地址中的变了，就是a和b的值成功交换。 再来看swap3，swap3运行到函数尾时，p和q交换了地址，但最后函数执行完后，a和b的值并未交换。 swap3中，形参p和q会保存在栈中，p指向a的地址，q指向b的地址，使用temp指针完成了p和q的地址交换，即p指向b的地址，q指向了a的地址，但a和b地址中的值并未发生变化，这与swap2不同，swap2中是p指向的地址中的值(就是a)与q指向的地址中的值(b)交换，所以swap2执行完后a和b的值是交换了的。 ¶引用传递 引用传递时，对形参的操作等同于对实参的操作，即传递的不会是实参的副本，而就是实参。最后会交换a和b的值。 ¶总结 到此，完了。当然函数参数也可以是指向指针的指针，这也是很常见的，但通常用在需要动态分配内存的地方以避免内存泄露。在使用cuda时调用cudaMalloc其参数就是这样，指向指针的指针。而malloc、CPLMolloc、new这些是通过返回值传递分配的动态内存的，自然是不会出现内存泄露的，这个后面再说。 ¶参考 C/C++中函数参数传递详解 C++中函数调用时的三种参数传递方式详解]]></content>
      <categories>
        <category>repost</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++内存分配]]></title>
    <url>%2F2018%2F04-14-Cpp-MemoryAllocation%2F</url>
    <content type="text"><![CDATA[¶C++存储区 栈区：由编译器自动分配释放，存放函数的参数值，局部变量的值等。函数结束后，该变量的存储单元自动释放，效率高，分配的空间有限。 堆区：一般由程序员通过new分配的动态内存单元，并由delete释放，若程序员不释放，程序结束时可能由OS（操作系统）回收。 自由存储区：那些由malloc等分配的内存块，他和堆是十分相似的，不过它是用free来结束自己的生命的。 全局/静态存储区：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。 常量存储区：这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改 ¶堆与栈的区别 ¶参考 What and where are the stack and heap? C++内存分配方式详解(堆、栈、自由存储区、全局/静态存储区和常量存储区) C++五种内存分配、堆与栈区别 C++内存分配机制]]></content>
      <categories>
        <category>knowledge</category>
        <category>coding</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++指针作为函数参数]]></title>
    <url>%2F2018%2F04-14-Cpp-PointerWithinFunctions%2F</url>
    <content type="text"><![CDATA[指针作为函数参数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;using namespace std;int* test1(int* i)&#123; i = new int; *i = 1; return i;&#125;void test2(int* i)&#123; *i = 2;&#125;void test3(int* i)&#123; i = new int; *i = 3;&#125;void test4(int** i)&#123; *i = new int; **i = 4;&#125;void test5(int*&amp; i)&#123; i = new int; *i = 5;&#125;int main()&#123; int *a; a = test1(a); cout &lt;&lt; "test1: " &lt;&lt; *a &lt;&lt; endl; // 1 int *b; b = new int; test2(b); cout &lt;&lt; "test2: " &lt;&lt; *b &lt;&lt; endl; // 2 int *c; test3(c); cout &lt;&lt; "test3: " &lt;&lt; *c &lt;&lt; endl; // Error int *d; test4(&amp;d); cout &lt;&lt; "test4: " &lt;&lt; *d &lt;&lt; endl; // 4 int *e; test5(e); cout &lt;&lt; "test5: " &lt;&lt; *e &lt;&lt; endl; // 5&#125; C++在创建指针的时候，只分配存储地址的内存，并不会分配存储数据的内存，所以指针可能指向任何位置。 test1中，函数形参i只是实参a的拷贝，但在函数内部，我们为i重新分配了地址，然后为这个地址指向的位置赋值为1，然后将这个新分配的地址返回，即赋值给a，此时的a已经不是原来的a了。 test2中，我们首先为实参b分配了一个int内存，然后传入test2，形参i同样是是实参b的拷贝，在函数内部，为i指向的位置赋值2。 test3中，函数形参i只是实参c的一个拷贝，但在函数中，我们为i重新分配了一个int内存，此时i和c指向两个不同的地方，给这个新的位置赋值为3，跟*c没有什么关系。 ¶参考 c++函数中new申请的内存是如何释放的？]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++函数中使用指针]]></title>
    <url>%2F2018%2F04-14-Cpp-PointerAsFunctionParameters%2F</url>
    <content type="text"><![CDATA[转载自c/c++使用指针做函数返回值和指针作函数参数问题 ¶使用指针做函数返回值 1、当使用指针做为函数的返回值时，主函数处的char *p;将获得调用函数char *pf;的值，即一个地址值，如oxAE72。此时需要我们注意的是该地址值所指向的空间是否存在(即已向操作系统声明注册，不会被释放，即可能被其他操作修改)； 2、使用栈内存返回指针是明显错误的，因为栈内存将在调用结束后自动释放，从而主函数使用该地址空间将很危险。 12345678910char* GetMemory()&#123; char p[] = "hi"; return p;&#125;void main()&#123; char *str = GetMemory(); //出错! 得到一块已释放的内存 printf(str);&#125; 3、使用堆内存返回指针是正确的，但是注意可能产生内存泄露问题，在使用完毕后主函数中释放该段内存。 例如： 12345678910char* GetMemory()&#123; char *p = new char[100]; return p;&#125;void main()&#123; char *str = GetMemory(); delete [] str; //防止内存泄露!&#125; ¶使用指针做函数参数 1、有的情况下我们可能需要需要在调用函数中分配内存，而在主函数中使用，而针对的指针此时为函数的参数。此时应注意形参与实参的问题，因为在C语言中，形参只是继承了实参的值，是另外一个量(ps:返回值也是同理，传递了一个地址值(指针)或实数值)，形参的改变并不能引起实参的改变。 2、直接使用形参分配内存的方式显然是错误的，因为实参的值并不会改变，如下则实参一直为NULL: 12345678910void GetMemory(char* p)&#123; char *p = new char[100];&#125;void main()&#123; char *str; GetMemory(str); strcpy(str, "hi"); // str = NULL&#125; 3、由于通过指针是可以传值的，因为此时该指针的地址是在主函数中申请的栈内存，我们通过指针对该栈内存进行操作，从而改变了实参的值。 1234567891011void Change(char *p)&#123; *p = 'b';&#125;void main()&#123; char a = 'a'; char* p = &amp;a; Change(p); printf("%c\n", a); //值a改变!&#125; 4、根据上述的启发，我们也可以采用指向指针的指针来进行在调用函数中申请，在主函数中应用。如下：假设a的地址为ox23，内容为'a'；而str的地址是ox46，内容为ox23；而pstr的地址是ox79，内容为ox46。 我们通过调用函数GetMemory，从而将pstr的内容赋给了p，此时p = ox46。通过对*p(ox23)的操作，即将内存地址为ox23之中的值改为char[100]的首地址，从而完成了对char* str地址的分配。 123456789101112void GetMemory(char** p)&#123; char *p = new char[100];&#125;void main()&#123; char a = 'a'; char* str = &amp;a; char** pstr = &amp;str; GetMemory(pstr); strcpy(str, "hi");&#125; 5、注意指针的释放问题，可能形成悬浮指针。 当我们释放掉一个指针p后，只是告诉操作系统该段内存可以被其他程序使用，而该指针p的地址值(如ox23)仍然存在。如果再次给这块地址赋值是危险的，应该将p指针置为NULL。 调用函数删除主函数中的内存块时，虽然可以通过地址传递直接删除，但由于无法对该指针赋值(形参不能传值)，可能造成悬浮指针，所以此时也应该采用指向指针的指针的形参。 例如： 1234567891011void MemoryFree(char** p)&#123; delete *p; *p = NULL;&#125;void main()&#123; char *str = new char[100]; char *pstr = &amp;str; MemoryFree(pstr);&#125; ¶参考 c/c++使用指针做函数返回值和指针作函数参数问题]]></content>
      <categories>
        <category>repost</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML颜色表]]></title>
    <url>%2F2018%2F04-13-ColorTable%2F</url>
    <content type="text"><![CDATA[¶HTML颜色表 颜色名 十六进制颜色值 颜色 AliceBlue #F0F8FF rgb(240, 248, 255) AntiqueWhite #FAEBD7 rgb(250, 235, 215) Aqua #00FFFF rgb(0, 255, 255) Aquamarine #7FFFD4 rgb(127, 255, 212) Azure #F0FFFF rgb(240, 255, 255) Beige #F5F5DC rgb(245, 245, 220) Bisque #FFE4C4 rgb(255, 228, 196) Black #000000 rgb(0, 0, 0) BlanchedAlmond #FFEBCD rgb(255, 235, 205) Blue #0000FF rgb(0, 0, 255) BlueViolet #8A2BE2 rgb(138, 43, 226) Brown #A52A2A rgb(165, 42, 42) BurlyWood #DEB887 rgb(222, 184, 135) CadetBlue #5F9EA0 rgb(95, 158, 160) Chartreuse #7FFF00 rgb(127, 255, 0) Chocolate #D2691E rgb(210, 105, 30) Coral #FF7F50 rgb(255, 127, 80) CornflowerBlue #6495ED rgb(100, 149, 237) Cornsilk #FFF8DC rgb(255, 248, 220) Crimson #DC143C rgb(220, 20, 60) Cyan #00FFFF rgb(0, 255, 255) DarkBlue #00008B rgb(0, 0, 139) DarkCyan #008B8B rgb(0, 139, 139) DarkGoldenRod #B8860B rgb(184, 134, 11) DarkGray #A9A9A9 rgb(169, 169, 169) DarkGreen #006400 rgb(0, 100, 0) DarkKhaki #BDB76B rgb(189, 183, 107) DarkMagenta #8B008B rgb(139, 0, 139) DarkOliveGreen #556B2F rgb(85, 107, 47) Darkorange #FF8C00 rgb(255, 140, 0) DarkOrchid #9932CC rgb(153, 50, 204) DarkRed #8B0000 rgb(139, 0, 0) DarkSalmon #E9967A rgb(233, 150, 122) DarkSeaGreen #8FBC8F rgb(143, 188, 143) DarkSlateBlue #483D8B rgb(72, 61, 139) DarkSlateGray #2F4F4F rgb(47, 79, 79) DarkTurquoise #00CED1 rgb(0, 206, 209) DarkViolet #9400D3 rgb(148, 0, 211) DeepPink #FF1493 rgb(255, 20, 147) DeepSkyBlue #00BFFF rgb(0, 191, 255) DimGray #696969 rgb(105, 105, 105) DodgerBlue #1E90FF rgb(30, 144, 255) Feldspar #D19275 rgb(209, 146, 117) FireBrick #B22222 rgb(178, 34, 34) FloralWhite #FFFAF0 rgb(255, 250, 240) ForestGreen #228B22 rgb(34, 139, 34) Fuchsia #FF00FF rgb(255, 0, 255) Gainsboro #DCDCDC rgb(220, 220, 220) GhostWhite #F8F8FF rgb(248, 248, 255) Gold #FFD700 rgb(255, 215, 0) GoldenRod #DAA520 rgb(218, 165, 32) Gray #808080 rgb(128, 128, 128) Green #008000 rgb(0, 128, 0) GreenYellow #ADFF2F rgb(173, 255, 47) HoneyDew #F0FFF0 rgb(240, 255, 240) HotPink #FF69B4 rgb(255, 105, 180) IndianRed #CD5C5C rgb(205, 92, 92) Indigo #4B0082 rgb(75, 0, 130) Ivory #FFFFF0 rgb(255, 255, 240) Khaki #F0E68C rgb(240, 230, 140) Lavender #E6E6FA rgb(230, 230, 250) LavenderBlush #FFF0F5 rgb(255, 240, 245) LawnGreen #7CFC00 rgb(124, 252, 0) LemonChiffon #FFFACD rgb(255, 250, 205) LightBlue #ADD8E6 rgb(173, 216, 230) LightCoral #F08080 rgb(240, 128, 128) LightCyan #E0FFFF rgb(224, 255, 255) LightGoldenRodYellow #FAFAD2 rgb(250, 250, 210) LightGrey #D3D3D3 rgb(211, 211, 211) LightGreen #90EE90 rgb(144, 238, 144) LightPink #FFB6C1 rgb(255, 182, 193) LightSalmon #FFA07A rgb(255, 160, 122) LightSeaGreen #20B2AA rgb(32, 178, 170) LightSkyBlue #87CEFA rgb(135, 206, 250) LightSlateBlue #8470FF rgb(132, 112, 255) LightSlateGray #778899 rgb(119, 136, 153) LightSteelBlue #B0C4DE rgb(176, 196, 222) LightYellow #FFFFE0 rgb(255, 255, 224) Lime #00FF00 rgb(0, 255, 0) LimeGreen #32CD32 rgb(50, 205, 50) Linen #FAF0E6 rgb(250, 240, 230) Magenta #FF00FF rgb(255, 0, 255) Maroon #800000 rgb(128, 0, 0) MediumAquaMarine #66CDAA rgb(102, 205, 170) MediumBlue #0000CD rgb(0, 0, 205) MediumOrchid #BA55D3 rgb(186, 85, 211) MediumPurple #9370D8 rgb(147, 112, 216) MediumSeaGreen #3CB371 rgb(60, 179, 113) MediumSlateBlue #7B68EE rgb(123, 104, 238) MediumSpringGreen #00FA9A rgb(0, 250, 154) MediumTurquoise #48D1CC rgb(72, 209, 204) MediumVioletRed #C71585 rgb(199, 21, 133) MidnightBlue #191970 rgb(25, 25, 112) MintCream #F5FFFA rgb(245, 255, 250) MistyRose #FFE4E1 rgb(255, 228, 225) Moccasin #FFE4B5 rgb(255, 228, 181) NavajoWhite #FFDEAD rgb(255, 222, 173) Navy #000080 rgb(0, 0, 128) OldLace #FDF5E6 rgb(253, 245, 230) Olive #808000 rgb(128, 128, 0) OliveDrab #6B8E23 rgb(107, 142, 35) Orange #FFA500 rgb(255, 165, 0) OrangeRed #FF4500 rgb(255, 69, 0) Orchid #DA70D6 rgb(218, 112, 214) PaleGoldenRod #EEE8AA rgb(238, 232, 170) PaleGreen #98FB98 rgb(152, 251, 152) PaleTurquoise #AFEEEE rgb(175, 238, 238) PaleVioletRed #D87093 rgb(216, 112, 147) PapayaWhip #FFEFD5 rgb(255, 239, 213) PeachPuff #FFDAB9 rgb(255, 218, 185) Peru #CD853F rgb(205, 133, 63) Pink #FFC0CB rgb(255, 192, 203) Plum #DDA0DD rgb(221, 160, 221) PowderBlue #B0E0E6 rgb(176, 224, 230) Purple #800080 rgb(128, 0, 128) Red #FF0000 rgb(255, 0, 0) RosyBrown #BC8F8F rgb(188, 143, 143) RoyalBlue #4169E1 rgb(65, 105, 225) SaddleBrown #8B4513 rgb(139, 69, 19) Salmon #FA8072 rgb(250, 128, 114) SandyBrown #F4A460 rgb(244, 164, 96) SeaGreen #2E8B57 rgb(46, 139, 87) SeaShell #FFF5EE rgb(255, 245, 238) Sienna #A0522D rgb(160, 82, 45) Silver #C0C0C0 rgb(192, 192, 192) SkyBlue #87CEEB rgb(135, 206, 235) SlateBlue #6A5ACD rgb(106, 90, 205) SlateGray #708090 rgb(112, 128, 144) Snow #FFFAFA rgb(255, 250, 250) SpringGreen #00FF7F rgb(0, 255, 127) SteelBlue #4682B4 rgb(70, 130, 180) Tan #D2B48C rgb(210, 180, 140) Teal #008080 rgb(0, 128, 128) Thistle #D8BFD8 rgb(216, 191, 216) Tomato #FF6347 rgb(255, 99, 71) Turquoise #40E0D0 rgb(64, 224, 208) Violet #EE82EE rgb(238, 130, 238) VioletRed #D02090 rgb(208, 32, 144) Wheat #F5DEB3 rgb(245, 222, 179) White #FFFFFF rgb(255, 255, 255) WhiteSmoke #F5F5F5 rgb(245, 245, 245) Yellow #FFFF00 rgb(255, 255, 0) YellowGreen #9ACD32 rgb(154, 205, 50) ¶生成代码 123456789101112131415161718#-*- coding:utf-8 -*-fin = open('color.txt', 'r')inLines = fin.readlines() #按行读出文件内容fin.close()outTxt = ''for line in inLines: temp1 = line.strip('\n') #去掉每行最后的换行符'\n' temp2 = temp1.split('\t') #以'\t'为标志，将每行分割成列表 # print(temp2[0]) outLine = '&lt;span style="color:' + temp2[0] + '"&gt;' + temp2[0] + '&lt;/span&gt; | ' outLine = outLine + '&lt;span style="color:' + temp2[0] + '"&gt;' + temp2[1] + '&lt;/span&gt; | ' outLine = outLine + '&lt;span style="background-color:' + temp2[0] + '"&gt;' + temp2[2] + '&lt;/span&gt;\n' outTxt = outTxt + outLinefout = open('color-1.txt', 'w')fout.write(outTxt)fout.close() ¶参考 CSDN-markdown编辑器语法——字体、字号与颜色 python读取txt文件到列表中]]></content>
      <categories>
        <category>knowledge</category>
        <category>miscellaneous</category>
      </categories>
      <tags>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown Tips]]></title>
    <url>%2F2018%2F04-12-MD-MarkdownTips%2F</url>
    <content type="text"><![CDATA[¶字体 ¶字体颜色 ¶内嵌HTML标签 &lt;span style=&quot;color:red&quot;&gt;Aquamarine&lt;/span&gt; =&gt; Aquamarine &lt;span style=&quot;background-color:MistyRose&quot;&gt;Aquamarine&lt;/span&gt; =&gt; Aquamarine ¶借助MathJax $\color{blue}{MathJax}$ =&gt; $\color{blue}{MathJax}$ $\color{blue}\text{MathJax}$ =&gt; $\color{blue}\text{MathJax}$ $\text{\color{blue}{MathJax}}$ =&gt; $\text{\color{blue}{MathJax}}$ ¶字体大小 &lt;span style=&quot;font-size: 120%;&quot;&gt;1.2 larger text&lt;/span&gt; =&gt; 1.2 larger text &lt;span style=&quot;font-size: 80%;&quot;&gt;0.8 smaller text&lt;/span&gt; =&gt; 0.8 smaller text ¶同时设置[3] &lt;span style=&quot;color:red; background-color:lightgray; font-size: 120%; text-align: center;&quot;&gt;Test Text&lt;/span&gt; =&gt; Test Text ¶表格 ¶表格内容位置 内容居左 内容居中 内容居右 A A A B B B ¶参考 为什么markdown不支持字号和字体颜色？ CSDN-markdown编辑器语法——字体、字号与颜色 Jekyll kramdown how to center text]]></content>
      <categories>
        <category>tools</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>writing</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS静态库与动态库]]></title>
    <url>%2F2018%2F04-10-Mac-StaticAndDynamicLibrary%2F</url>
    <content type="text"><![CDATA[¶Static Library(.a) Static libraries allow an application to load code into its address space at compile time.This results in a larger size on disk and slower launch times. Because the library’s code is added directly to the linked target’s binary, it means that to update any code in the library, the linked target would also have to be rebuilt. ¶Dynamic Library(.dylib) Dynamic libraries allow an application to load code into its address space when it’s actually needed at run time. Because the code isn’t statically linked into the executable binary, there are some benefits from loading at runtime. Mainly, the libraries can be updated with new features or bug-fixes without having to recompile and relink executable. In addition, being loaded at runtime means that individual code libraries can have their own initializers and clean up after their own tasks before being unloaded from memory ¶Link Library with CMake CMake favours passing the full path to link libraries Assuming libfoo.a is in ${CMAKE_SOURCE_DIR}, to link the library using: 12add_executable(main main.cpp)target_link_libraries(main $&#123;CMAKE_SOURCE_DIR&#125;/libfoo.a) The same for dynamic library: 1234add_executable(main main.cpp)target_link_libraries(main /usr/local/Cellar/open-mesh/6.3/lib/libOpenMeshTools.6.3.dylib /usr/local/Cellar/open-mesh/6.3/lib/libOpenMeshCore.6.3.dylib) ¶Reference What is the difference between .dylib and .a lib in ios? How do I tell CMake to link in a static library in the source directory?]]></content>
      <categories>
        <category>knowledge</category>
        <category>coding</category>
      </categories>
      <tags>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMake Tutorial]]></title>
    <url>%2F2018%2F04-07-Cpp-CMakeTutorial%2F</url>
    <content type="text"><![CDATA[翻译自cmake-tutorial ¶A Basic Starting Point (Step1) 一个最基本的项目是由一些源代码文件构建得到的可执行文件，对于一个简单的项目，只需要一个三行的CMakeLists.txt文件，这个文件也将是本教程的出发点。这样一个CMakeLists.txt文件像下面这样： 123cmake_minimum_required (VERSION 2.6)project (Tutorial)add_executable(Tutorial tutorial.cxx) 注意这个例子中的CMakeLists.txt文件使用了小写字母的命令，CMake支持大写、小写、混合字母的命令。源代码tutorial.cxx计算一个数字的平方根，第一个版本非常简单，如下所示： 12345678910111213141516// A simple program that computes the square root of a number#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;int main (int argc, char *argv[])&#123; if (argc &lt; 2) &#123; fprintf(stdout,"Usage: %s number\n",argv[0]); return 1; &#125; double inputValue = atof(argv[1]); double outputValue = sqrt(inputValue); fprintf(stdout,"The square root of %g is %g\n", inputValue, outputValue); return 0;&#125; ¶Adding a Version Number and Configured Header File 这里要添加的第一个特性是为可执行文件和项目提供一个版本号，虽然这可以在源代码中完成，但在CMakeLists.txt中添加更加具有灵活性，只需简单修改CMakeLists.txt文件便可以添加一个版本号，这里将其做如下修改： 123456789101112131415161718cmake_minimum_required (VERSION 2.6)project (Tutorial)# The version number.set (Tutorial_VERSION_MAJOR 1)set (Tutorial_VERSION_MINOR 0)# configure a header file to pass some of the CMake settings to the source codeconfigure_file ( "$&#123;PROJECT_SOURCE_DIR&#125;/TutorialConfig.h.in" "$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h" )# add the binary tree to the search path for include files# so that we will find TutorialConfig.hinclude_directories("$&#123;PROJECT_BINARY_DIR&#125;")# add the executableadd_executable(Tutorial tutorial.cxx) 由于配置文件将被写入二进制树(binary tree)，所以必须将该文件路径添加到搜索路径中以包含这些文件。然后在源代码树(source tree)中创建一个包含以下内容的TutorialConfig.h.in文件： 123// the configured options and settings for Tutorial#define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@#define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@ 当CMake配置该头文件时，@Tutorial_VERSION_MAJOR@和@Tutorial_VERSION_MINOR@的值将会被替换为CMakeLists.txt文件中定义的值，接下来在tutorial.cxx文件中包含配置头文件以使用版本号，修改后的源代码如下所示： 1234567891011121314151617181920212223// A simple program that computes the square root of a number#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#include "TutorialConfig.h"int main (int argc, char *argv[])&#123; if (argc &lt; 2) &#123; fprintf(stdout,"%s Version %d.%d\n", argv[0], Tutorial_VERSION_MAJOR, Tutorial_VERSION_MINOR); fprintf(stdout,"Usage: %s number\n",argv[0]); return 1; &#125; double inputValue = atof(argv[1]); double outputValue = sqrt(inputValue); fprintf(stdout,"The square root of %g is %g\n", inputValue, outputValue); return 0;&#125; 主要的改变是添加了头文件TutorialConfig.h的包含，并将版本号作为使用信息的一部分输出到屏幕。 ¶Adding a Library (Step 2) 现在需要添加一个库到项目中，这个库包含了平方根计算的实现，可执行文件便可以使用这个库，而不去使用编译器提供的平方根计算函数。本教程将把这个库放在一个叫MathFunctions的子文件夹中，CMakeLists.txt文件需要有下面这样一行： 1add_library(MathFunctions mysqrt.cxx) 源文件mysqrt.cxx有一个叫mysqrt的函数，拥有跟编译器自带的sqrt函数同样的功能，为了使用这个新库，需要在CMakeLists.txt文件的上一层添加add_subdirectory的调用，以让该库得到构建。此外还添加一个包含路径来让该函数能够找到MathFunctions/MathFunctions.h头文件，最后一点需要改变的是添加这个新的库到可执行文件。现在CMakeLists.txt文件中的最后几行如下所示： 123456include_directories ("$&#123;PROJECT_SOURCE_DIR&#125;/MathFunctions")add_subdirectory (MathFunctions)# add the executableadd_executable (Tutorial tutorial.cxx)target_link_libraries (Tutorial MathFunctions) 接下来考虑将MathFunctions库设置为可选的，在本教程中虽然没有必要这样做，但在使用更大的库，或者库依赖第三方代码时可能需要这样去做。首先需要在CMakeLists.txt文件的前面添加一个选项。 123# should we use our own math functions?option (USE_MYMATH "Use tutorial provided math implementation" ON) 这个选项将在CMake GUI中出现，且默认值为ON，并且用户可以自己修改这个值。这个设置会被存储在缓存中，所以用户不用在每次用CMake运行这个项目时都来设置。接下来需要进一步将关于MathFunctions库的构建和链接设置为可选，只需将CMakeLists.txt文件按如下示例更改： 1234567891011# add the MathFunctions library?#if (USE_MYMATH) include_directories ("$&#123;PROJECT_SOURCE_DIR&#125;/MathFunctions") add_subdirectory (MathFunctions) set (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; MathFunctions)endif (USE_MYMATH)# add the executableadd_executable (Tutorial tutorial.cxx)target_link_libraries (Tutorial $&#123;EXTRA_LIBS&#125;) 这里使用USE_MYMATH的设置来决定MathFunctions是否被编译与使用，注意这里使用变量EXTRA_LIBS来收集所有可选的库来在后面链接到可执行文件，这是一个保持有许多可选部件的大项目干净的通用方法。源代码对应的改变非常直观明了： 1234567891011121314151617181920212223242526272829303132// A simple program that computes the square root of a number#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#include "TutorialConfig.h"#ifdef USE_MYMATH#include "MathFunctions.h"#endifint main (int argc, char *argv[])&#123; if (argc &lt; 2) &#123; fprintf(stdout,"%s Version %d.%d\n", argv[0], Tutorial_VERSION_MAJOR, Tutorial_VERSION_MINOR); fprintf(stdout,"Usage: %s number\n",argv[0]); return 1; &#125; double inputValue = atof(argv[1]);#ifdef USE_MYMATH double outputValue = mysqrt(inputValue);#else double outputValue = sqrt(inputValue);#endif fprintf(stdout,"The square root of %g is %g\n", inputValue, outputValue); return 0;&#125; 在源代码中同样使用USE_MYMATH，它是CMake通过配置文件TutorialConfig.h.in提供给源代码的，只需在配置文件中添加下面一行： 1#cmakedefine USE_MYMATH ¶Installing and Testing (Step 3) 接下来添加安装规则(Install Rules)和测试(Testing)支持到项目中，安装规则非常直接明了，对于MathFunctions库，可以通过在MathFunctions的CMakeLists.txt文件中添加下面两行代码来安装库和头文件： 12install (TARGETS MathFunctions DESTINATION bin)install (FILES MathFunctions.h DESTINATION include) 对于应用程序，通过在CMakeLists.txt文件的前面添加下面几行来安装可执行文件和配置头文件： 1234# add the install targetsinstall (TARGETS Tutorial DESTINATION bin)install (FILES "$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h" DESTINATION include) 这便是全部内容，现在便可以构建这个教程，然后输入make install或者从IDE构建INSTALL目标，便可以安装合适的头文件、库文件和可执行文件。CMake变量CMAKE_INSTALL_PREFIX将决定这些文件安装的根目录。 添加测试同样也是一个非常简单直接的过程，通过在CMakeLists.txt文件的末尾添加一些基础测试来检验应用程序是否正常工作。 12345678910111213141516include(CTest)# does the application runadd_test (TutorialRuns Tutorial 25)# does it sqrt of 25add_test (TutorialComp25 Tutorial 25)set_tests_properties (TutorialComp25 PROPERTIES PASS_REGULAR_EXPRESSION "25 is 5")# does it handle negative numbersadd_test (TutorialNegative Tutorial -25)set_tests_properties (TutorialNegative PROPERTIES PASS_REGULAR_EXPRESSION "-25 is 0")# does it handle small numbersadd_test (TutorialSmall Tutorial 0.0001)set_tests_properties (TutorialSmall PROPERTIES PASS_REGULAR_EXPRESSION "0.0001 is 0.01")# does the usage message work?add_test (TutorialUsage Tutorial)set_tests_properties (TutorialUsage PROPERTIES PASS_REGULAR_EXPRESSION "Usage:.*number") 构建以后在命令行工具中输入ctest便可以运行所有测试，第一个测试验证程序是否能够正常运行，不会出现段错误(segfault)或者崩溃(crash)，能够返回0，这是CTest测试最基本的形式。接下来的几个测试适当地使用PASS_REGULAR_EXPRESSION测试属性来验证测试的输出结构是否包含特定的字符串。在这个例子中即验证计算的平方根是否正确，当提供错误的参数时将使用信息打印到屏幕。如果需要添加许多测试来检测不同的输入值，可以考虑定义一个下面这样的宏： 12345678910#define a macro to simplify adding tests, then use itmacro (do_test arg result) add_test (TutorialComp$&#123;arg&#125; Tutorial $&#123;arg&#125;) set_tests_properties (TutorialComp$&#123;arg&#125; PROPERTIES PASS_REGULAR_EXPRESSION $&#123;result&#125;)endmacro (do_test)# do a bunch of result based testsdo_test (25 "25 is 5")do_test (-25 "-25 is 0") 这样对于do_test的每一次调用，一个新的测试便被添加到项目中，名字、输入、结果便是传入的相关参数。 ¶Adding System Introspection (Step 4) 下面考虑向项目中添加一些代码，而这些代码取决于目标平台可能没有的特性。对于这个例子，这里将根据目标平台是否有log和exp函数来添加一些代码，当然，几乎所有的平台都包含这两个函数，但这个教程假设目标平台不是常见的那些。如果平台有log函数，则直接在mysqrt函数中使用这个函数计算平方根。这里首先在CMakeLists.txt文件中利用CheckFunctionExists.cmake宏来测试这些函数的可用性： 1234# does this system provide the log and exp functions?include (CheckFunctionExists)check_function_exists (log HAVE_LOG)check_function_exists (exp HAVE_EXP) 然后修改TutorialConfig.h.in文件，如果CMake在平台找到这些函数则定义相应的值，如下所示： 123// does the platform provide exp and log functions?#cmakedefine HAVE_LOG#cmakedefine HAVE_EXP 很重要的一点，函数log和exp的可用性测试需要在TutorialConfig.h文件的configure_file命令调用前完成，configure_file命令立即在CMake中用当前的设置配置文件。最后在mysqrt函数中添加一个基于log和exp函数的替代实现，如果系统可以获取这两个函数，具体代码如下： 12345// if we have both log and exp then use them#if defined (HAVE_LOG) &amp;&amp; defined (HAVE_EXP) result = exp(log(x)*0.5);#else // otherwise use an iterative approach . . . ¶Adding a Generated File and Generator (Step 5) 这一小节介绍怎样在一个应用程序的构建过程中添加生成的源代码，这个例子将创建一个表，表中存储一些预先计算好的平方根作为构建过程的一部分，然后将这个表编译进应用程序。首先需要一个程序来生成这个表，在MathFunctions子文件夹，一个叫MakeTable.cxx的新的源文件会完成这个工作： 123456789101112131415161718192021222324252627282930313233343536// A simple program that builds a sqrt table#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;int main (int argc, char *argv[])&#123; int i; double result; // make sure we have enough arguments if (argc &lt; 2) &#123; return 1; &#125; // open the output file FILE *fout = fopen(argv[1],"w"); if (!fout) &#123; return 1; &#125; // create a source file with a table of square roots fprintf(fout,"double sqrtTable[] = &#123;\n"); for (i = 0; i &lt; 10; ++i) &#123; result = sqrt(static_cast&lt;double&gt;(i)); fprintf(fout,"%g,\n",result); &#125; // close the table with a zero fprintf(fout,"0&#125;;\n"); fclose(fout); return 0;&#125; 注意这个表是通过一个有效的C++代码生成的，输出文件的文件名由传入的参数确定。接下来要添加合适的命令到MathFunctions的CMakeLists.txt文件中来构建MakeTable可执行文件，然后将其作为构建过程的一部分。下面是完成这些所需要的一些命令： 123456789101112131415# first we add the executable that generates the tableadd_executable(MakeTable MakeTable.cxx)# add the command to generate the source codeadd_custom_command ( OUTPUT $&#123;CMAKE_CURRENT_BINARY_DIR&#125;/Table.h COMMAND MakeTable $&#123;CMAKE_CURRENT_BINARY_DIR&#125;/Table.h DEPENDS MakeTable )# add the binary tree directory to the search path for include filesinclude_directories( $&#123;CMAKE_CURRENT_BINARY_DIR&#125; )# add the main libraryadd_library(MathFunctions mysqrt.cxx $&#123;CMAKE_CURRENT_BINARY_DIR&#125;/Table.h ) 首先，MakeTable的可执行文件跟其他可执行文件的添加方式一样，然后添加一个自定义命令(custom command)来具体说明怎样通过运行MakeTable来生成Table.h，接下来必须让CMake知道mysqrt.cxx依赖于生成的Table.h文件，具体通过将生成的Table.h文件添加到MathFunctions库的源文件代码列表中完成。此外还必须将当前的二进制路径添加到包含文件的列表中，以让Table.h文件能够被mysqrt.cxx找到并包含。当这个项目被构建时，首先会构建MakeTable可执行文件，然后运行MakeTable生成Table.h，最后再编译包含有Table.h的mysqrt.cxx来生成MathFunctions库。现在拥有这些已添加的特性的CMakeLists.txt文件如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172cmake_minimum_required (VERSION 2.6)project (Tutorial)include(CTest)# The version number.set (Tutorial_VERSION_MAJOR 1)set (Tutorial_VERSION_MINOR 0)# does this system provide the log and exp functions?include ($&#123;CMAKE_ROOT&#125;/Modules/CheckFunctionExists.cmake)check_function_exists (log HAVE_LOG)check_function_exists (exp HAVE_EXP)# should we use our own math functionsoption(USE_MYMATH "Use tutorial provided math implementation" ON)# configure a header file to pass some of the CMake settings# to the source codeconfigure_file ( "$&#123;PROJECT_SOURCE_DIR&#125;/TutorialConfig.h.in" "$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h" )# add the binary tree to the search path for include files# so that we will find TutorialConfig.hinclude_directories ("$&#123;PROJECT_BINARY_DIR&#125;")# add the MathFunctions library?if (USE_MYMATH) include_directories ("$&#123;PROJECT_SOURCE_DIR&#125;/MathFunctions") add_subdirectory (MathFunctions) set (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; MathFunctions)endif (USE_MYMATH)# add the executableadd_executable (Tutorial tutorial.cxx)target_link_libraries (Tutorial $&#123;EXTRA_LIBS&#125;)# add the install targetsinstall (TARGETS Tutorial DESTINATION bin)install (FILES "$&#123;PROJECT_BINARY_DIR&#125;/TutorialConfig.h" DESTINATION include)# does the application runadd_test (TutorialRuns Tutorial 25)# does the usage message work?add_test (TutorialUsage Tutorial)set_tests_properties (TutorialUsage PROPERTIES PASS_REGULAR_EXPRESSION "Usage:.*number" )#define a macro to simplify adding testsmacro (do_test arg result) add_test (TutorialComp$&#123;arg&#125; Tutorial $&#123;arg&#125;) set_tests_properties (TutorialComp$&#123;arg&#125; PROPERTIES PASS_REGULAR_EXPRESSION $&#123;result&#125; )endmacro (do_test)# do a bunch of result based testsdo_test (4 "4 is 2")do_test (9 "9 is 3")do_test (5 "5 is 2.236")do_test (7 "7 is 2.645")do_test (25 "25 is 5")do_test (-25 "-25 is 0")do_test (0.0001 "0.0001 is 0.01") TutorialConfig.h.in文件如下： 12345678// the configured options and settings for Tutorial#define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@#define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@#cmakedefine USE_MYMATH// does the platform provide exp and log functions?#cmakedefine HAVE_LOG#cmakedefine HAVE_EXP MathFunctions的CMakeLists.txt文件如下所示： 1234567891011121314151617# first we add the executable that generates the tableadd_executable(MakeTable MakeTable.cxx)# add the command to generate the source codeadd_custom_command ( OUTPUT $&#123;CMAKE_CURRENT_BINARY_DIR&#125;/Table.h DEPENDS MakeTable COMMAND MakeTable $&#123;CMAKE_CURRENT_BINARY_DIR&#125;/Table.h )# add the binary tree directory to the search path# for include filesinclude_directories( $&#123;CMAKE_CURRENT_BINARY_DIR&#125; )# add the main libraryadd_library(MathFunctions mysqrt.cxx $&#123;CMAKE_CURRENT_BINARY_DIR&#125;/Table.h)install (TARGETS MathFunctions DESTINATION bin)install (FILES MathFunctions.h DESTINATION include) ¶Building an Installer (Step 6) 接下来假设需要将项目发布给其他人使用，需要在众多平台提供二进制和源代码发布包，这和在前面第三节讲的安装从源代码构建得到的二进制文件还有一点区别。这个例子将讲解如何构建安装包，并支持二进制安装和包管理这些在cygwin、debian、RPMs等平台都拥有的特性。为了达到这个目的，这里使用CPack来生成各个平台的安装程序，在Chapter Packaging with CPack有介绍。具体来说，在CMakeLists.txt文件的底部需要加下面几行代码： 1234567# build a CPack driven installer packageinclude (InstallRequiredSystemLibraries)set (CPACK_RESOURCE_FILE_LICENSE "$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/License.txt")set (CPACK_PACKAGE_VERSION_MAJOR "$&#123;Tutorial_VERSION_MAJOR&#125;")set (CPACK_PACKAGE_VERSION_MINOR "$&#123;Tutorial_VERSION_MINOR&#125;")include (CPack) 上面就是需要添加的东西，这里首先包含InstallRequiredSystemLibraries，这个模块将包含项目在当前平台所需要的所有运行库(runtime libraries)，接下来设置一些CPack变量，包括许可协议和项目的版本信息，版本信息利用教程前面设置的变量。最后再包含CPack模块，CPack将使用这些变量和当前系统的一些特性来设置安装程序。 下一步便使用通常的方法构建项目，然后运行CPack。要构建一个二进制发布包(binary distribution)使用如下命令： 1cpack --config CPackConfig.cmake 要生成一个源代码发布包(source distribution)需要输入如下命令： 1cpack --config CPackSourceConfig.cmake ¶Adding Support for a Dashboard (Step 7) 增加提交测试结果到仪表板(dashboard)的支持非常简单，前面的教程已经在项目中定义了许多测试，现在只需运行这些测试然后提交到仪表板。为了添加仪表板的支持，首先需要在CMakeLists.txt文件的前面包含CTest模块： 12# enable dashboard scriptinginclude (CTest) 然后创建一个CTestConfig.cmake文件，并在里面设置这个项目在仪表板中的名字： 1set (CTEST_PROJECT_NAME "Tutorial") CTest在运行时会读入这个文件。如果想创建一个简单的仪表板，可以在项目中运行CMake，然后将路径切换到二进制树目录，运行ctest –D Experimental命令，仪表板的结果会被上传到Kitware的公共仪表板。 ¶参考 cmake-tutorial cmake-tutorial-code]]></content>
      <categories>
        <category>translation</category>
        <category>cmake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenCV 图片的读取与存储]]></title>
    <url>%2F2018%2F04-07-CV-OpenCVImageIO%2F</url>
    <content type="text"><![CDATA[翻译自OpenCV 3.1.0 Docs - Image file reading and writing ¶Enumerations ¶Imread flags 123456789101112131415enum cv::ImreadModes&#123; cv::IMREAD_UNCHANGED = -1, // 导入原始图片，包括透明度通道 cv::IMREAD_GRAYSCALE = 0, // 图片转化为单通道灰度图 cv::IMREAD_COLOR = 1, // 图片转化为三通道*BGR*图片 cv::IMREAD_ANYDEPTH = 2, // 若输入图片是16或32位深度图直接读入，否则转化位8位深度图 cv::IMREAD_ANYCOLOR = 4, // 任何形式的图片格式都直接读入 cv::IMREAD_LOAD_GDAL = 8, // 使用GDAL驱动读入图片 cv::IMREAD_REDUCED_GRAYSCALE_2 = 16, // 图片转化位单通道灰度图，尺寸缩小1/2 cv::IMREAD_REDUCED_COLOR_2 = 17, // 图片转化为三通道BGR图，尺寸缩小1/2 cv::IMREAD_REDUCED_GRAYSCALE_4 = 32, // 图片转化位单通道灰度图，尺寸缩小1/4 cv::IMREAD_REDUCED_COLOR_4 = 33, // 图片转化为三通道BGR图，尺寸缩小1/4 cv::IMREAD_REDUCED_GRAYSCALE_8 = 64, // 图片转化位单通道灰度图，尺寸缩小1/8 cv::IMREAD_REDUCED_COLOR_8 = 65 // 图片转化为三通道BGR图，尺寸缩小1/8&#125; ¶Imwrite flags 1234567891011121314enum cv::ImwriteFlags&#123; cv::IMWRITE_JPEG_QUALITY = 1, // 存为JPEG图片，质量从0到100，默认95 cv::IMWRITE_JPEG_PROGRESSIVE = 2, // 使用JPEG特性，0或1，默认FALSE cv::IMWRITE_JPEG_OPTIMIZE = 3, // 使用JPEG特性，0或1，默认FALSE cv::IMWRITE_JPEG_RST_INTERVAL = 4, // JPEG restart interval, 0 - 65535, default is 0 - no restart. cv::IMWRITE_JPEG_LUMA_QUALITY = 5, // 单独的亮度质量水平，从0到100，默认0，不使用 cv::IMWRITE_JPEG_CHROMA_QUALITY = 6,// 单独的色度质量水平，从0到100，默认0，不使用 cv::IMWRITE_PNG_COMPRESSION = 16, // 对于PNG图片， 压缩水平从0到9，值越大图片越小，默认3， cv::IMWRITE_PNG_STRATEGY = 17, // One of cv::ImwritePNGFlags, default is IMWRITE_PNG_STRATEGY_DEFAULT. cv::IMWRITE_PNG_BILEVEL = 18, // Binary level PNG, 0 or 1, default is 0. cv::IMWRITE_PXM_BINARY = 32, // For PPM, PGM, or PBM, it can be a binary format flag, 0 or 1. Default value is 1. cv::IMWRITE_WEBP_QUALITY = 64 // For WEBP, it can be a quality from 1 to 100 (the higher is the better). By default (without any parameter) and for quality above 100 the lossless compression is used.&#125; ¶Imwrite PNG specific flags 这些flags会修改PNG图片压缩的方式，并被传递到接下来zlib处理阶段。 IMWRITE_PNG_STRATEGY_FILTERED的效果force more Huffman coding and less string matching，处于IMWRITE_PNG_STRATEGY_DEFAULT和IMWRITE_PNG_STRATEGY_HUFFMAN_ONLY之间。 IMWRITE_PNG_STRATEGY_RLE的速度几乎和IMWRITE_PNG_STRATEGY_HUFFMAN_ONLY一样快，但对于PNG图片有更好的压缩效果。 策略参数(strategy parameter)只影响压缩率，不影响压缩后数据的正确性。 IMWRITE_PNG_STRATEGY_FIXED避免dynamic Huffman codes，对特殊的应用允许简单的解码器。 1234567891011enum cv::ImwritePNGFlags&#123; cv::IMWRITE_PNG_STRATEGY_DEFAULT = 0, // Use this value for normal data cv::IMWRITE_PNG_STRATEGY_FILTERED = 1, // Use this value for data produced by a filter (or predictor). // Filtered data consists mostly of small values with a somewhat random distribution. // In this case, the compression algorithm is tuned to compress them better. cv::IMWRITE_PNG_STRATEGY_HUFFMAN_ONLY = 2, // Use this value to force Huffman encoding only (no string match) cv::IMWRITE_PNG_STRATEGY_RLE = 3, // Use this value to limit match distances to one (run-length encoding) cv::IMWRITE_PNG_STRATEGY_FIXED = 4 // Using this value prevents the use of dynamic Huffman codes, // allowing for a simpler decoder for special applications&#125; ¶Functions ¶imdecode &amp; imencode 函数cv::imdecode从内存中的缓存读取图片，如果缓存太短或包含不合法的数据，则返回一个空矩阵，即Mat::data==NULL。 注意对于彩色图片，颜色通道安装B G R的顺序存储。 1234Mat cv::imdecode( InputArray buf, // input array or vector of bytes. int flags // The same flags as in cv::imread) 下面是为了方便定义的一个重载函数，区别主要是接收的参数。 1234567Mat cv::imdecode( InputArray buf, int flags, Mat* dst // The optional output placeholder for the decoded matrix. // It can save the image reallocations when the function is // called repeatedly for images of the same size.) 函数cv::imencode压缩图片并将其存储在合适大小的内存缓冲区，支持的图片格式和flags描述见函数cv::imwrite。 123456bool cv::imencode( const String&amp; ext, // File extension that defines the output format. InputArray img, // Image to be written. std::vector&lt;uchar&gt;&amp; buf, // Output buffer resized to fit the compressed image. const std::vector&lt;int&gt;&amp; params = std::vector&lt;int&gt;() // Format-specific parameters. See cv::imwrite and cv::ImwriteFlags.) ¶imread &amp; imwrite 函数cv::imread从给定的文件中读取并返回图片，如果图片不能被正确读取（由于文件丢失，没有读取权限，不支持或不合法的格式等等），函数返回一个空矩阵，即Mat::data==NULL。 1234Mat cv::imread( const String&amp; filename, // Name of file to be loaded. int flags = IMREAD_COLOR // Flag that can take values of cv::ImreadModes) 目前支持的格式包括： Windows bitmaps - *.bmp, *.dib (always supported) JPEG files - *.jpeg, *.jpg, *.jpe (see the Notes section) JPEG 2000 files - *.jp2 (see the Notes section) Portable Network Graphics - *.png (see the Notes section) WebP - *.webp (see the Notes section) Portable image format - *.pbm, *.pgm, *.ppm *.pxm, *.pnm (always supported) Sun rasters - *.sr, *.ras (always supported) TIFF files - *.tiff, *.tif (see the Notes section) OpenEXR Image files - *.exr (see the Notes section) Radiance HDR - *.hdr, *.pic (always supported) Raster and Vector geospatial data supported by Gdal (see the Notes section) 注意： The function determines the type of an image by the content, not by the file extension. In the case of color images, the decoded images will have the channels stored in B G R order. On Microsoft Windows* OS and MacOSX*, the codecs shipped with an OpenCV image (libjpeg, libpng, libtiff, and libjasper) are used by default. So, OpenCV can always read JPEGs, PNGs, and TIFFs. On MacOSX, there is also an option to use native MacOSX image readers. But beware that currently these native image loaders give images with different pixel values because of the color management embedded into MacOSX. On Linux*, BSD flavors and other Unix-like open-source operating systems, OpenCV looks for codecs supplied with an OS image. Install the relevant packages (do not forget the development files, for example, “libjpeg-dev”, in Debian* and Ubuntu*) to get the codec support or turn on the OPENCV_BUILD_3RDPARTY_LIBS flag in CMake. In the case you set WITH_GDAL flag to true in CMake and IMREAD_LOAD_GDAL to load the image, then GDAL driver will be used in order to decode the image by supporting the following formats: Raster, Vector. 函数cv::imreadmulti从给定的文件读入multi-page image并存储在一个包含Mat的std::vector对象中。 12345bool cv::imreadmulti( const String &amp; filename, // Name of file to be loaded. std::vector&lt;Mat&gt; &amp; mats, // Flag that can take values of cv::ImreadModes, default with cv::IMREAD_ANYCOLOR. int flags = IMREAD_ANYCOLOR // A vector of Mat objects holding each page, if more than one.) 函数cv::imwrite将图片保存到给定的文件中，图片格式根据文件的扩展名确定，只有8-bit (or 16-bit unsigned (CV_16U) in case of PNG, JPEG 2000, and TIFF) single-channel or 3-channel (with 'BGR' channel order) images能够使用这个函数保存。如果格式format、深度depth或通道顺序channel order不是这些，需要在保存前使用Mat::convertTo和cv::cvtColor函数将图片转化，或者使用更通用的FileStorage I/O函数将图片保存为XML或YAML格式。 1234567bool cv::imwrite( const String &amp; filename, // Name of the file. InputArray img, // Image to be saved. const std::vector&lt;int&gt; &amp; params = std::vector&lt;int&gt;() // Format-specific parameters // encoded as pairs (paramId_1, paramValue_1, paramId_2, paramValue_2, ... .) see cv::ImwriteFlags) 使用这个函数在存储PNG图片时能够同时保存透明度alpha channel，要这样做，创建一个8-bit (or 16-bit) 4-channel image BGRA，完全透明(transparent)的像素的alpha值为0，完全不透明(opaque)的像素的alpha值为255/65535。 下面的例子展示了怎样来创建这样一个BGRA图片，并存储为PNG文件，例子同时说明了怎样设置一个压缩参数。 12345678910111213141516171819202122232425262728293031323334#include &lt;opencv2/opencv.hpp&gt;using namespace cv;using namespace std;void createAlphaMat(Mat &amp;mat)&#123; CV_Assert(mat.channels() == 4); for (int i = 0; i &lt; mat.rows; ++i) &#123; for (int j = 0; j &lt; mat.cols; ++j) &#123; Vec4b&amp; bgra = mat.at&lt;Vec4b&gt;(i, j); bgra[0] = UCHAR_MAX; // Blue bgra[1] = saturate_cast&lt;uchar&gt;((float (mat.cols - j)) / ((float)mat.cols) * UCHAR_MAX); // Green bgra[2] = saturate_cast&lt;uchar&gt;((float (mat.rows - i)) / ((float)mat.rows) * UCHAR_MAX); // Red bgra[3] = saturate_cast&lt;uchar&gt;(0.5 * (bgra[1] + bgra[2])); // Alpha &#125; &#125;&#125;int main(int argv, char **argc)&#123; // Create mat with alpha channel Mat mat(480, 640, CV_8UC4); createAlphaMat(mat); vector&lt;int&gt; compression_params; compression_params.push_back(IMWRITE_PNG_COMPRESSION); compression_params.push_back(9); try &#123; imwrite("alpha.png", mat, compression_params); &#125; catch (cv::Exception&amp; ex) &#123; fprintf(stderr, "Exception converting image to PNG format: %s\n", ex.what()); return 1; &#125; fprintf(stdout, "Saved PNG file with alpha data.\n"); return 0;&#125; ¶Reference OpenCV 3,1,0 Documentation: Image file reading and writing]]></content>
      <categories>
        <category>translation</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMakeCommands]]></title>
    <url>%2F2018%2F04-07-Cpp-CMakeCommands%2F</url>
    <content type="text"><![CDATA[¶参考 CMake 3.11.0 Documentation: cmake-commands]]></content>
      <categories>
        <category>translation</category>
        <category>cmake</category>
      </categories>
      <tags>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用dlib进行人脸关键点检测]]></title>
    <url>%2F2018%2F04-07-CV-FaceDetectionUsingDlib%2F</url>
    <content type="text"><![CDATA[¶代码 12 ¶结果 ¶参考 Opencv与dlib联合进行人脸关键点检测与识别 Dlib人脸关键点检测顺序 How to convert mat to array2d&lt;rgb_pixel&gt;?]]></content>
      <categories>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>cv</tag>
        <tag>dlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS配置DLib]]></title>
    <url>%2F2018%2F04-06-Mac-ConfigureDlib%2F</url>
    <content type="text"><![CDATA[¶写在前面 首先，不要使用Homebrew安装，我用brew install dlib安装后，运行例子提示错误 12error: "DLIB_NO_GUI_SUPPORT is defined so you can't use the GUI code. Turn DLIB_NO_GUI_SUPPORT off if you want to use it."error: "Also make sure you have libx11-dev installed on your system" 查询相关资料说是需要安装XQuartz，可我已经通过brew cask install xquartz安装了，而且也有人说安装后还是不行，仍然报错，最后发现作者说不要通过Homebrew安装，因为Homebrew中所有的dlib版本默认都设置为不使用X11，下面是作者在GitHub-Issues回答的原话： 1Don&apos;t use homebrew. Whatever copy of dlib is in homebrew is configured to not use X11. 所以需要按照官网提供的教程进行安装。 ¶编译 卸载通过Homebrew安装的dlib，命令如下： 1brew uninstall dlib 因为我已经安装了XQuartz，如果没有安装，还需要通过官网安装包或者brew cast进行安装。 接下来编译dlib 12345git clone https://github.com/davisking/dlib.gitcd dlib/examplesmkdir buildcmake ..cmake --build . --config Release 经过漫长的编译过程后，就可以测试其中的例子了，如人脸关键点检测例子。借助dlib官网提供的训练好的模型文件，再提供一张带人脸的图片，便可以定位人脸的68个关键点了。 1./face_landmark_detection_ex shape_predictor_68_face_landmarks.dat faces/2008_002506.jpg 结果如下图所示 官网提供的模型只能定位68个关键点，不过你可以通过作者给的例子自己训练新的模型。 ¶测试 当然，你也可以在你自己的项目中使用dlib，CMakeLists.txt如下 12345678910project(hello)cmake_minimum_required(VERSION 2.8)set(CMAKE_CXX_STANDARD 11)set(CMAKE_CXX_STANDARD_REQUIRED ON)add_subdirectory(/Users/liwei/myLibs/dlib/dlib ./dlib_build)aux_source_directory(./src SRC_LIST)add_executable($&#123;PROJECT_NAME&#125; $&#123;SRC_LIST&#125;)target_link_libraries($&#123;PROJECT_NAME&#125; dlib::dlib) ¶参考 DLib C++ Library cmake项目引入dlib方法 Mac下dlib安装 Install dlib (the easy, complete guide) Dlib系列之在iOS中提取人脸特征点（第一篇）]]></content>
      <categories>
        <category>tutorials</category>
        <category>cv/cg</category>
      </categories>
      <tags>
        <tag>dlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MemoryDebugVS]]></title>
    <url>%2F2018%2F04-05-VS-MemoryDebug%2F</url>
    <content type="text"><![CDATA[¶打开 首先需要打开VS的内存查看窗口，即QuickWatch window，快捷键是Ctrl + Alt + Q 。 ¶查看变量内存地址 ¶查看指针地址 ¶查看对象地址 ¶查看数组地址 ¶Reference How to read the debug memory window in Visual Studio]]></content>
      <categories>
        <category>tools</category>
        <category>IDEs</category>
      </categories>
      <tags>
        <tag>vs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度相机的原理]]></title>
    <url>%2F2018%2F03-28-CG-DepthSensorPrinciple%2F</url>
    <content type="text"><![CDATA[¶深度相机分类 基于三角化(Triangulation)的方法 双目立体视觉(Stereo Vision)通过计算两张图片的视差来估计深度 结构光(Structured Light)方法先向场景投射散斑，通过pattern的distortion来估计视差 基于飞行时间(Time-of-Flight)的方法 激光雷达 (Light detection and ranging, LIDAR) ToF相机通过计算飞行时间来估计深度 ¶被动测距传感 ¶双目立体视觉 ¶主动测距传感 ¶TOF相机 ¶结构光 ¶激光雷达 ¶总结 ¶参考 深度图像的获取原理 深度相机哪家强？ 可测深度摄像头（TOF Camera）原理是什么？ https://zhuanlan.zhihu.com/p/32199990 https://zhuanlan.zhihu.com/p/32375622]]></content>
      <categories>
        <category>knowledge</category>
        <category>cv/cg</category>
      </categories>
      <tags>
        <tag>cg</tag>
        <tag>kinect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kinect比较]]></title>
    <url>%2F2018%2F03-28-CG-KinectComparison%2F</url>
    <content type="text"><![CDATA[¶技术比较 Kinect v1的深度传感器采用了一种称为“光编码”（Light Coding）的技术（源自以色列的PrimeSense Inc.的技术，该公司2013年被苹果收购）。该方法读取投影的红外图案(Pattern)，并从图案的变形中获取深度信息。因此，深度传感器分为投射红外图案的IR投影仪（左）和读取红外图案的IR相机（右）。此外，在深度传感器中间安装彩色摄像机。 Kinect v2的深度传感器采用称为“飞行时间”（Time of Flight, ToF）的方法（貌似来自微软收购的一家公司(3DV Systems，Canesta)），该方法从反射和返回反射红外线的时间获得深度信息。从外部看不到的深度传感器配备了红外摄像头（左侧）和投射脉冲调制红外线的投影机（右侧）。彩色摄像头在旁边一侧。 下图简单展示了“光编码”方法与“飞行时间”方法之间的区别： Kinect v1 红外激光(infrared laser)发射一束光柱，然后通过衍射光栅机制分成多份光束，投影到物体的光斑被红外照相机(infrared camera)捕捉，并与已知的参考光斑比较，投影光斑和观察到的光斑用来计算深度信息。 ¶规格比较 Items Kinect v1 Kinect v2 彩色图(Color) 640x480@30fps 1920x1080@30fps 深度图(Depth) 320x240@30fps 512x424@30fps 范围(Range) 0.8~4.0m 0.5~4.5m 传感器远离(Sensor) 结构光(Structured Light) 飞行时间(Time of Flight) 视场(Angle of View) 水平/垂直 57/43 70/60 麦克风阵列(Microphone Array) O O 人体(Body) 6 people 6 people 人体标记(BodyIndex) 2 people 6 people 关节(Joint) 20 joints/people 25 joints/people Hand State Open / Closed Open / Closed / Lasso Gesture X O Face O O Speech/Beamforming O O ¶彩色图 Kinect v1 640 x 480 x 24 bpp 4:3 RGB @ 30fps 640 x 480 x 16 bpp 4:3 YUV @ 15fps Kinect v2 1920 x 1080 x 16 bpp 16:9 YUY2 @ 30 fps 注：bpp代表像素深度 Kinect v1的Color Camera的分辨率仅为640x480，Kinect v2的分辨率大幅提高，能够达到1920×1080。 注：v1的要求是USB2.0，理论传输速率是60MB/s，v2是USB3.0，理论传输速率是500MB/s。 可以计算一下，以XRGB Color为例，30fps，那么每秒所需传输的数据大小为640 x 480 x 4 x 30约为35M；再加上USHORT格式的Depth Color，30fps，大小为320 x 240 x 2 x 30约为4M。总计约为40MB/s，因为带宽有限，所以在保证画面帧率稳定的情况下，分辨率只能如此，而且基本上必须独占一个USB Controller。 再算算v2的情况，Color = 1920 x 1080 x 4 x 30 约为237M，Depth = 512 x 424 x 2 x 30约为12M，总计约为250M/s。所以非USB3.0不可，否则传输不了这么大的数据量。 显而易见，Color Map是最占带宽的，其实可以通过一些其他格式，比如I420或MJPG来减少数据量，然后通过CPU或GPU来进行解压和回放。 ¶深度图 Kinect v2预览版的深度传感器的分辨率也提高到512×424，而Kinect v1是可以取640×480分辨率的深度数据，乍一看规格好像下降了，其实Kinect v1的深度传感器的物理分辨率是320x240，Up Scaling到640x480而已（注：猜测是Runtime处理的）。另外，深度传感器的方式也是从Light Coding变更为Time of Flight(TOF)。 Kinect v1 320 x 240 x 16 bpp, 13-bit depth, 3-bit玩家信息 Kinect v2 512 x 424 x 16 bpp, 13-bit depth, 3-bit玩家信息 Kinect v1的深度图有16位，其中13bit保存深度信息（包括一个标志位），另外3bit保存player information，如果player index没有被申请，则这3bit为0。 12bit的深度信息能够覆盖2^12=4096mm，也就是4米的距离。 标志位存储如下信息 Too near: 0x0000 Too far: 0x7ff8 Unknown: 0xfff8 深度图像是12位的，存储格式是PNG。 JPG只能存储8位，且属于有损压缩。 PNG最大支持单通道16位，且PNG是一种无损压缩格式。 ¶人体关节 Kinect v1中可用的关节每人有20个，但Kinect v2有25个关节，如图所示有增加了 颈部(NECK) 指尖(HAND_TIP_LEFT, HAND_TIP_RIGHT) 拇指(THUMB_LEFT, THUMB_RIGHT) 这五个位置。 ¶数据采集流程比较 ¶参考 Kinect v2 Introduction and Tutorial 目前市面上的RGBD相机对比 Kinect v1和Kinect v2之间的全面比较 翻译 - Kinect v1和Kinect v2的彻底比较 Kinect v2编程（C ++） - 深度 Kinect for Windows SDKs &gt; Kinect for Windows v1 SDK &gt; Kinect uses 12 bits or 13 bits for depth data? Kinect API Overview]]></content>
      <categories>
        <category>knowledge</category>
        <category>cv/cg</category>
      </categories>
      <tags>
        <tag>cg</tag>
        <tag>kinect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows10配置DNSCrypt]]></title>
    <url>%2F2018%2F03-26-Win-Windows10DNSCrypt%2F</url>
    <content type="text"><![CDATA[使用XXNET, dropbox下载不了，看网上说是因为DNS被污染的问题，开启XX-NET，安装并使用DNSCrypt就好了。 ¶下载dnscrypt-proxy 地址：https://download.dnscrypt.org/dnscrypt-proxy/ 我选择 LATEST-win64-full.zip 并解压 ¶下载dnscrypt-winclient 地址：https://github.com/Noxwizard/dnscrypt-winclient 将LATEST-win64-full/dnscrypt-proxy-win64文件夹下的文件拷贝到 dnscrypt-winclient/binaries/Release文件夹下 ¶运行dnscrypt-winclient 右键管理员运行dnscrypt-winclient.exe，并做如下操作： 在NICs勾选要用的网络 将Config -&gt; Provider(服务器) 选择为 Cisco OpenDNS 点击Start开始。 ¶修改DNS服务器地址 将Windows网络链接TCP/IP的DNS修改为127.0.0.1 控制面板 -&gt; 网络与Internet -&gt; 网络与共享中心 -&gt; 更改适配器设置 -&gt; 选择某个本地连接 右键属性，选择Internet协议版本4(TCP/IP)，点击下面的属性。 ` 网络链接TCP/IP的首选DNS服务器修改为127.0.0.1 ` 顺便记得把 dnscrypt-winclient 里面的 Install （Install Dnscrypt as a Windows service) 点击一下，之后就不用每次重启再运行了。 ¶参考 DNSCrypt在Windows和Ubuntu下的配置 dnscrypt怎么用？使用dnscrypt解决dns污染问题 Windows 10怎么设置IP地址与DNS怎么设置 希望加入Dropbox客户端支持 #3482]]></content>
      <categories>
        <category>tutorials</category>
        <category>miscellaneous</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git-FetchPull]]></title>
    <url>%2F2018%2F03-23-Git-FetchPull%2F</url>
    <content type="text"><![CDATA[¶参考 关于使用 Git 的操作流程 关于git pull的问题，如何在不commit的前提下pull回来？ 为什么要先commit，然后pull，最后再push？而不是commit然后直接push？ Git少用Pull多用Fetch和Merge git fetch和git pull的区别 Git:代码冲突常见解决方法 GIT: FETCH AND MERGE, DON’T PULL]]></content>
      <categories>
        <category>tools</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown中的代码语法高亮]]></title>
    <url>%2F2018%2F03-22-MD-CodeSyntaxHighlighting%2F</url>
    <content type="text"><![CDATA[¶代码高亮语法 Markdown中代码高亮的一般书写格式为： ```language_key if (condition) { &emsp; return true; } ``` 其中language_key填写具体的语言类型。 ¶代码语言支持 注意：不同的Markdown编辑器所支持的语言可能不同。 Language language_key 1C 1c ActionScript actionscript Apache apache AppleScript applescript AsciiDoc asciidoc AspectJ asciidoc AutoHotkey autohotkey AVR Assembler avrasm Axapta axapta Bash bash BrainFuck brainfuck Cap’n Proto capnproto Clojure REPL clojure Clojure clojure CMake cmake CoffeeScript coffeescript C++ cpp C# cs CSS css D d Dart d Delphi delphi Diff diff Django django DOS .bat dos Dust dust Elixir elixir ERB (Embedded Ruby) erb Erlang REPL erlang-repl Erlang erlang FIX fix F# fsharp G-code (ISO 6983) gcode Gherkin gherkin GLSL glsl Go go Gradle gradle Groovy groovy Haml haml Handlebars handlebars Haskell haskell Haxe haxe HTTP http Ini file ini Java java JavaScript javascript JSON json Lasso lasso Less less Lisp lisp LiveCode livecodeserver LiveScript livescript Lua lua Makefile makefile Markdown markdown Mathematica mathematica Matlab matlab MEL (Maya Embedded Language) mel Mercury mercury Mizar mizar Monkey monkey nginx nginx Nimrod nimrod Nix nix NSIS nsis Objective C objectivec OCaml ocaml Oxygene oxygene Parser 3 parser3 Perl perl PHP php PowerShell powershell Processing processing Python’s profiler output profile Protocol Buffers protobuf Puppet puppet Python python Q q R r RenderMan RIB rib Roboconf roboconf RenderMan RSL rsl Ruby ruby Oracle Rules Language ruleslanguage Rust rust Scala scala Scheme scheme Scilab scilab SCSS scss Smali smali SmallTalk smalltalk SML sml SQL sql Stata stata STEP Part 21 (ISO 10303-21) step21 Stylus stylus Swift swift Tcl tcl TeX tex Thrift thrift Twig twig TypeScript typescript Vala vala VB.NET vbnet VBScript in HTML vbscript-html VBScript vbscript Verilog verilog VHDL vhdl Vim Script vim Intel x86 Assembly x86asm XL xl ¶参考 markdown语法高亮支持]]></content>
      <categories>
        <category>tools</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atom插件安装]]></title>
    <url>%2F2018%2F03-22-Atom-PackageInstalling%2F</url>
    <content type="text"><![CDATA[¶方法一：使用客户端安装 使用客户端安装是最简单的方式。 点击Preference，在Settings中点击Install，然后输入需要安装的package的名字，搜索结束后点击需要安装的package栏目中的Install按钮即可。 ¶方法二：使用apm安装 apm(Atom Package Manager)是atom的包管理工具，可以方便的管理Atom的插件。 首先打开你的terminal,切换到atom的插件目录 1cd ~/.atom/packages 然后使用命令 1apm install &lt;package-name&gt; 安装名称为&lt;package-name&gt;的插件 Note：如果不知道具体的插件目录，点击Preference，在Settings中点击Open Config Folder，然后在packages文件夹上右击选择Show in Finder，便能在Finder中打开插件目录。 ¶方法三：使用git安装 这种方法可能会少相关依赖，需要自行在packages里运行npm install &lt;node-package&gt;安装相关的依赖。 在atom.io上(或者在atom设置界面中跳转到插件的网页)找到插件页面，点击Repo跳到插件的github仓库，将&lt;package-repo-url&gt;替换为仓库的地址，然后在packages目录下运行下列命令： 1git clone &lt;package-repo-url&gt; ¶参考 Atom安装插件的几个方法]]></content>
      <categories>
        <category>tools</category>
        <category>editor</category>
      </categories>
      <tags>
        <tag>atom</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS配置OpenCV]]></title>
    <url>%2F2018%2F03-21-CV-macOSConfigureOpenCV%2F</url>
    <content type="text"><![CDATA[¶安装OpenCV库 使用Homebrew安装，非常简单，一个命令搞定 1brew install opencv ¶XCode测试 ¶新建项目 新建XCode的macOS Command Line Tool项目，具体方式如图所示。 ¶项目配置 配置项目的Header Search Paths和Library Search Paths，即包含目录和库目录。 双击项目打开testOpenCV.xcodeproj，点击Build Setting，再点击下方的Basic。在Header Search Paths和Library Search Paths分别添加OpenCV的相应路径。 具体路径可以通过brea info opencv获得。 ¶测试代码 测试代码通过MBP自带摄像头捕捉图像，并转化为灰度图，进行适当降燥后计算Canny算子，完整代码如下。 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main(int argc, char** argv)&#123; VideoCapture capture(0); Mat gray,edge; while(1) &#123; Mat frame; capture &gt;&gt; frame; printf("Camera capturing....\n"); cvtColor(frame, gray, CV_BGR2GRAY); //转换为灰度图 blur(gray, edge, Size(3,3)); //降噪 Canny(edge, edge, 3, 9); //运行Canny算子，3为threshold1，9为threshold2 imshow("Capture",edge); waitKey(30); &#125; return 0;&#125; ¶运行结果 下面运行结果的一张截图 ¶QtCreator测试 ¶CMake测试 CMakeLists.txt文件 12345678910111213cmake_minimum_required(VERSION 3.9)set(PROJECT_NAME TestOpenCVCmake)project($&#123;PROJECT_NAME&#125;)set(CMAKE_CXX_STANDARD 11)find_package(OpenCV REQUIRED)include_directories($&#123;OpenCV_INCLUDE_DIRS&#125;)add_executable(TestOpenCVCmake main.cpp)target_link_libraries($&#123;PROJECT_NAME&#125; $&#123;OpenCV_LIBS&#125;) ¶参考 配置OpenCV3 + Python3的简易方法（macOS)]]></content>
      <categories>
        <category>tutorials</category>
        <category>cv/cg</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tips for Shortcut Keys on macOS]]></title>
    <url>%2F2018%2F03-20-Mac-Tips4ShortcutKeys%2F</url>
    <content type="text"><![CDATA[¶文件 ¶预览文件 选中文件，按Space ¶显示文件信息 选中文件，按Command + I ¶文件夹 ¶复制、粘贴、剪切文件夹 复制Command + C 粘贴Command + V 剪切Command + Option + V ¶显示隐藏文件、文件夹 Command + Shift + . ¶前往任意文件夹 Finder下Command + Shift + G ¶复制文件夹路径 选中文件夹，按Command + Option + C即可 按Command + C拷贝文件夹，再按Command + V粘贴到终端 将文件夹拖进终端（Terminal），可以显示路径 ¶显示文件夹信息 选中文件夹或文件，按Command + I ¶键盘、输入法 ¶切换输入法 单击Caps Lock 按住Control，再按Space可以切换输入法 ¶锁定大写 长按Caps Lock至绿灯亮 ¶窗口 ¶最小化窗口 窗口在非全屏状态下，点击Command + M ¶最大化窗口 按住Option，全屏按钮就会变为+，点击就是垂直最大化 按住Option + Shift，全屏按钮也会变为+，点击就是最大化，而不是全屏 ¶全屏 点击Command + Control + F进入或退出全屏 ¶分屏 窗口在非全屏状态下，点击全屏图标不动，直至进入分屏选择状态，点击另一窗口进入分屏，或点击桌面退出分屏。 ¶参考]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Jekyll搭建个人博客网站]]></title>
    <url>%2F2018%2F03-15-Mis-JekyllBlog%2F</url>
    <content type="text"><![CDATA[¶借助jekyll-theme-next搭建博客 ¶新建GitHub仓库 打开创建代码仓库页面，新建仓库并取名为your-username.github.io，这样后面你就可以通过your-username.github.io访问你的博客。 ¶前期jekyll环境准备 确保已安装Ruby 2.1.0 或更高版本 1ruby --version 安装Bundler： 1gem install bundler ¶本地安装NexT 新建博客文件夹，如jekyll-theme-next。 初始化本地Git仓库： 1git init 下载NexT主题，这里还有更多的主题，你可以选择自己喜欢的，方法是一样的。 解压后把文件拷贝到你的博客文件夹，即jekyll-theme-next。 进入博客文件夹： 1cd jekyll-theme-next 安装依赖： 1bundle install 运行 Jekyll： 1bundle exec jekyll server 此时即可使用浏览器访问 http://localhost:4000，检查站点是否正确运行。 ¶推送本地代码到GitHub 将本地代码推送到GitHub： 1234git add *git commit -m &quot;first commit&quot;git remote add origin https://github.com/your-repositorygit push -u origin master 这里your-repository即为your-username.github.io。此时打开网址your-username.github.io便能看到你的博客。 ¶借助七牛图床存储博客图片 装载自Markdown 配置七牛云作为图床 ¶配置七牛云 注册完成之后，在资源主页中的对象存储里添加对象，如添加image，但不能为Bucket 注意选择的地区可能会影响到图片能否加载成功，如果出错修改地区重试。 ¶上传图片 看如下动图： 点击复制外链，粘贴到Markdown文档中即可。 ¶借助LeanCloud统计访问人数 装载自为NexT主题添加文章阅读量统计功能 注册完成LeanCloud帐号并验证邮箱之后，我们就可以登录我们的LeanCloud帐号，进行一番配置之后拿到AppID以及AppKey这两个参数即可正常使用文章阅读量统计的功能了。 ¶配置LeanCloud ¶创建应用 新建一个应用来专门进行博客的访问统计的数据操作。首先，打开控制台，如下图所示： 在出现的界面点击创建应用： 在接下来的页面，新建的应用名称我们可以随意输入，即便是输入的不满意我们后续也是可以更改的: 这里为了演示的方便，我新创建一个取名为test的应用。创建完成之后我们点击新创建的应用的名字来进行该应用的参数配置： 在应用的数据配置界面，左侧下划线开头的都是系统预定义好的表，为了便于区分我们新建一张表来保存我们的数据。点击左侧右上角的齿轮图标，新建Class： 在弹出的选项中选择创建Class来新建Class用来专门保存我们博客的文章访问量等数据: 点击创建Class之后，理论上来说名字可以随意取名，只要你交互代码做相应的更改即可，但是为了保证我们前面对NexT主题的修改兼容，此处的新建Class名字必须为Counter: 由于LeanCloud升级了默认的ACL权限，如果你想避免后续因为权限的问题导致次数统计显示不正常，建议在此处选择无限制。 创建完成之后，左侧数据栏应该会多出一栏名为Counter的栏目，这个时候我们点击顶部的设置，切换到test应用的操作界面: 在弹出的界面中，选择左侧的应用Key选项，即可发现我们创建应用的AppID以及AppKey，有了它，我们就有权限能够通过主题中配置好的Javascript代码与这个应用的Counter表进行数据存取操作了: 复制AppID以及AppKey并在NexT主题的_config.yml文件中我们相应的位置填入即可，正确配置之后文件内容像这个样子: 1234leancloud_visitors: enable: true app_id: joaeuuc4hsqudUUwx4gIvGF6-gzGzoHsz app_key: E9UJsJpw1omCHuS22PdSpKoh 这个时候重新生成部署博客，应该就可以正常使用文章阅读量统计的功能了。需要特别说明的是：记录文章访问量的唯一标识符是文章的发布日期以及文章的标题，因此请确保这两个数值组合的唯一性，如果你更改了这两个数值，会造成文章阅读数值的清零重计。 ¶后台管理 当你配置部分完成之后，初始的文章统计量显示为0，但是这个时候我们LeanCloud对应的应用的Counter表中并没有相应的记录，只是单纯的显示为0而已，当博客文章在配置好阅读量统计服务之后第一次打开时，便会自动向服务器发送数据来创建一条数据，该数据会被记录在对应的应用的Counter表中。 我们可以修改其中的time字段的数值来达到修改某一篇文章的访问量的目的（博客文章访问量快递提升人气的装逼利器）。双击具体的数值，修改之后回车即可保存。 url字段被当作唯一ID来使用，因此如果你不知道带来的后果的话请不要修改。 title字段显示的是博客文章的标题，用于后台管理的时候区分文章之用，没有什么实际作用。 其他字段皆为自动生成，具体作用请查阅LeanCloud官方文档，如果你不知道有什么作用请不要随意修改。 ¶Web安全 因为AppID以及AppKey是暴露在外的，因此如果一些别用用心之人知道了之后用于其它目的是得不偿失的，为了确保只用于我们自己的博客，建议开启Web安全选项，这样就只能通过我们自己的域名才有权访问后台的数据了，可以进一步提升安全性。 选择应用的设置的安全中心选项卡: 在Web 安全域名中填入我们自己的博客域名，来确保数据调用的安全: ¶借助Disqus添加评论支持 转载自为Hexo博客加入Disqus评论 ¶注册Disqus 打开Disqus主页，注册一个账号。 ¶配置Disqus 登录后，点击首页的GET STARTED按钮，之后选择I want to install Disqus on my site选项，新建一个站点。 Websit Name： 就是等会配置文件中要填写的shortname，自己填写即可，但是要求全网唯一，设定后不可改变，比如这里假设为your-name：这个在配置jekyll的时候需要用到。 Category：选择种类，可以随便选，我这里选Tech。 Language：语言选Chinese或者English。 然后点Create Site等待界面跳转。 接下来在页面的左侧点击Configure Disqus ¶配置jekyll 打开_config.yml文件，搜索找到disqus，将配置更改为如下： 1234disqus: enable: true shortname: your-name count: true 将更改推送到GitHub打开博客网址便可以看到下面出现了评论框了。 ¶撰写博客 ¶参考 Simpleyyt/jekyll-theme-next NexT使用文档 Jekyll中文文档 用Jekyll搭建的Github Pages个人博客 Markdown 配置七牛云作为图床 为NexT主题添加文章阅读量统计功能 为Hexo博客加入Disqus评论]]></content>
      <categories>
        <category>tutorials</category>
        <category>miscellaneous</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>jekyll</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源协议]]></title>
    <url>%2F2018%2F03-14-License%2F</url>
    <content type="text"><![CDATA[¶BSD开源协议（original BSD license、FreeBSD license、Original BSD license） BSD开源协议是一个给于使用者很大自由的协议。基本上使用者可以”为所欲为”,可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。 但”为所欲为”的前提当你发布使用了BSD协议的代码，或则以BSD协议代码为基础做二次开发自己的产品时，需要满足三个条件： 如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中的BSD协议。 如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。 不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。 BSD代码鼓励代码共享，但需要尊重代码作者的著作权。BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销售，因此是对 商业集成很友好的协议。而很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者二次开发。 ¶Apache Licence 2.0（Apache License, Version 2.0、Apache License, Version 1.1、Apache License, Version 1.0） Apache Licence是著名的非盈利开源组织Apache采用的协议。该协议和BSD类似，同样鼓励代码共享和尊重原作者的著作权，同样允许代码修改，再发布（作为开源或商业软件）。需要满足的条件也和BSD类似： 需要给代码的用户一份Apache Licence 如果你修改了代码，需要再被修改的文件中说明。 在延伸的代码中（修改和有源代码衍生的代码中）需要带有原来代码中的协议，商标，专利声明和其他原来作者规定需要包含的说明。 如果再发布的产品中包含一个Notice文件，则在Notice文件中需要带有Apache Licence。你可以在Notice中增加自己的许可，但不可以表现为对Apache Licence构成更改。 Apache Licence也是对商业应用友好的许可。使用者也可以在需要的时候修改代码来满足需要并作为开源或商业产品发布/销售。 ¶GPL（GNU General Public License） 我们很熟悉的Linux就是采用了GPL。GPL协议和BSD, Apache Licence等鼓励代码重用的许可很不一样。 GPL的出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用，但不允许修改后和衍生的代 码做为闭源的商业软件发布和销售。这也就是为什么我们能用免费的各种linux，包括商业公司的linux和linux上各种各样的由个人，组织，以及商 业软件公司开发的免费软件了。 GPL协议的主要内容是只要在一个软件中使用(”使用”指类库引用，修改后的代码或者衍生代码)GPL 协议的产品，则该软件产品必须也采用GPL协议，既必须也是开源和免费。这就是所谓的”传染性”。GPL协议的产品作为一个单独的产品使用没有任何问题， 还可以享受免费的优势。 由于GPL严格要求使用了GPL类库的软件产品必须使用GPL协议，对于使用GPL协议的开源代码，商业软件或者对代码有保密要求的部门就不适合集成/采用作为类库和二次开发的基础。 其它细节如再发布的时候需要伴随GPL协议等和BSD/Apache等类似。 ###关于开源协议GPL V2和V3 单从开源行业的GPL协议上来看，似乎开源linux产品上的一切是可以无条件的开放和共享的，但是从实际的操作来看，在GPL相对的许可授权之下，又有其相对封闭的一面，就这次的GPL v2到GPL v3的修订改版来说，正是GPL协议“封闭”一面的具体体现。 根据GPL v2的相关规定：只要这种修改文本在整体上或者其某个部分来源于遵循GPL的程序，该修改文本的整体就必须按照GPL流通，不仅该修改文本的源码必须向社 会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制。而在GPL v3的修订草案中，不仅要求用户公布修改的源代码，还要求公布相关硬件，恰恰是这一条，由于触及和其他相关数字版权管理(DRM)及其产品的关系，并且也 由于有和开源精神相违的地方，所以备受争议，甚至因此也遭到了有着“LINUX之父”之称的托瓦尔兹的反对。 从表面上看，GPL v2到GPL v3的升级之困只不过是对协议修订过程中某一条款的分歧，而更为严重的是在两种协议都合法存在的前提下，具体的开源软件或者开源产品的所有者有权选择是遵 循GPL v2协议还是恪守GPL v3协议，因此冲突也就来了，这种冲突正如中科红旗的CTO郑忠源描述的那样：“世界有如此多软件都在GPL v2的约束之下，而自由软件是集合全世界程序员劳动，即使是贡献一行代码，如果该程序员只同意这一代码只遵循GPL v2之下，就不能随便去修改协议。如果计划将软件转移到GPL v3之下，理论上讲，必须征得所有代码人的同意。但是目前还很难确定有多少开发人员愿意转移到新版本之下，如果有的人愿意转，有的人不愿意转，这其中就有 很多的麻烦；而如果多数人都不愿意改变，那这一事情也许就无声无息……” 通过业内人士的精辟描述，相信大家一定对开源行业和开源软件产品有了一个全新的认识吧，就那熟悉的LINUX系统来说，虽然表面上看起来大家有权按 照自己的需要和目的进行任意的改写重组，但是在诸多的独立程序面前，别人是只能共享使用，而无权修改的，当然获得授权就另当别论了。而就GPL v2到GPL v3的协议升级来说，这种协议的选择上的分歧实际上也是开源行业里一种观念认知上的相左，到底谁的选择是正确的？绝对不是一两句话能说得清的，尤其是在各 种利益交织之下。 情势之下，开源社区的GPL v2与GPL v3选择之困很现实的会在相当一段时间内给这个行业及其产品造成“兼容问题”，说白了就是两种协议以及两种协议之下的矛盾，不管是人的还是产品的都将会持 续下去，而这种僵持对整个开源行业来说未必是一件好事，最起码从“精神”方面来说这个行业已经在开始分道扬镳。 ¶LGPL（GNU Lesser General Public License） LGPL是GPL的一个为主要为类库使用设计的开源协议。和GPL要求任何使用/修改/衍生之GPL类库的的软件必须采用GPL协议不同。 LGPL 允许商业软件通过类库引用(link)方式使用LGPL类库而不需要开源商业软件的代码。这使得采用LGPL协议的开源代码可以被商业软件作为类库引用并 发布和销售。 但是如果修改LGPL协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用LGPL协议。因此LGPL协议的开源 代码很适合作为第三方类库被商业软件引用，但不适合希望以LGPL协议代码为基础，通过修改和衍生的方式做二次开发的商业软件采用。 GPL/LGPL都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品 ¶MIT（MIT License） MIT是和BSD一样宽范的许可协议,作者只想保留版权,而无任何其他了限制.也就是说,你必须在你的发行版里包含原许可协议的声明,无论你是以二进制发布的还是以源代码发布的. ¶参考 Open Source Licenses by Category 各种开源协议介绍 BSD、Apache Licence、GPL V2 、GPL V3 、LGPL、MIT 知乎：主流开源协议之间有何异同？ Choose an open source license SPDX License List]]></content>
      <categories>
        <category>knowledge</category>
        <category>miscellaneous</category>
      </categories>
      <tags>
        <tag>license</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS配置OpenMesh]]></title>
    <url>%2F2018%2F03-07-Mac-ConfigureOpenMesh%2F</url>
    <content type="text"><![CDATA[¶安装OpenMesh库 使用Homebrew安装，非常简单，一个命令搞定 1brew install open-mesh 安装后可能不知道库的具体位置，通过下面命令 1brew info open-mesh 可以查看库的信息，其中就包括了库的路径，我得到的是 1/usr/local/Cellar/open-mesh/6.3 ¶用Qt Creator测试OpenMesh Creator的安装这里不再赘述，新建控制台项目，如test。 在test.pro中添加保护目录和库文件 1234INCLUDEPATH += /usr/local/Cellar/open-mesh/6.3/includeLIBS += /usr/local/Cellar/open-mesh/6.3/lib/libOpenMeshCore.aLIBS += /usr/local/Cellar/open-mesh/6.3/lib/libOpenMeshTools.a main函数中的代码如下： 12345678910111213141516171819202122232425262728293031#include &lt;QCoreApplication&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;OpenMesh/Core/IO/MeshIO.hh&gt;#include &lt;OpenMesh/Core/Mesh/PolyMesh_ArrayKernelT.hh&gt;#include &lt;OpenMesh/Core/IO/reader/OBJReader.hh&gt;#include &lt;OpenMesh/Core/IO/writer/OBJWriter.hh&gt;typedef OpenMesh::PolyMesh_ArrayKernelT&lt;&gt; MyMesh;int main(int argc, char *argv[])&#123; QCoreApplication a(argc, argv); OpenMesh::IO::_OBJReader_(); OpenMesh::IO::_OBJWriter_(); MyMesh mesh; std::string file = "bunny.obj"; if (!OpenMesh::IO::read_mesh(mesh, file)) &#123; std::cout &lt;&lt; "Failed to read mesh" &lt;&lt; std::endl; return a.exec(); &#125; if (!OpenMesh::IO::write_mesh(mesh, "out.obj")) &#123; std::cout &lt;&lt; "Failed to save mesh" &lt;&lt; std::endl; return a.exec(); &#125; return a.exec();&#125; 程序正确运行。 注意：一开始程序中没加 12#include &lt;OpenMesh/Core/IO/reader/OBJReader.hh&gt;#include &lt;OpenMesh/Core/IO/writer/OBJWriter.hh&gt; 和 12OpenMesh::IO::_OBJReader_();OpenMesh::IO::_OBJWriter_(); 运行时报错[OpenMesh::IO::_IOManager_] No reading modules available!，搜索这里发现需要加上面的内容。 ¶在Cmake中使用OpenMesh 在Cmake中使用OpenMesh，CmakeList.txt如下所示： 12345678910111213cmake_minimum_required(VERSION 3.9)project(testOpenMeshCMake)set(SOURCE_FILES main.cpp)set(CMAKE_CXX_STANDARD 11)add_executable(testOpenMeshCMake main.cpp)target_link_libraries (testOpenMeshCMake /usr/local/Cellar/open-mesh/6.3/lib/libOpenMeshTools.6.3.dylib /usr/local/Cellar/open-mesh/6.3/lib/libOpenMeshCore.6.3.dylib ) ¶Reference OpenMesh — BrewFormulas - Homebrew Formulas [OpenMesh] A question about the Examples]]></content>
      <categories>
        <category>tutorials</category>
      </categories>
      <tags>
        <tag>openmesh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tips for Homebrew]]></title>
    <url>%2F2018%2F03-07-Mac-Tips4Homebrew%2F</url>
    <content type="text"><![CDATA[¶更新Homebrew 要获取最新的包的列表，首先得更新Homebrew自己，这可以用brew update办到。 1brew update ¶安装包 安装包的命令如下： 1brew install $FORMULA # 安装指定的包 可以在Homebrew Formulas搜索你需要安装的包。比如你要安装OpenMesh库，在该网页中输入OpenMesh点击搜索，会得到一个搜索结果，点击进去，可以看到安装命令如下： 1brew install open-mesh 但通过brew install安装某些包提示找不到，可能已经废弃了，如ann，通过下面命令可以安装，参考这里. 1brew install brewsci/science/ann 12brew unlink opencvbrew link --force opencv@3 ¶卸载包 1brew uninstall $FORMULA # 卸载指定的包 注意：卸载一个包不会同时卸载其依赖的包。 ¶更新包 通过下面命令可以查看所有可更新的包 1brew outdated 然后就可以用brew upgrade去更新了。Homebrew会安装新版本的包，但旧版本仍然会保留。 12brew upgrade # 更新所有的包brew upgrade $FORMULA # 更新指定的包 ¶清理旧版本 一般情况下，新版本安装了，旧版本就不需要了。可以用brew cleanup清理旧版本和缓存文件。Homebrew只会清除比当前安装的包更老的版本，所以不用担心有些包没更新但被删了。 123brew cleanup # 清理所有包的旧版本brew cleanup $FORMULA # 清理指定包的旧版本brew cleanup -n # 查看可清理的旧版本包，不执行实际操作 ¶锁定包 如果经常更新的话，brew update一次更新所有的包是非常方便的。但有时候会担心自动升级把一些不希望更新的包更新了，这时可用brew pin去锁定这个包，然后brew update就会略过它了。 12brew pin $FORMULA # 锁定某个包brew unpin $FORMULA # 取消锁定 ¶查看包信息 brew info可以查看包的相关信息，包括包依赖和相应的命令。 12brew info $FORMULA # 显示某个包的信息brew info # 显示安装了包数量，文件数量，和总占用空间 brew deps可以显示包的依赖关系，可以用来查看已安装的包的依赖，然后判断哪些包是可以安全删除的。 1brew deps --installed --tree # 查看已安装的包的依赖，树形显示 如输出的python依赖如下： 1234567python├── gdbm├── openssl├── readline├── sqlite│ └── readline└── xz ¶查看包列表 1brew list # 列出所有安装的包 brew list命令还有一些可选参数[--unbrewed][--versions [--multiple]] [--pinned][formulae] 如果给定[formulae]参数，将列出该包的所安装的文件，如果加上--verbose参数，将进一步列出该包所有子文件夹中的文件。 如果给定--unbrewed，list all files in the Homebrew prefix not installed by Homebrew. 如果给定--versions，显示所有包或者某个包([formulae]参数指定)的版本号，如果进一步给定–multiple参数，将只显示多版本安装的包。 如果给定--pinned参数，将现实所有或者某个包被pin的包。 ¶安装其他仓库的包 一般情况下我们安装的都是主仓库(Homebrew’s master repository)中的包，但有些包可能在其他仓库，如brewsci/science和homebrew/core。这时可以通过brew tap命令做到，比如： 1brew tap brewsci/science 然后你就可以直接用brew install安装brewsci/science中的包： 1brew install $FORMULA ¶参考 你应该定期更新Homebrew Keeping Your Homebrew Up to Date Homebrew-OpenMesh]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LaTeX文档多图排版]]></title>
    <url>%2F2018%2F02-16-Tex-imageTypesetting%2F</url>
    <content type="text"><![CDATA[¶两图并排 ¶两图竖直排放，共享标题 1234567\begin&#123;figure&#125;[htbp] \centering \includegraphics[width=0.2\textwidth]&#123;number_1.jpg&#125; \\ \includegraphics[width=0.2\textwidth]&#123;number_2.jpg&#125; \caption&#123;两图竖直摆放，共享标题&#125; \label&#123;fig:ver_2figs_1cap&#125;\end&#123;figure&#125; ¶两图水平排放，共享标题 123456789101112\begin&#123;figure&#125; \begin&#123;minipage&#125;[t]&#123;0.5\linewidth&#125; \centering \includegraphics[width=2.2in]&#123;number_1.jpg&#125; \end&#123;minipage&#125; \begin&#123;minipage&#125;[t]&#123;0.5\linewidth&#125; \centering \includegraphics[width=2.2in]&#123;number_2.jpg&#125; \end&#123;minipage&#125; \caption&#123;两图水平摆放，共享标题&#125; \label&#123;fig:hor_2figs_1cap&#125;\end&#123;figure&#125; ¶两图竖直排放，独立标题 12345678910111213141516\begin&#123;figure&#125; \centering \begin&#123;minipage&#125;[t]&#123;0.5\linewidth&#125; \centering \includegraphics[width=2.2in]&#123;number_1.jpg&#125; \caption&#123;标题一&#125; \label&#123;fig:ver_2figs_2cap_1&#125; \end&#123;minipage&#125; \\ \begin&#123;minipage&#125;[t]&#123;0.5\linewidth&#125; \centering \includegraphics[width=2.2in]&#123;number_2.jpg&#125; \caption&#123;标题二&#125; \label&#123;fig:ver_2figs_2cap_2&#125; \end&#123;minipage&#125;\end&#123;figure&#125; ¶两图水平排放，独立标题 1234567891011121314\begin&#123;figure&#125; \begin&#123;minipage&#125;[t]&#123;0.5\linewidth&#125; \centering \includegraphics[width=2.2in]&#123;number_1.jpg&#125; \caption&#123;标题一&#125; \label&#123;fig:hor_2figs_2cap_1&#125; \end&#123;minipage&#125; \begin&#123;minipage&#125;[t]&#123;0.5\linewidth&#125; \centering \includegraphics[width=2.2in]&#123;number_2.jpg&#125; \caption&#123;标题二&#125; \label&#123;fig:hor_2figs_2cap_2&#125; \end&#123;minipage&#125;\end&#123;figure&#125; ¶两图水平排放，统一大标题，独立子标题 1234567891011121314151617\begin&#123;figure&#125; \centering \subfigure[子标题一]&#123; \begin&#123;minipage&#125;[b]&#123;0.2\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_1.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:hor_2figs_1cap_2subcap_1&#125; &#125; \subfigure[子标题二]&#123; \begin&#123;minipage&#125;[b]&#123;0.2\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_2.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:hor_2figs_1cap_2subcap_2&#125; &#125; \caption&#123;两图水平排放，统一大标题，独立子标题&#125; \label&#123;fig:hor_2figs_1cap_2subcap&#125;\end&#123;figure&#125; ¶四图并排 ¶四图水平摆放，统一大标题，两两独立子标题 12345678910111213141516171819\begin&#123;figure&#125; \centering \begin&#123;minipage&#125;[b]&#123;0.45\textwidth&#125; \subfigure[标题一]&#123; \includegraphics[width=0.4\textwidth]&#123;number_1.jpg&#125; \includegraphics[width=0.4\textwidth]&#123;number_2.jpg&#125; \label&#123;fig:hor_4figs_1cap_2subcap_1&#125; &#125; \end&#123;minipage&#125; \begin&#123;minipage&#125;[b]&#123;0.45\textwidth&#125; \subfigure[标题二]&#123; \includegraphics[width=0.4\textwidth]&#123;number_3.jpg&#125; \includegraphics[width=0.4\textwidth]&#123;number_4.jpg&#125; \label&#123;fig:hor_4figs_1cap_2subcap_2&#125; &#125; \end&#123;minipage&#125; \caption&#123;四图水平摆放，统一大标题，两两独立子标题&#125; \label&#123;fig:hor_4figs_1cap_2subcap&#125;\end&#123;figure&#125; ¶四图栅格摆放，统一大标题，两两独立子标题 1234567891011121314151617181920\ref&#123;fig:grid_4figs_1cap_2subcap_2&#125;。\begin&#123;figure&#125; \centering \subfigure[标题一]&#123; \begin&#123;minipage&#125;[b]&#123;0.5\textwidth&#125; \includegraphics[width=0.4\textwidth]&#123;number_1.jpg&#125; \includegraphics[width=0.4\textwidth]&#123;number_2.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:grid_4figs_1cap_2subcap_1&#125; &#125; \subfigure[标题二]&#123; \begin&#123;minipage&#125;[b]&#123;0.5\textwidth&#125; \includegraphics[width=0.4\textwidth]&#123;number_3.jpg&#125; \includegraphics[width=0.4\textwidth]&#123;number_4.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:grid_4figs_1cap_2subcap_2&#125; &#125; \caption&#123;四图栅格摆放，统一大标题，两两独立子标题&#125; \label&#123;fig:grid_4figs_1cap_2subcap&#125;\end&#123;figure&#125; ¶四图栅格摆放，统一大标题，独立子标题 123456789101112131415161718192021222324252627282930\begin&#123;figure&#125; \centering \subfigure[标题一]&#123; \begin&#123;minipage&#125;[b]&#123;0.3\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_1.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:grid_4figs_1cap_4subcap_1&#125; &#125; \subfigure[标题二]&#123; \begin&#123;minipage&#125;[b]&#123;0.3\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_2.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:grid_4figs_1cap_4subcap_2&#125; &#125; \\ \subfigure[标题三]&#123; \begin&#123;minipage&#125;[b]&#123;0.3\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_3.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:grid_4figs_1cap_4subcap_3&#125; &#125; \subfigure[标题四]&#123; \begin&#123;minipage&#125;[b]&#123;0.3\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_4.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:grid_4figs_1cap_4subcap_4&#125; &#125; \caption&#123;四图栅格布局摆放，统一大标题，独立子标题&#125; \label&#123;fig:grid_4figs_1cap_4subcap&#125;\end&#123;figure&#125; ¶并排摆放，统一大标题，独立子标题 如果想要两幅并排的图片共享一个标题，并各有自己的子标题，一般有两种办法。但需要 特别注意：这两种方法不互相兼容，即在同一份文档中，你只能选择其中的一种方法使用。 ¶方法一：使用宏包subfig(不推荐) 使用subfig宏包提供的\subfloat命令，需要使用宏包\usepackage{graphicx}和\usepackage{subfig}。subfloat命令缺少宽度参数，虽然可以用\hspace命令调整子图的距离，子标题却只能和子图本身一样宽，会出现折行。为了避免子标题折行，一般在\subfloat里再嵌套个minipage，因为后者是有宽度的。 12345678910111213141516171819\begin&#123;figure&#125;[htbp] \centering \subfloat[子标题一]&#123; \label&#123;fig:1&#125; \begin&#123;minipage&#125;[c]&#123;0.45\textwidth&#125; \centering \includegraphics[width=\textwidth]&#123;number_1.jpg&#125; \end&#123;minipage&#125; &#125; \subfloat[子标题二]&#123; \label&#123;fig:2&#125; \begin&#123;minipage&#125;[c]&#123;0.45\textwidth&#125; \centering \includegraphics[width=\textwidth]&#123;number_2.jpg&#125; \end&#123;minipage&#125; &#125; \caption&#123;两图水平排放，统一大标题，独立子标题&#125; \label&#123;fig:2figs&#125;\end&#123;figure&#125; ¶方法二：使用宏包subfigure(推荐) 使用subfigure宏包提供的\subfigure命令，需要使用宏包\usepackage{graphicx}和\usepackage{subfigure}，subfigure不支持\\换行，可以把minipage放在subfigure{}中，在minipage{}里换行。 1234567891011121314151617\begin&#123;figure&#125; \centering \subfigure[子标题一]&#123; \begin&#123;minipage&#125;[b]&#123;0.2\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_1.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:hor_2figs_1cap_2subcap_1&#125; &#125; \subfigure[子标题二]&#123; \begin&#123;minipage&#125;[b]&#123;0.2\textwidth&#125; \includegraphics[width=1\textwidth]&#123;number_2.jpg&#125; \end&#123;minipage&#125; \label&#123;fig:hor_2figs_1cap_2subcap_2&#125; &#125; \caption&#123;两图水平排放，统一大标题，独立子标题&#125; \label&#123;fig:hor_2figs_1cap_2subcap&#125;\end&#123;figure&#125; 以上显示在单列。如果希望跨列显示，并且修改相应的宽度参数。 ¶Reference Latex基础——图片位置排版技巧]]></content>
      <categories>
        <category>tools</category>
        <category>latex</category>
      </categories>
      <tags>
        <tag>latex</tag>
        <tag>writing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LaTeX的minipage命令]]></title>
    <url>%2F2018%2F02-15-Tex-minipageCommand%2F</url>
    <content type="text"><![CDATA[The minipage is often used to put things next to each other, which can otherwise be hard put together. For example, two pictures side by side, two tables next to a text or a picture or vice versa. The idea behind the minipage command is that within an existing page “built in” an additional page. By this one has the opportunity to use this new page, for example, set two pictures side by side, then just set two minipages side by side. Here than in Figure 1 is set in the first and Figure 2 in the second minipage. ¶The command minipage Wherein minipage is an environment that has a specific orientation, and a predetermined width. 12345\begin&#123;minipage&#125;[adjusting]&#123;width of the minipage&#125; Text ... \ \ Images ... \ \ Tables ... \ \\end&#123;minipage&#125; ¶Adjustment When adjusting the choices is: c (for centers) t (for top) and b (for bottom). By default, c is used for centering. It is aligned by t and/or b at the highest (top line) and/or at the lowest line (bottom line). ¶Width The width can be set as absolute or as relative value. That means one can indicate 0.2 to the 6cm or 60mm or 0.3\textwidth or \textwidth as value for the width can. Whereby one must note here that the widths of several minipages those do not lay next to each other than the width of the text are larger, since otherwise everything cannot be indicated. ¶Further options Besides there are still further options, which however in practical application the minipage does not play a role like the height and the adjustment (again c, t and b) within the minipage. Example of further options 1\begin&#123;minipage&#125;[t][5cm][b]&#123;0.5\textwidth&#125; This minipage now has a defined height of 5cm, and the content will now be aligned to the bottom of the minipage. Hint A mistake that is often made is, there is a blank line between the \end{minipage} and \begin{minipage} left. Then the pages are no longer together. ¶Examples minipage Put three pictures side by side, where you should set the width of the image using width = \textwidth, if they are too wide. 123456789\begin&#123;minipage&#125;[t]&#123;0.3\textwidth&#125;\includegraphics[width=\textwidth]&#123;pic1&#125;\end&#123;minipage&#125;\begin&#123;minipage&#125;[t]&#123;0.3\textwidth&#125;\includegraphics[width=\textwidth]&#123;pic2&#125;\end&#123;minipage&#125;\begin&#123;minipage&#125;[t]&#123;0.3\textwidth&#125;\includegraphics[width=\textwidth]&#123;pic3&#125;\end&#123;minipage&#125; With minipage also text can be put next to an image, this also can be implemented by the usepackage sidecap. 12345678910\begin&#123;minipage&#125;&#123;0.5\textwidth&#125;\includegraphics[width=\textwidth]&#123;pic1&#125;\end&#123;minipage&#125;\begin&#123;minipage&#125;&#123;0.5\textwidth&#125;on pic 1 you find the word pic 1\\on pic 1 you find the word pic 1\\on pic 1 you find the word pic 1\\on pic 1 you find the word pic 1\\on pic 1 you find the word pic 1\ \vspace&#123;2.5cm&#125;\\\end&#123;minipage&#125; Two tables next to each other: 1234567891011121314151617181920\begin&#123;minipage&#125;&#123;0.2\textwidth&#125;\begin&#123;tabular&#125;&#123;|c|c|c|&#125;\hline A &amp; B &amp; C \\\hline 1 &amp; 2 &amp; 3 \\\hline 4 &amp; 5 &amp; 6 \\\hline\end&#123;tabular&#125;\end&#123;minipage&#125;\begin&#123;minipage&#125;&#123;0.2\textwidth&#125;\begin&#123;tabular&#125;&#123;c|c|c&#125; A &amp; B &amp; C \\\hline 1 &amp; 2 &amp; 3 \\\hline 4 &amp; 5 &amp; 6 \\\end&#123;tabular&#125;\end&#123;minipage&#125; ¶Reference Latex minipage]]></content>
      <categories>
        <category>tools</category>
        <category>latex</category>
      </categories>
      <tags>
        <tag>latex</tag>
        <tag>writing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Useful Git Commands]]></title>
    <url>%2F2018%2F01-06-Git-UsefulGitCommands%2F</url>
    <content type="text"><![CDATA[¶查看git追踪的文件 1git ls-files ¶更新gitignore文件 123git rm -r --cached .git add -Agit commit -m &quot;update .gitignore&quot; ¶远程仓库相关命令 检出仓库：$ git clone git://github.com/jquery/jquery.git 查看远程仓库：$ git remote -v 添加远程仓库：$ git remote add [name][url] 删除远程仓库：$ git remote rm [name] 拉取远程仓库：$ git pull [remoteName] [localBranchName] ¶推送远程仓库： $ git push [remoteName] [localBranchName] ¶移除远程仓库的文件夹 123git rm -r --cached some-directorygit commit -m "Remove the now ignored directory some-directory"git push origin master ¶分支操作相关命令 查看本地分支：$ git branch 查看远程分支：$ git branch -r 查看所有分支：$ git branch --all 创建本地分支：$ git branch [name] 切换到某分支：$ git checkout [name] 创建新分支并立即切换到该分支：$ git checkout -b [name] 删除已有分支：$ git branch -d [name] ---- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项 合并分支：$ git merge [name] ----将名称为[name]的分支与当前分支合并 创建远程分支(本地分支push到远程)：$ git push origin [name] ¶参考 Stackoverflow: Remove directory from remote repository after adding them to .gitignore git 常用命令]]></content>
      <categories>
        <category>tools</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kmeans算法及其推广]]></title>
    <url>%2F2017%2F11-03-Alg-kmeans%2F</url>
    <content type="text"><![CDATA[K-means是一种经典的聚类算法。但其有两个非常大的缺陷 K 是事先给定的，这个 K 值的选定是非常难以估计的。很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。 K-Means算法需要用初始随机种子点来搞，这个随机种子点太重要，不同的随机种子点会有得到完全不同的结果。 k-means的算法有很多推广： k-means++： 该算法有效地解决了k-means算法的第二个缺陷，通过简单直观地改进：初始的聚类中心之间的相互距离要尽可能的远，很好地改进了初始聚类中心的选取。 ISODATA：ISODATA的全称是迭代自组织数据分析法，该算法有效地解决了k-means算法的第一个缺陷，通过类的自动合并和分裂，得到较为合理的类型数目k。 Kernel K-means：传统K-means采用欧式距离进行样本间的相似度度量，显然并不是所有的数据集都适用于这种度量方式。参照支持向量机中核函数的思想，该算法将所有样本映射到另外一个特征空间中再进行聚类，就有可能改善聚类效果。 ¶k-means算法原理分析 k-means算法是聚类分析中使用最广泛的算法之一。它把n个对象根据它们的属性分为k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。 给定训练样本$X={x^{(1)}, x^{(2)}, \cdots, x^{(m)}}$，k-means算法的基本过程如下所示： (1) 任意选择$k$个初始类中心 $c_{1},c_{2},…,c_{k}$ (2) 计算$X$中的每个对象$x{(i)}$与这些中心对象的距离，并根据最小距离重新对相应对象$x{(i)}$进行划分确定其所属类$C^{(i)}$； $$ C^{(i)} = \arg\min_j ||x^{(i)} - c_j||^2 $$ (3) 重新计算每个类$C_{i}​$的中心$c_{i}​$的值 $$ C_i: c_i = \frac{1}{|C_i|} \sum_{x \in C_i} x $$ (4) 计算标准测度函数，当满足一定条件，如函数收敛时，则算法终止；如果条件不满足则重复步骤(2)，(3)。 ¶k-means算法的缺点 k-means算法虽然简单快速，但是存在下面的缺点： 聚类中心的个数K需要事先给定，但在实际中K值的选定是非常困难的，特别是遇到高维度、海量的数据集时。 k-means算法随机地确定初始聚类中心，但不同的初始聚类中心可能导致完全不同的聚类结果。 ¶k-means++算法原理分析 k-means++算法选择初始聚类中心的基本原则是：初始的聚类中心之间的相互距离要尽可能的远。它选择初始聚类中心的步骤是： (1) 从输入的数据点集合中随机选择一个点作为第一个聚类中心$c_1$ (2) 对于数据集$X$中的每一个点$x$，计算它与当前已有聚类中心之间的最短距离（即与最近的一个聚类中心的距离），用$D(x)$表示，接着计算每个样本被选为下一个聚类中心的概率 $\frac{D(x)^2}{\sum_{x \ in X} D(x)^2}$，并根据概率选择出下一个聚类中心$c_{i}$ 。即选择的原则是：$D(x)$较大的点，被选取作为聚类中心的概率较大。 (3) 重复过程(2)直到找到$k$个聚类中心。 算法的关键是第(2)步，依次计算每个数据点与最近的种子点（聚类中心）的距离，依次得到$D(1),D(2),\cdots,D(m)$构成的集合$D$，其中$m$表示数据集的大小。在$D$中，为了避免噪声，不能直接选取值最大的元素，应该选择值较大的元素，然后将其对应的数据点作为种子点。 如何选择值较大的元素呢，一种算法如下。 求所有的距离和Sum(D(x)) 取一个随机值，用权重的方式来取计算下一个“种子点”。这个算法的实现是，先取一个能落在Sum(D(x))中的随机值Random，然后用Random -= D(x)，直到其Random&lt;=0，此时的点就是下一个“种子点”。 为什么用这样的方式呢？我们换一种比较好理解的方式来说明。把集合D中的每个元素D(x)想象为一根线L(x)，线的长度就是元素的值。将这些线依次按照L(1)、L(2)、...、L(n)的顺序连接起来，组成长线L。L(1)、L(2)、…、L(n)称为L的子线。根据概率的相关知识，如果我们在L上随机选择一个点，那么这个点所在的子线很有可能是比较长的子线，而这个子线对应的数据点就可以作为种子点。 k-means++参考代码 ¶k-means++算法的缺点 虽然k-means++算法可以确定地初始化聚类中心，但是从可扩展性来看，它存在一个缺点，那就是它内在的有序性特性：下一个中心点的选择依赖于已经选择的中心点。 针对这种缺陷，k-means||算法提供了解决方法。 ¶ISODATA算法 ISODATA算法在运行过程中能够根据各个类别的实际情况进行两种操作来调整聚类中心数K：(1)分裂操作，对应着增加聚类中心数；(2)合并操作，对应着减少聚类中心数。 下面首先给出ISODATA算法的输入（输入的数据和迭代次数不再单独介绍）： 预期的聚类中心数目$K_o$：虽然在ISODATA运行过程中聚类中心数目是可变的，但还是需要由用户指定一个参考标准。事实上，该算法的聚类中心数目变动范围也由$K_o$决定。具体地，最终输出的聚类中心数目范围是 $[K_o/2, 2K_o]$。 每个类所要求的最少样本数目$N_{min}$：用于判断当某个类别所包含样本分散程度较大时是否可以进行分裂操作。如果分裂后会导致某个子类别所包含样本数目小于$N_{min}$，就不会对该类别进行分裂操作。 最大方差$Sigma$：用于衡量某个类别中样本的分散程度。当样本的分散程度超过这个值时，则有可能进行分裂操作（注意同时需要满足[2]中所述的条件）。 两个类别对应聚类中心之间所允许最小距离$d_{min}$：如果两个类别靠得非常近（即这两个类别对应聚类中心之间的距离非常小），则需要对这两个类别进行合并操作。是否进行合并的阈值就是由$d_{min}$决定。 ISODATA算法的原理非常直观，不过由于它和其他两个方法相比需要额外指定较多的参数，并且某些参数同样很难准确指定出一个较合理的值，因此ISODATA算法在实际过程中并没有K-means++受欢迎。 ¶参考文献 K-means聚类算法的三种改进介绍与对比 k-means、k-means++以及k-means算法分析 k-means聚类算法C++实现 K-means聚类算法 K-means++ clustering K-Means++算法]]></content>
      <categories>
        <category>algorithm</category>
        <category>math</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长公共子序列 & 最长公共子串]]></title>
    <url>%2F2017%2F10-29-Alg-LongestCommonSubstring%26Subsequence%2F</url>
    <content type="text"><![CDATA[最长公共子序列（longest common sequence）和最长公共子串（longest common substring）不是一回事儿。什么是子序列呢？即一个给定的序列的子序列，就是将给定序列中零个或多个元素去掉之后得到的结果。什么是子串呢？给定串中任意个连续的字符组成的子序列称为该串的子串。 ¶最长公共子序列 ¶题目分析 解决LCS问题，需要把原问题分解成若干个子问题，所以需要刻画LCS的特征。 设A=“a0，a1，…，am”，B=“b0，b1，…，bn”，且Z=“z0，z1，…，zk”为它们的最长公共子序列。不难证明有以下性质： 如果am=bn，则zk=am=bn，且“z0，z1，…，z(k-1)”是“a0，a1，…，a(m-1)”和“b0，b1，…，b(n-1)”的一个最长公共子序列； 如果am!=bn，则若zk!=am，蕴涵“z0，z1，…，zk”是“a0，a1，…，a(m-1)”和“b0，b1，…，bn”的一个最长公共子序列； 如果am!=bn，则若zk!=bn，蕴涵“z0，z1，…，zk”是“a0，a1，…，am”和“b0，b1，…，b(n-1)”的一个最长公共子序列。 ¶递归公式 假设我们用c[i,j]表示Xi 和 Yj 的LCS的长度（直接保存最长公共子序列的中间结果不现实，需要先借助LCS的长度）。其中$X = {x_1, \cdots, x_m}, Y ={y_1, \cdots,y_n}$, $X_i = {x_1,\cdots,x_i}, Y_j={y_1,\cdots,y_j}$。 可得递归公式如下： ¶最长公共子串 ¶Reference 动态规划 最长公共子序列 过程图解 最长公共子序列（LCS）问题 动态规划：求最长公共子串/最长公共子序列 最长公共子序列求解：递归与动态规划方法]]></content>
      <categories>
        <category>algorithm</category>
        <category>math</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++结构体]]></title>
    <url>%2F2017%2F09-23-Cpp-Struct%2F</url>
    <content type="text"><![CDATA[¶结构体类型 ¶结构体对象 ¶结构体对象的定义形式 定义结构体对象有三种形式： 先定义结构体类型，再定义结构体对象 12345struct DATE&#123; int year, month, day;&#125;;DATE a, b; // C++的方式struct DATE c, d; // C语言的方式 定义结构体类型的同时定义结构体对象 123struct DATE&#123; int year, month, day;&#125;d1, d2; 直接定义结构体对象 123struct &#123; int year, month, day;&#125;d1, d2; ¶结构体对象的内存形式 结构体各成员是根据在结构体定义时出现的顺序依次分配空间的，其内存长度是各个成员内存长度之和，推荐使用sizeof运算，由编译器自动确定内存长度。 注意：在有的编译器中，sizeof得到的结构体内存长度可能比理论值大。如： 123456789101112struct A&#123; int a; // 4 字节 char b; // 1 字节 short c; // 2 字节&#125;;struct B&#123; char b; // 1 字节 int a; // 4 字节 short c; // 2 字节&#125;; 这两个结构体类型成员相同（仅顺序不同），理论上它们的内存长度都是4+1+2=7。但实际上sizeof(A)的结构为8，sizeof(B)的结构为12。 原因：为了加快数据存储的速度，编译器默认情况下会对结构体成员和结构体本身（其他数据成员也是如此）存储位置进行处理，使其存放的起始位置是一定字节数的倍数，而不是顺序存放，称为字节对齐。 设对齐字节数为n(n=1, 2, 4, 8, 16)，每个字节内存长度为Li,Max(Li)为最大的成员内存长度。字节对齐的规则是： 结构体对象的起始位置能够被Max(Li)所整除； 结构体中每个成员相对于起始地址的偏移量，即对齐值应是min(n, Li)的倍数。若不满足对齐值的要求，编译器会在成员之间填充若干个字节，称为internal padding； 结构体的总长度值应是min(n, Max(Li))的倍数，若不满足总长度的要求，编译器在为最后一个成员分配空间后，会在其后填充若干个字节，称为trailing padding。 VC默认的对齐字节数为n=8，则A与B的内存长度分析如下： A的第一个成员a为int，对齐值min(n, sizeof(int))=4，成员a相对于结构体起始地址从0偏移开始，满足4字节对齐要求； 第二个成员b为char，对齐值min(n, sizeof(char))=1，b紧接着a后面从偏移4开始，满足1字节对齐要求； 第三个成员c为short，对齐值min(n, sizeof(short))=2，如果c紧接着b后面从偏移5开始就不满足2字节对齐要求，因此需要补充一个字节，从偏移6开始存储。 结构体A的内存长度为4+1+1(补充)+2=8。 B的第一个成员b为char，对齐值min(n, sizeof(char))=1，成员b相对于结构体起始地址从0偏移开始，满足1字节对齐要求； 第二个成员a为int，对齐值min(n, sizeof(int))=4，如果a紧接着b后面从偏移1开始，不满足4字节对齐要求，因此补充3个字节，从偏移4开始存储； 第三个成员c为short，对齐值min(n, sizeof(short))=2，c紧接着a后面从偏移8开始，满足2字节对齐要求。 则当前总的内存长度为1+3(补充)+4+2=10，由于n大于最大的成员内存长度4，故结构体长度应是4的倍数，因此最后需要再补充2个字节。 结构体B的内存长度为1+3(补充)+4+2+2(补充)=12。 使用预处理命令#progma pack(n)可以设定对齐字节数n(n=1, 2, 4, 8, 16)。例如： 123456789#progma pack(push) // 保存对齐字节数#progma pack(1) // 设定对齐字节数为1struct A&#123; int a; // 4 字节 char b; // 1 字节 short c; // 2 字节&#125;;#progma pack(pop) // 恢复对齐字节数 此时sizeof(A)的结果为7。 ¶Reference C++程序设计]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++函数指针]]></title>
    <url>%2F2017%2F09-22-Cpp-FunctionPointer%2F</url>
    <content type="text"><![CDATA[¶指向函数 可以将函数的地址赋值给函数指针变量，它要求函数指针变量必须与指向函数必须有相同的返回类型，参数个数，参数类型。例如，假设： 123int max(int a, int b); int min(int a, int b); int (*p)(int a, int b); //定义函数指针变量 则 1p = max; 称p指向函数max。当然也可以指向min，即它可以指向所有与它有相同的返回类型，参数个数和参数类型的函数。 ¶通过函数指针调用函数 对函数指针间接引用即是通过函数指针调用函数。通过函数指针调用函数，在实参，参数传递，返回值等方面与函数名调用相同。例如： 12c = p(a, b);b = (*p)(a, b); // 等价 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int max(int a, int b)&#123; return a&gt;b?a:b;&#125;int min(int a, int b)&#123; return a&gt;b?b:a;&#125;int main()&#123; int (*p)(int a, int b); // 定义函数指针变量 p = max; // p指向max函数 cout &lt;&lt; p(3, 4) &lt;&lt; " "; // 通过p调用函数，输出 4 p = min; // p指向min函数 cout &lt;&lt; p(3, 4) &lt;&lt; " "; // 通过p调用函数，输出 3 return 0;&#125; ¶函数指针作为参数 指向函数的指针多用于指向不同的函数，从而可以利用指针变量调用不同函数，相当于将函数调用由静态方式（固定地调用指定函数）变为动态方式（调用哪个函数由指针值来确定）。 如下面的例子： 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;cmath&gt;using namespace std;double integral(double a, double b, double (*f)(double x)) //求定积分&#123; int n = 1000, i; int h, x, s = 0.0; h = (b-a)/n; for (i = 0; i &lt;= n; i++) &#123; x = a + (i-1)*h; s = s + (f(x) + f(x+h)) * h / 2; // 调用 f 函数求 f(x) 与 f(x+h) &#125; return s;&#125;double f1(double x)&#123; return x + 1;&#125;double f2(double x)&#123; return exp(-x*x/2);&#125;double f3（double x)&#123; return x*x*x;&#125;int main()&#123; double a = 0.0, b = 1.0; cout &lt;&lt; integral(a, b, f1) + integral(a, b, f2) + integral(a, b, f3) &lt;&lt; endl; // 输出2.60562 return 0;&#125; ¶Reference C++程序设计]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logistic Regression模型]]></title>
    <url>%2F2017%2F09-21-ML-LogisticRegression%2F</url>
    <content type="text"><![CDATA[¶ ¶Reference Logistic Regression 模型简介]]></content>
      <categories>
        <category>algorithm</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络的权重初始化]]></title>
    <url>%2F2017%2F09-18-ML-WeightInitialization%2F</url>
    <content type="text"><![CDATA[文章转载自知乎聊一聊深度学习的weight initialization。 Weight Initialization matters!!!深度学习中的weight initialization对模型收敛速度和模型质量有重要影响！ 在ReLU activation function中推荐使用Xavier Initialization的变种，暂且称之为He Initialization： 12import numpy as npW = np.random.randn(node_in, node_out) / np.sqrt(node_in / 2) 使用Batch Normalization Layer可以有效降低深度网络对weight初始化的依赖： 123import tensorflow as tf# put this before nonlinear transformationlayer = tf.contrib.layers.batch_norm(layer, center=True, scale=True, is_training=True) 实验代码请参见feixia586 ¶背景 深度学习模型训练的过程本质是对weight（即参数 W）进行更新，这需要每个参数有相应的初始值。有人可能会说：“参数初始化有什么难点？直接将所有weight初始化为0或者初始化为随机数！” 对一些简单的机器学习模型，或当optimization function是convex function时，这些简单的方法确实有效。然而对于深度学习而言，非线性函数被疯狂叠加，产生如本文题图所示的non-convex function，如何选择参数初始值便成为一个值得探讨的问题 — 其本质是初始参数的选择应使得objective function便于被优化。事实上，在学术界这也是一个被actively研究的领域。 TLDR里已经涵盖了本文的核心要点，下面在正文中，我们来深入了解一下前因后果。 ¶初始化为0的可行性？ 答案是不可行。 这是一道送分题 哈哈！为什么将所有W初始化为0是错误的呢？是因为如果所有的参数都是0，那么所有神经元的输出都将是相同的，那在back propagation的时候同一层内所有神经元的行为也是相同的 — gradient相同，weight update也相同。这显然是一个不可接受的结果。 ¶可行的几种初始化方式 ¶pre-training pre-training是早期训练神经网络的有效初始化方法，一个便于理解的例子是先使用greedy layerwise auto-encoder做unsupervised pre-training，然后再做fine-tuning。具体过程可以参见UFLDL的一个tutorial，因为这不是本文重点，就在这里简略的说一下： pre-training阶段，将神经网络中的每一层取出，构造一个auto-encoder做训练，使得输入层和输出层保持一致。在这一过程中，参数得以更新，形成初始值 fine-tuning阶段，将pre-train过的每一层放回神经网络，利用pre-train阶段得到的参数初始值和训练数据对模型进行整体调整。在这一过程中，参数进一步被更新，形成最终模型。 随着数据量的增加以及activation function (参见我的另一篇文章) 的发展，pre-training的概念已经渐渐发生变化。目前，从零开始训练神经网络时我们也很少采用auto-encoder进行pre-training，而是直奔主题做模型训练。不想从零开始训练神经网络时，我们往往选择一个已经训练好的在任务A上的模型（称为pre-trained model），将其放在任务B上做模型调整（称为fine-tuning）。 ¶random initialization 随机初始化是很多人目前经常使用的方法，然而这是有弊端的，一旦随机分布选择不当，就会导致网络优化陷入困境。下面举几个例子。 核心代码见下方 12345678910111213data = tf.constant(np.random.randn(2000, 800))layer_sizes = [800 - 50 * i for i in range(0,10)]num_layers = len(layer_sizes)fcs = [] # To store fully connected layers' outputfor i in range(0, num_layers - 1): X = data if i == 0 else fcs[i - 1] node_in = layer_sizes[i] node_out = layer_sizes[i + 1] W = tf.Variable(np.random.randn(node_in, node_out)) * 0.01 fc = tf.matmul(X, W) fc = tf.nn.tanh(fc) fcs.append(fc) 这里我们创建了一个10层的神经网络，非线性变换为tanh，每一层的参数都是随机正态分布，均值为0，标准差为0.01。下图给出了每一层输出值分布的直方图。 随着层数的增加，我们看到输出值迅速向0靠拢，在后几层中，几乎所有的输出值x都很接近0！回忆优化神经网络的back propagation算法，根据链式法则，gradient等于当前函数的gradient乘以后一层的gradient，这意味着输出值x是计算gradient中的乘法因子，直接导致gradient很小，使得参数难以被更新！ 让我们将初始值调大一些： 1W = tf.Variable(np.random.randn(node_in, node_out)) 均值仍然为0，标准差现在变为1，下图是每一层输出值分布的直方图： 几乎所有的值集中在-1或1附近，神经元saturated了！注意到tanh在-1和1附近的gradient都接近0，这同样导致了gradient太小，参数难以被更新。 ¶Xavier initialization Xavier initialization可以解决上面的问题！其初始化方式也并不复杂。Xavier初始化的基本思想是保持输入和输出的方差一致，这样就避免了所有输出值都趋向于0。注意，为了问题的简便，Xavier初始化的推导过程是基于线性函数的，但是它在一些非线性神经元中也很有效。让我们试一下： 1W = tf.Variable(np.random.randn(node_in, node_out)) / np.sqrt(node_in) Woohoo！输出值在很多层之后依然保持着良好的分布，这很有利于我们优化神经网络！之前谈到Xavier initialization是在线性函数上推导得出，这说明它对非线性函数并不具有普适性，所以这个例子仅仅说明它对tanh很有效，那么对于目前最常用的ReLU神经元呢（关于不同非线性神经元的比较请参考这里）？继续做一下实验： 123W = tf.Variable(np.random.randn(node_in, node_out)) / np.sqrt(node_in)......fc = tf.nn.relu(fc) 前面看起来还不错，后面的趋势却是越来越接近0。幸运的是，He initialization可以用来解决ReLU初始化的问题。 ¶He initialization He initialization的思想是：在ReLU网络中，假定每一层有一半的神经元被激活，另一半为0，所以，要保持variance不变，只需要在Xavier的基础上再除以2： 123W = tf.Variable(np.random.randn(node_in,node_out)) / np.sqrt(node_in/2)......fc = tf.nn.relu(fc) 看起来效果非常好，推荐在ReLU网络中使用！ ¶Batch Normalization Layer Batch Normalization是一种巧妙而粗暴的方法来削弱bad initialization的影响，其基本思想是：If you want it, just make it! 我们想要的是在非线性activation之前，输出值应该有比较好的分布（例如高斯分布），以便于back propagation时计算gradient，更新weight。Batch Normalization将输出值强行做一次Gaussian Normalization和线性变换： Batch Normalization中所有的操作都是平滑可导，这使得back propagation可以有效运行并学到相应的参数$\gamma$，$\beta$。需要注意的一点是Batch Normalization在training和testing时行为有所差别。Training时$\mu_\mathcal{B}$和$\sigma_\mathcal{B}$由当前batch计算得出；在Testing时$\mu_\mathcal{B}$和$\sigma_\mathcal{B}$应使用Training时保存的均值或类似的经过处理的值，而不是由当前batch计算。 随机初始化，无Batch Normalization： 123W = tf.Variable(np.random.randn(node_in, node_out)) * 0.01......fc = tf.nn.relu(fc) 随机初始化，有Batch Normalization： 1234W = tf.Variable(np.random.randn(node_in, node_out)) * 0.01......fc = tf.contrib.layers.batch_norm(fc, center=True, scale=True, is_training=True)fc = tf.nn.relu(fc) 很容易看到，Batch Normalization的效果非常好，推荐使用！ ¶参考资料 Xavier initialization是由Xavier Glorot et al.在2010年提出，He initialization是由Kaiming He et al.在2015年提出，Batch Normalization是由Sergey Ioffe et al.在2015年提出。 另有知乎网友在评论中提到了一些其他相关工作：https://arxiv.org/abs/1511.06422， https://arxiv.org/pdf/1702.08591.pdf Xavier Glorot et al., Understanding the Difficult of Training Deep Feedforward Neural Networks Kaiming He et al., Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classfication Sergey Ioffe et al., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift Standord CS231n ¶Reference 聊一聊深度学习的weight initialization GitHub-feixia586/zhihu_material]]></content>
      <categories>
        <category>repost</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络激活函数]]></title>
    <url>%2F2017%2F09-17-ML-ActivationFunction%2F</url>
    <content type="text"><![CDATA[文章转载自知乎聊一聊深度学习的activation function。 ¶神经网络激活函数 深度学习的基本原理是基于人工神经网络，信号从一个神经元进入，经过非线性的activation function，传入到下一层神经元；再经过该层神经元的activate，继续往下传递，如此循环往复，直到输出层。正是由于这些非线性函数的反复叠加，才使得神经网络有足够的capacity来抓取复杂的pattern，在各个领域取得state-of-the-art的结果。显而易见，activation function在深度学习中举足轻重，也是很活跃的研究领域之一。目前来讲，选择怎样的activation function不在于它能否模拟真正的神经元，而在于能否便于优化整个深度神经网络。下面我们简单聊一下各类函数的特点以及为什么现在优先推荐ReLU函数。 ¶sigmoid $$ \sigma(x) = \frac{1}{1+e^{-x}} $$ Sigmoid函数是深度学习领域开始时使用频率最高的activation function。它是便于求导的平滑函数，其导数为$\sigma(x)(1-\sigma(x))$，这是优点。然而，Sigmoid有三大缺点： 容易出现gradient vanishing 函数输出并不是zero-centered 幂运算相对来讲比较耗时 Gradient Vanishing 优化神经网络的方法是Back Propagation，即导数的后向传递：先计算输出层对应的loss，然后将loss以导数的形式不断向上一层网络传递，修正相应的参数，达到降低loss的目的。 Sigmoid函数在深度网络中常常会导致导数逐渐变为0，使得参数无法被更新，神经网络无法被优化。原因在于两点： 在上图中容易看出，当$\sigma(x)$中$x$较大或较小时，导数接近0，而后向传递的数学依据是微积分求导的链式法则，当前层的导数需要之前各层导数的乘积，几个小数的相乘，结果会很接近0 Sigmoid导数的最大值是0.25，这意味着导数在每一层至少会被压缩为原来的1/4，通过两层后被变为1/16，…，通过10层后为1/1048576。请注意这里是“至少”，导数达到最大值这种情况还是很少见的。 输出不是zero-centered Sigmoid函数的输出值恒大于0，这会导致模型训练的收敛速度变慢。举例来讲，对$\sigma(\sum_i w_i x_i + b)$，如果所有$x_i$均为正数或负数，那么其对$w_i$的导数总是正数或负数，这会导致如下图红色箭头所示的阶梯式更新，这显然并非一个好的优化路径。深度学习往往需要大量时间来处理大量数据，模型的收敛速度是尤为重要的。所以，总体上来讲，训练深度学习网络尽量使用zero-centered数据 (可以经过数据预处理实现) 和zero-centered输出。 幂运算相对耗时 相对于前两项，这其实并不是一个大问题，我们目前是具备相应计算能力的，但面对深度学习中庞大的计算量，最好是能省则省。之后我们会看到，在ReLU函数中，需要做的仅仅是一个thresholding，相对于幂运算来讲会快很多。 ¶tanh $$ \tanh(x) = \frac{ex-e{-x}}{ex+e{-x}} $$ tanh读作Hyperbolic Tangent(双曲正切函数)，如上图所示，它解决了zero-centered的输出问题，然而，gradient vanishing的问题和幂运算的问题仍然存在。 ¶ReLU (Rectified Linear Unit) $$ \text{ReLU}(x) = \max(0, x) $$ ReLU函数其实就是一个取最大值函数，注意这并不是全区间可导的，但是我们可以取sub-gradient，如上图所示。ReLU虽然简单，但却是近几年的重要成果，有以下几大优点： 解决了gradient vanishing问题 (在正区间) 计算速度非常快，只需要判断输入是否大于0 收敛速度远快于sigmoid和tanh ReLU也有几个需要特别注意的问题： ReLU的输出不是zero-centered Dead ReLU Problem，指的是某些神经元可能永远不会被激活，导致相应的参数永远不能被更新。有两个主要原因可能导致这种情况产生: 非常不幸的参数初始化，这种情况比较少见 learning rate太高导致在训练过程中参数更新太大，不幸使网络进入这种状态。解决方法是可以采用Xavier初始化方法，以及避免将learning rate设置太大或使用adagrad等自动调节learning rate的算法。 尽管存在这两个问题，ReLU目前仍是最常用的activation function，在搭建人工神经网络的时候推荐优先尝试！ ¶Leaky ReLU $$ f(x) = \max(0.01x, x) $$ 人们为了解决Dead ReLU Problem，提出了将ReLU的前半段设为$0.01x$而非0。另外一种直观的想法是基于参数的方法，即Parametric ReLU: $f(x) = \max(\alpha x, x)$，其中$\alpha$可由back propagation学出来。理论上来讲，Leaky ReLU有ReLU的所有优点，外加不会有Dead ReLU问题，但是在实际操作当中，并没有完全证明Leaky ReLU总是好于ReLU。 ¶ELU (Exponential Linear Units) $$ f(x) = \begin{cases} x, \qquad \qquad \text{if} ,x&gt;0 \ \alpha(e^x-1), ,,; \textrm{otherwise} \end{cases} $$ ELU也是为解决ReLU存在的问题而提出，显然，ELU有ReLU的基本所有优点，以及: 不会有Deal ReLU问题 输出的均值接近0，zero-centered 它的一个小问题在于计算量稍大。类似于Leaky ReLU，理论上虽然好于ReLU，但在实际使用中目前并没有好的证据ELU总是优于ReLU。 ¶Reference 知乎 聊一聊深度学习的activation function]]></content>
      <categories>
        <category>repost</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++利用宏控制打印]]></title>
    <url>%2F2017%2F09-17-Cpp-DbgPrintf%2F</url>
    <content type="text"><![CDATA[¶利用宏控制打印 在程序调试时，我们经常需要输出一些调试信息，当调试完毕后，就不再需要使用了。那怎么快速的在调试状态和发布状态切换呢？通常我们使用预编译加宏定义来处理这个问题，例如： 123#ifdef DEBUG 调试代码#endif 如果我们使用printf来显示一些调试信息，那么每个地方都加上#ifdef和#endif就很麻烦了。我们可以定义一个DbgPrintf的函 数来专门处理这些事情，只在DbgPrintf函数内放上#ifdef和#endif就行了。但是这样代码在运行时，还是有调用一次函数的，浪费了时间。 那么可不可以利用宏定义，实现完全没有编译代码产生的宏呢？ 可以尝试下面的宏代码： 1234567//#define MYDEBUG#ifdef MYDEBUG#define DbgPrintf printf#else#define DbgPrintf /\/DbgPrintf#endif 如果MYDEBUG已经定义了，则用printf去代替DbgPrintf了。 如果MYDEBUG未定义的情形，这个宏定义实际上是将DbgPrintf定义成了//DbgPrintf，由于续行符的作用，#define定义时不会发现注释符//，但是在展开到代码之后，就成了注释符//了，也就是说，如果你原来的代码是DbgPrintf(&quot;%d&quot;,x);，经过这个宏展开后成了//DbgPrintf(&quot;%d&quot;,x)，相当于自动在前面加了注释符//。 注意： 续行符后面的/一定要顶格写，否则就不是//了。 另外，这个宏只能单独一行使用，因为它将该行后面的代码都注释掉了。 ¶打印信息的同时输出位置 通过logI输出一些程序运行信息，可以借助logInfo控制是否打印，对于警告和错误，分别通过logW和logE输出。 12345678910#define logInfo#ifdef logInfo#define logI (printf("--info-- in [%d@%s] ",__LINE__, __FUNCTION__), printf) #else#define logI /\/logI#endif#define logW (printf("--warn-- in [%d@%s] ",__LINE__, __FUNCTION__), printf) #define logE (printf("--error- in [%d@%s] ",__LINE__, __FUNCTION__), printf) ¶Reference 利用宏控制打印]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ STL vector]]></title>
    <url>%2F2017%2F09-14-Cpp-vector%2F</url>
    <content type="text"><![CDATA[¶C++ STL vector简介 vector是一个类模板，模板本身不是类或函数（类模板和函数模板），相反可以将模板看作编译器生成类或函数的一份说明。编译器根据模板创建类或函数的过程称为实例化(instantiation)，当使用模板时，需要指出编译器把类或函数实例化成何种类型。 C++能允许大多数类型的对象作为vector的元素，但是因为引用不是对象，所以不存在包含引用的vector。 vector常见成员函数 size() 返回容器中有多少个元素 capacity() 返回容器当前已经分配的内存能容纳多少个元素 resize(n) 强迫容器改变到包含n个元素的状态 reserve(n) 强迫容器把它的容量变为至少n，前提是n不小于当前的大小 ¶vector对象增长机制 为了支持快速随机访问，vector将元素连续存储，如果没有空间容纳新元素，而不得不获取新的内存空间时，vector和string的实现通常会分配比新的空间需求更大的内存空间，然后将已有元素从旧位置移动到新空间中，然后添加新元素，析构掉旧内存中的对象并释放旧存储空间。 vector和string提供了一些成员函数允许我们与它的实现中内存分配部分互动。 c.shrink_to_fit() 将capacity()减少为size()同样大小 c.capacity() 不重新分配内存，c可以保存多少元素 c.reserve(n) 分配至少能容纳n个元素的内存空间 注意： shrink_to_fit()只适用于vector, string和deque capacity()和reserve只适用于vector和 string 只有当需要的内存空间超过当前容量时，reserve调用才会改变vector的容量。如果需求大于当前容量，reserve至少分配与需求一样大的内存空间（可能更大）。如果小于等于当前容量，reserve什么也不做。 在新标准库中，可以调用shrink_to_fit来要求vector, string和deque退回不需要的内存空间。但是，具体的实现可以选择忽略此请求，即==调用shrink_to_fit也并不保证一定退回内存空间==。 ¶vector内存回收机制 由于vector的内存占用空间只增不减，比如你首先分配了10,000个字节，然后erase掉后面9,999个，留下一个有效元素，但是内存占用仍为10,000个。所有内存空间是在vector析构时候才能被系统回收。empty用来检测容器是否为空的，clear可以清空所有元素。但是即使clear，vector所占用的内存空间依然如故，无法保证内存的回收。 如果需要空间动态缩小，可以考虑使用deque。如果非vector不可，可以用swap()来帮助你释放内存。具体方法如下： 1234vector&lt;int&gt; nums; nums.push_back(1);nums.push_back(2);vector&lt;int&gt;().swap(nums); //或者nums.swap(vector&lt;int&gt; ()) 或者如下所示，使用一对大括号，意思一样的： 12345//加一对大括号是可以让tmp退出&#123;&#125;的时候自动析构&#123; std::vector&lt;int&gt; tmp = nums; nums.swap(tmp); &#125; swap()是交换函数，使vector离开其自身的作用域，从而强制释放vector所占的内存空间，总而言之，释放vector内存最简单的方法是vector&lt;int&gt;().swap(nums)。但是如果nums是一个类的成员，不能把vector&lt;int&gt;().swap(nums)写进类的析构函数中，否则会导致double free or corruption (fasttop)的错误，原因可能是重复释放内存。 如果vector中存放的是指针，那么当vector销毁时，这些指针指向的对象不会被销毁，那么内存就不会被释放。如下面这种情况，vector中的元素时由new操作动态申请出来的对象指针： 123456789void doSomething()&#123; vector&lt;int*&gt; vip; for (int i = 0; i &lt; 5; i++) vip.push_back(new int); // do something for (vector&lt;int*&gt;::iterator i = vip.begin(); i != vip.end(); ++i) delete *i;&#125; ¶Reference C++ Primer - Chapter 3.3 &amp; 9.4 Effective STL - Item 17]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bundle Adjustment简述]]></title>
    <url>%2F2017%2F09-13-CV-BundleAdjustment%2F</url>
    <content type="text"><![CDATA[¶Bundle Adjustment简述 在SFM (structure from motion)的计算中BA (Bundle Adjustment)作为最后一步优化具有很重要的作用，在近几年兴起的基于图的SLAM (simultaneous localization and mapping)算法里面使用了图优化替代了原来的滤波器，这里所谓的图优化其实也是指BA。其实很多经典的文献对于BA都有深深浅浅的介绍，如果想对BA的全过程做一个全面的更深层次的了解，推荐阅读 Bundle Adjustment —A Modern Synthesis. ¶什么是BA Bundle Adjustment中文译为光束法平差，还有其他一些翻译如束调整、捆集调整或者捆绑调整等等。 所谓bundle，来源于bundle of light，其本意就是指的光束，这些光束指的是三维空间中的点投影到像平面上的光束，而重投影误差正是利用这些光束来构建的，因此称为光束法强调光束也正是描述其优化模型是如何建立的。 用一句话来描述BA那就是，BA的本质是一个优化模型，其目的是最小化重投影误差。重投影也就是指的第二次投影， 第一次投影指的是相机在拍照的时候三维空间点投影到图像上 然后我们利用这些图像对一些特征点进行三角定位 (triangulation)，利用几何信息构建三角形来确定三维空间点的位置，参考对极几何 最后利用计算得到的三维点的坐标（注意不是真实的）和我们计算得到的相机矩阵（当然也不是真实的）进行第二次投影，也就是重投影 重投影误差指的就是真实三维空间点在图像平面上的投影（也就是图像上的像素点）和重投影（其实是用我们的计算值得到的虚拟的像素点）的差值，因为种种原因计算得到的值和实际情况不会完全相符，也就是这个差值不可能恰好为0，此时也就需要将这些差值的和最小化获取 最优的相机参数及三维空间点的坐标。 $$ \min_{a_j, b_i} \sum_{i=1}^n \sum_{j=1}^m v_{ij} d(Q(a_j, b_i), x_{ij})^2 $$ 其中， $n$个3D点在$m$个view（拍摄场景）中， 向量$X_{ij}$：图像j上的第i个点projection（坐标） 值$v_{ij}$：如果点i在图像j上有映射，则$v_{ij}=1$; else $v_{ij}=0$; 每个图像j由向量$a_j$参数化 每个3D点由$b_i$参数化 $Q(a_i,b_j)$:点i在图像j上的predicted projection $d(x,y)$:向量$x,y$的欧式距离 ¶Reference Bundle Adjustment - 基于feature的3D场景重建算法 Bundle Adjustment 简述]]></content>
      <categories>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Softmax Regression in TensorFlow]]></title>
    <url>%2F2017%2F09-08-TF-SoftmaxReg4MNIST%2F</url>
    <content type="text"><![CDATA[¶Softmax Regression TensorFlow实现Softmax Regression识别手写数字，数据集用MINIST(Mixed National Institute of Standards and Technology database)，其由几万张$28 \times 28$像素的手写数字组成，这些图片只包含灰度信息。我们的任务就是对这些图片进行分类，转成0~9共10类。 ¶定义算法公式 在我们使用多分类任务时，通常需要使用Softmax Regression模型。它的工作原理很简单，将可以判定为某类的特征相加，然后将这些特征转化为判定是这一类的概率。上述特征可以通过一些简单的方法得到，比如对所有的像素求一个加权和，而权重是模型根据数据自动学习，训练出来的。即可以表示为 $$ feature_i = \sum_i W_{ij}x_j + b_i $$ 然后对所有特征计算softmax，即 $$ y = softmax(feature) $$ 其中softmax函数先对变量计算一个$\exp$函数，然后进行标准化（让所有类别输出的概率值和为1）。即 $$ softmax(x)_i = \frac{\exp(x_i)}{\sum_j \exp(x_j)} $$ 所以整个模型可以表示为 $$ y = softmax(Wx+b) $$ 其TensorFlow的实现是 123456import tensorflow as tfsess = tf.InteractiveSession()x = tf.placeholder(tf.float32, [None, 784])W = tf.Variable(tf.zeros([784, 10]))b = tf.Variable(tf.zeros([10]))y = tf.nn.softmax(tf.matmul(x, W) + b) 首先载入TensorFlow库，并创建一个InteractiveSession，使用这个命令会将这个session注册为默认的session，之后的运算默认跑在这个session里，不同session之间的数据和运算应该都是互相独立的。接下来创建一个784]```代表tensor的shape，这里None指不限条数的输入，784代表每条输入是一个784维的向量。接下来创建模型的weights和bias变量，```Variables```是用来存储模型参数的，不同于存储数据的tensor一旦使用掉就会消失，```Variables```在模型训练迭代中是持久化的，她可以长期存在并在每轮迭代中被更新。1234567891011121314## 定义损失函数为了训练模型，一般需要定义一个 Loss Function来描述模型对问题的分类精度。Loss越小，代表模型的分类结果与真实值的偏差越小，也就是说模型越精确。训练的目的就是不断将这个Loss减少，达到一个全局最优或者局部最优解。对于多分类问题，通常使用 Cross-entropy 作为 Loss Function，用它来判断模型对真是概率分布估计的准确程度。其定义如下$$H_&#123;y&apos;&#125;(y)= - \sum y&apos;_i \log(y_i)$$在TensorFlow中，定义Cross-entropy的代码如下```pythony_ = tf.placeholder(tf.float32, [None, 10])cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=[1])) 先定义一个123456789## 选择优化方法并训练模型有了算法定义和损失函数，定义一个优化方法便可以开始训练。这里采用随机梯度下降(Stochastic Gradient Descent, SGD)算法。TensorFlow用SGD训练模型的的实现是```pythontrain_step = tf.train.GradientDescentOptimizier(0.5).moinimize(cross_entropy)tf.global_variables_initializer().run()for i in rang(1000): batch_xs, batch_ys = mnist.train.next_batch9100） train_step.run(&#123;x: batch_xs, y_: batch_ys&#125;) TensorFlow可以根据我们定义的整个计算图自动求导，并根据反向传播(Back Propagation)算法进行训练，在每一轮迭代时更新参数来减少Loss。 这里每次都随机从训练集中抽取100条样本构成一个mini-batch，并feed给1234567## 评测算法完成训练后，还需要对模型的准确率进行验证。```pythoncorrect_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))print(accuracy.eval(&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)) 将测试数据的特征和Label输入评测流程Regression在MNIST数据进行分类识别，在测试集上的平均准确率可达92%左右。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364## 完整代码```python&quot;&quot;&quot;A very simple MNIST classifier.See extensive documentation athttps://www.tensorflow.org/get_started/mnist/beginners&quot;&quot;&quot;from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionimport argparseimport sysfrom tensorflow.examples.tutorials.mnist import input_dataimport tensorflow as tfFLAGS = Nonedef main(_): # Import data mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True) # Create the model x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.matmul(x, W) + b # Define loss and optimizer y_ = tf.placeholder(tf.float32, [None, 10]) # The raw formulation of cross-entropy, # tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)), reduction_indices=[1])) # can be numerically unstable. # # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw # outputs of &apos;y&apos;, and then average across the batch. cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)) train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) sess = tf.InteractiveSession() tf.global_variables_initializer().run() # Train for _ in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) # Test trained model correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))if __name__ == &apos;__main__&apos;: parser = argparse.ArgumentParser() parser.add_argument(&apos;--data_dir&apos;, type=str, default=&apos;./mnist/input_data&apos;, help=&apos;Directory for storing input data&apos;) FLAGS, unparsed = parser.parse_known_args() tf.app.run(main=main, argv=[sys.argv[0]] + unparsed) ¶Reference TensorFlow: MNIST For ML Beginners]]></content>
      <categories>
        <category>algorithm</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Doxygen生成程序文档]]></title>
    <url>%2F2017%2F09-07-Cpp-DocCodeWithDoxygen%2F</url>
    <content type="text"><![CDATA[¶生成配置文件 在项目中新建doc文件夹，在doc文件夹中打开Power Shell（Shift+右键，选择在此处打开Power Shell窗口），键入 1doxygen -g 会在当前目录下生成Doxyfile文件，该文件是Doxygen工程的配置文件，里面含有一些配置信息。 ¶修改配置信息 修改 PROJECT_NAME 等其他一些有关的项目信息； 设置 INPUT ,这个标记创建一个以空格分隔的所有目录的列表，这个列表包含需要生成文档的 C/C++ 源代码文件和头文件。例如，请考虑以下代码片段： INPUT = …/src …/include 如果源代码层次结构是嵌套的，而且需要为所有层次上的 C/C++ 文件生成文档，就把 RECURSIVE 标记设置为 Yes. 如果注释中含有中文，将 INPUT_ENCODING 从默认的UTF-8改为GBK。 设置 OUTPUT_DIRECTORY 即文档的输出目录； 将 GENERATE_LATEX 从默认的 YES 改为 NO，接下来，修改HTML的显示方式，将 DISABLE_INDEX，GENERATE_TREEVIEW 从默认的 NO 均改为 YES。 将 EXTRACT_ALL 从默认的NO改为YES，这个标记告诉 doxygen，即使各个类或函数没有文档，也要提取信息。必须把这个标记设置为 Yes。 将 EXTRACT_PRIVATE 标记设置为Yes。否则，文档不包含类的私有数据成员。 将 EXTRACT_STATIC 标记设置为 Yes。否则，文档不包含文件的静态成员（函数和变量）。 如果需要中文文档，将 OUTPUT_LANGUAGE 标记设置为Chinese。 如果要添加公式支持，将 USE_MATHJAX 标记设置为YES。 ¶生成文档 在Power Shell中键入 1doxygen .\Doxyfile ¶配置文件参考 Doxyfile Example ¶常用命令 命令 @file 档案的批注说明 @author 作者的信息 @brief 用于class 或function的简易说明 @param 主要用于函数说明中，后面接参数的名字，然后再接关于该参数的说明 @return 描述该函数的返回值情况 @retval 描述返回值类型 @note 注解 @attention 注意 @warning 警告信息 @enum 引用了某个枚举，Doxygen会在该枚举处产生一个链接 eg：@enum CTest::MyEnum @var 引用了某个变量，Doxygen会在该枚举处产生一个链接 eg：@var CTest::m_FileKey @class 引用某个类，格式：@class [] [] eg: @class CTest “inc/class.h” @exception 可能产生的异常描述 eg: @exception 本函数执行可能会产生超出范围的异常 字体 word``` 用斜体italics强调单词word，如果要让多个单词斜体，用 ```multiple words```1- ```\b word``` 用黑体bold强调单词word，如果要让多个单词黑体，用 ```&lt;b&gt;multiple words&lt;/b&gt; word``` 用打印机字体typewriter显示单词word，一般用来引用代码中的单词。 跟```word```等价，如果有多个单词，用```word```。123456 - 3. 公式 - 注意要将*USE_MATHJAX* 标记设置为YES， - 行内公式：将公式写在一对```\f$```之间。 eg: ```The distance between \f$(x_1,y_1)\f$ and \f$(x_2,y_2)\f$ is \f$\sqrt&#123;(x_2-x_1)^2+(y_2-y_1)^2&#125;\f$. 行间公式：将公式写在一对1eg: \f[ |I_2|=\left| \int_{0}^T \psi(t) \left{ u(a,t)- \int_{\gamma(t)}^a \frac{d\theta}{k(\theta,t)} \int_{a}^\theta c(\xi)u_t(\xi,t),d\xi \right} dt \right| ] 参考Doxygen-Including formulas 表格 参考Doxygen-Including tables 图片 参考Doxygen-Graphs and diagrams ¶Reference Doxygen Manual Doxygen Special Commands Doxygen HTML Commands 使用doxygen为C/C++程序生成中文文档 Doxygen 10 分钟入门教程 学习用 doxygen 生成源码文档]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ICP算法]]></title>
    <url>%2F2017%2F08-29-Alg-ICP%2F</url>
    <content type="text"><![CDATA[ICP（Iterative Closest Point），即迭代最近点算法，是经典的数据配准算法。其特征在于，通过求取源点云和目标点云之间的对应点对，基于对应点对构造旋转平移矩阵，并利用所求矩阵，将源点云变换到目标点云的坐标系下，估计变换后源点云与目标点云的误差函数，若误差函数值大于阀值，则迭代进行上述运算直到满足给定的误差要求. ICP算法采用最小二乘估计计算变换矩阵，原理简单且具有较好的精度，但是由于采用了迭代计算，导致算法计算速度较慢，而且采用ICP进行配准计算时，其对待配准点云的初始位置有一定要求，若所选初始位置不合理，则会导致算法陷入局部最优。 ¶Align 3D Data 如果如果空间中两组点云之间的对应关系已经明确，则很容易求得两者之间的刚性变换，即旋转和平移共6个参数，但这种对应关系一般很难事先知道。 ICP算法假设两组点云之间的对应关系由最近点确定，一步步将源点云匹配$P$到目标点云$Q$。 ¶Basic ICP 在源点云 $P$ 中选择一些随机点 $p_i, i=1,2, \cdots,n$ 在目标点云 $Q$ 中找到每个点 $p_i$ 的最近点 $q_i$ 剔除一些距离较远的点对 构建距离误差函数 $$E = \sum_i (Rp_i + t - q_i)^2$$ 极小化误差函数 ¶Error Metric Point-to-Point Error Metric $$E = \sum_i (Rp_i + t - q_i)^2$$ Point-to-Plane Error Metric $$E = \sum_i ((Rp_i + t - q_i)\cdot n_i)^2$$ 非线性最小二乘问题，但可以线性化，假设$\theta \approx 0$，则$\sin(\theta) \approx 0$，$\cos(\theta) \approx 1$，忽略二次项，可以得到一个线性的最小二乘问题，并用SVD分解求解。 ¶Reference Dynamic Geometry Processing]]></content>
      <categories>
        <category>algorithm</category>
        <category>cg</category>
      </categories>
      <tags>
        <tag>cg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rules of C++]]></title>
    <url>%2F2017%2F08-28-Cpp-CppRules%2F</url>
    <content type="text"><![CDATA[¶Rules of C++ 如果一个类定义没有显式申明一个复制构造函数，一个非显式的函数会隐式地定义。 如果该类定义申明了一个移动构造函数或者移动赋值运算符，隐式定义的复制构造函数被定义为以删除的；否则，其被定义为默认的。当该类有一个用户申明的复制赋值运算符或者析构函数，后者的情况被弃用。 If the class definition does not explicitly declare a copy constructor, a non-explicit one is declared implicitly. If the class definition declares a move constructor or move assignment operator, the implicitly declared copy constructor is defined as deleted; otherwise, it is defined as defaulted (8.4). The latter case is deprecated if the class has a user-declared copy assignment operator or a user-declared destructor. ¶三/五/零规则 ¶三规则 若一个类需要用户定义析构函数、用户定义复制构造函数或用户定义的复制赋值运算符，则它几乎肯定要求三者全体。 因为 C++ 在各种场合（传递/按值返回、操作容器等）复制和复制赋值用户定义的对象，若可访问则会调用这些特殊成员函数，且若它们不为用户定义，则为编译器隐式定义。 若该类管理资源，而资源的柄是非类类型（生指针、 POSIX 文件描述符等），则隐式定义的特殊成员函数大体是错误的，其中析构函数无操作而复制构造函数/赋值运算符进行“浅复制”（复制柄的值，而不备份底下的资源）。 1234567891011121314151617181920212223242526272829303132class rule_of_three&#123; char* cstring; // 用于指向动态分配内存块的句柄的生指针 public: rule_of_three(const char* arg) : cstring(new char[std::strlen(arg)+1]) // 分配 &#123; std::strcpy(cstring, arg); // 复制内容 &#125; ~rule_of_three() &#123; delete[] cstring; // 解分配 &#125; rule_of_three(const rule_of_three&amp; other) // 复制构造函数 &#123; cstring = new char[std::strlen(other.cstring) + 1]; std::strcpy(cstring, other.cstring); &#125; rule_of_three&amp; operator=(const rule_of_three&amp; other) // 复制赋值 &#123; char* tmp_cstring = new char[std::strlen(other.cstring) + 1]; std::strcpy(tmp_cstring, other.cstring); delete[] cstring; cstring = tmp_cstring; return *this; &#125; // 另可重用析构函数和复制构造函数 // rule_of_three&amp; operator=(rule_of_three other) // &#123; // std::swap(cstring, other.cstring); // return *this; // &#125;&#125;; 通过可复制柄管理不可复制资源的类，必须声明复制赋值和复制构造函数为私有并不提供其定义，或定义它们为被删除。这是另一种三规则：删除一者并保留另一者为隐式定义很可能导致错误。 ¶五规则 因为用户定义析构函数、复制构造函数或复制赋值运算符的存在阻止移动构造函数和移动赋值运算符的隐式定义，任何需要移动语义的类必须声明所有五个特殊成员函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class rule_of_five&#123; char* cstring; // 用作指向动态分配内存块的句柄的生指针 public: rule_of_five(const char* arg) : cstring(new char[std::strlen(arg)+1]) // 分配 &#123; std::strcpy(cstring, arg); // 复制内容 &#125; ~rule_of_five() &#123; delete[] cstring; // 解分配 &#125; rule_of_five(const rule_of_five&amp; other) // 复制构造函数 &#123; cstring = new char[std::strlen(other.cstring) + 1]; std::strcpy(cstring, other.cstring); &#125; rule_of_five(rule_of_five&amp;&amp; other) : cstring(other.cstring) // 移动构造函数 &#123; other.cstring = nullptr; &#125; rule_of_five&amp; operator=(const rule_of_five&amp; other) // 复制赋值 &#123; char* tmp_cstring = new char[std::strlen(other.cstring) + 1]; std::strcpy(tmp_cstring, other.cstring); delete[] cstring; cstring = tmp_cstring; return *this; &#125; rule_of_five&amp; operator=(rule_of_five&amp;&amp; other) // 移动赋值 &#123; if(this!=&amp;other) // 阻止自移动 &#123; delete[] cstring; cstring = other.cstring; other.cstring = nullptr; &#125; return *this; &#125; // 另可将二个赋值运算符以下面的替换 // rule_of_five&amp; operator=(rule_of_five other) // &#123; // std::swap(cstring, other.cstring); // return *this; // &#125;&#125;; 不同于三规则，不提供移动构造函数和移动赋值运算符通常不是错误，然而是对优化机会的错失。 ¶零规则 拥有自定义析构函数、复制/移动构造函数或复制/移动赋值运算符的类应该排他地处理所有权（这遵循单一责任原则）。其他类不该有自定义析构函数、复制/移动构造函数或复制/移动赋值运算符。 123456class rule_of_zero&#123; std::string cppstring; public: rule_of_zero(const std::string&amp; arg) : cppstring(arg) &#123;&#125;&#125;; 当基类为多态使用而设时，其析构函数可能必须声明为公开且为虚。这阻止隐式移动（并将隐式复制过时化），从而特殊成员函数必须声明为默认 123456789class base_of_five_defaults&#123; public: base_of_five_defaults(const base_of_five_defaults&amp;) = default; base_of_five_defaults(base_of_five_defaults&amp;&amp;) = default; base_of_five_defaults&amp; operator=(const base_of_five_defaults&amp;) = default; base_of_five_defaults&amp; operator=(base_of_five_defaults&amp;&amp;) = default; virtual ~base_of_five_defaults() = default;&#125;; 然而，若导出类不被动态分配，或仅在被存储于 std::shared_ptr 时动态分配（例如通过 std::make_shared ），则可避免它：共享指针调用导出类的析构函数，即使在被转型为 std::shared_ptr 后。 ¶Reference 三/五/零规则 C++ Compiler Error C2280 “attempting to reference a deleted function” in Visual Studio 2013 and 2015 Does rule of three/five apply to inheritance and virtual destructors?]]></content>
      <categories>
        <category>coding</category>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度传感器]]></title>
    <url>%2F2017%2F08-27-CG-DepthSensor%2F</url>
    <content type="text"><![CDATA[¶Microsoft Kinect Kinece二代的技术来自于PrimeSense，微软收购了这家以色列公司。 Windows Kinect Sensor 包含 RGB相机 An RGB camera that stores three channel data in a 1280x960 resolution. This makes capturing a color image possible. IR红外发射器和深度传感器 An infrared (IR) emitter and an IR depth sensor. The emitter emits infrared light beams and the depth sensor reads the IR beams reflected back to the sensor. The reflected beams are converted into depth information measuring the distance between an object and the sensor. This makes capturing a depth image possible. 麦克风阵列 A multi-array microphone, which contains four microphones for capturing sound. Because there are four microphones, it is possible to record audio as well as find the location of the sound source and the direction of the audio wave. 3轴加速计 A 3-axis accelerometer configured for a 2G range, where G is the acceleration due to gravity. It is possible to use the accelerometer to determine the current orientation of the Kinect. Kinect Array Specifications Viewing angle 43° vertical by 57° horizontal field of view Vertical tilt range ±27° Frame rate (depth and color stream) 30 frames per second (FPS) Audio format 16-kHz, 24-bit mono pulse code modulation (PCM) Audio input characteristics A four-microphone array with 24-bit analog-to-digital converter (ADC) and Kinect-resident signal processing including acoustic echo cancellation and noise suppression Accelerometer characteristics A 2G/4G/8G accelerometer configured for the 2G range, with a 1° accuracy upper limit. The resolution of the depth stream is dependent on the frame rate, and is specified by the DepthImageFormat Enumeration enumeration. Similarly, the resolution of the color stream is specified by the ColorImageFormat Enumeration enumeration. See the depth space range section to see the depth data ranges as well as values for out-of-range data. ¶Intel RealSense ¶Intel RealSense Camera R200 Operating Range (Min-Max) 0.5m - 3.5m ¶Reference Kinect for Windows Sensor Components and Specifications Specifications for the Intel RealSense Camera R200]]></content>
      <categories>
        <category>knowledge</category>
        <category>cv/cg</category>
      </categories>
      <tags>
        <tag>cg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[方向梯度直方图]]></title>
    <url>%2F2017%2F08-20-CV-HOG%2F</url>
    <content type="text"><![CDATA[¶算法简介 方向梯度直方图(Histogram of Oriented Gradient, HOG)是应用在计算机视觉和图像处理领域，用于目标检测(Object detection)的特征描述器。 ¶算法步骤 ¶Reference wikipedia:方向梯度直方图]]></content>
      <categories>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随机抽样一致算法]]></title>
    <url>%2F2017%2F08-20-CV-RANSAC%2F</url>
    <content type="text"><![CDATA[¶算法简介 ¶算法步骤 ¶Reference wikipedia：随机抽样一致算法]]></content>
      <categories>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SIFT-尺度不变特征转换]]></title>
    <url>%2F2017%2F08-20-CV-SIFT%2F</url>
    <content type="text"><![CDATA[¶算法简介 尺度不变特征转换(Scale-invariant feature transform 或 SIFT)是一种电脑视觉的算法用来侦测与描述影像中的局部性特征，它在空间尺度中寻找极值点，并提取出其位置、尺度、旋转不变量，此算法由 David Lowe 在1999年所发表，2004年完善总结。 Sift算法就是用不同尺度（标准差）的高斯函数对图像进行平滑，然后比较平滑后图像的差别， 差别大的像素就是特征明显的点。 Sift（Scale Invariant Feature Transform）是一个很好的图像匹配算法，同时能处理亮度、平移、旋转、尺度的变化，利用特征点来提取特征描述符，最后在特征描述符之间寻找匹配。 ¶算法步骤 构建尺度空间，检测极值点，获得尺度不变性 特征点过滤并进行精确定位，剔除不稳定的特征点 在特征点处提取特征描述符，为特征点分配方向值 生成特征描述子，利用特征描述符寻找匹配点 计算变换参数 ¶Reference wikipedia：尺度不变特征转换 经典算法研究系列：九、图像特征提取与匹配之SIFT算法]]></content>
      <categories>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉中的 F 矩阵，E 矩阵与 H 矩阵]]></title>
    <url>%2F2017%2F08-14-CV-Matrix-F-E-H%2F</url>
    <content type="text"><![CDATA[¶F 矩阵 - 基础矩阵 (Fundamental Matrix) 在计算机视觉中，基础矩阵 $\mathrm {F}$ 是一个3×3的矩阵，表达了立体像对的像点之间的对应关系。在对极几何中，对于立体像对中的一对同名点，它们的齐次化图像坐标分别为 $p$ 与 $p’$，$\mathrm {F} p$ 表示一条必定经过 $p$ 的直线（极线）。这意味着立体像对的所有同名点对都满足： $$ p’\mathrm {F} p=0 $$ F 矩阵中蕴含了立体像对的两幅图像在拍摄时相互之间的空间几何关系（外参数）以及相机检校参数（内参数），包括旋转、位移、像主点坐标和焦距。因为 $\mathrm {F}$ 矩阵的秩为2，并且可以自由缩放（尺度化），所以只需7对同名点即可估算出 F 的值。 尽管本质矩阵也满足类似的关系式，但本质矩阵中并不蕴含相机检校参数。本质矩阵与基础矩阵之间的关系可由下式表达： $$ \mathrm {E} = \mathrm{K’^TFK} $$ 其中 $\mathrm{K}$ 和 $\mathrm{K’}$ 分别为两个相机的内参数矩阵。 ¶E 矩阵 - 本质矩阵 (Essential Matrix) 本质矩阵也满足类似的关系式， ¶H 矩阵 - 单应矩阵 (Homography) ¶推导 基础矩阵有许多种推导方式，下面介绍其中一种。 在双相机的拍摄场景中建立一个空间直角坐标系，称为世界坐标系（如下图中蓝色坐标系）。物点就是场景中物体表面上的点，比如说点 $P$ 在世界坐标系中的坐标为 $(X,Y,Z)^T$。 相机的光心从物理上讲就是相机镜头组的光学中心。以光心为原点，主光轴为Z轴建立空间直角坐标系，称为相机坐标系（如下图中绿色和红色坐标系）。像平面在相机坐标系中的方程即为 $z=1$，像点就是在物点在像平面上的投影，这个投影关系是透视投影。 用一句话来概括相机的拍摄模型，就是物点、像点、光心三点一线，此模型称为针孔相机模型。在此模型中，世界坐标系到左右相机坐标系的变换是刚性变换，即只包含旋转和平移，因此我们分别用增广矩阵 $[R;t]$ 和 $[R’;t’]$ 表示，其中 $R$ 和 $R’$ 是 $3 \times 3$ 的旋转矩阵， $t$ 和 $t’$ 为平移向量。令 $\tilde{P}$ 为 $P$ 的齐次化坐标，那么物点 $P$ 在左右相机坐标系下的坐标分别为 $$ P_{cam}(X_{C},Y_{C},Z_{C})^T=[R;t]\tilde {P} $$ 和 $$ P_{cam}’(X_{C’},Y_{C’},Z_{C’})^T = [R’;t’]{\tilde {P}} $$ 以一台相机为例，如图所示， $C$ 为相机光心，$Z$ 轴为主轴。物点在相机坐标系下的坐标 $\tilde{P}$ 和以相片左下角为原点的像点坐标 $p$ 有如下关系： $$ x = (\frac{f_xX_c}{Z_c} + x_0)^T $$ $$ y = (\frac{f_yY_c}{Z_c} + y_0)^T $$ 式中 $(x_{0},y_{0},f)$ 为像主点在相机坐标系下的坐标。 设两相机内参数矩阵同为： $$ K = \left( \begin{matrix} f_x &amp; 0 &amp; p_{c_x} \ 0 &amp; f_y &amp; p_{c_y} \ 0 &amp; 0 &amp; 1 \end{matrix} \right) $$ 那么物点与像点之间的关系为： $$ p={\frac {1}{Z_{C}}}KP_{cam}={\frac{1}{Z_{C}}}K[R;t]P $$ $$ p’={\frac {1}{Z_{C}}}KP’{cam}={\frac {1}{Z{C}}}K[R’;t’]P $$ 将 $P=[R;t]{+}P_{cam}=Z’_{C}K[R;t]{+}p$ 代入上式，并令 $H_{\pi }=K[R’;t’]K[R;t]^{+}$，得： $$ p’={\frac {Z’{C}}{Z{C}}}H_{\pi }p $$ 由于物点、像点、光心三点一线，那么物点、一对同名点和2个光心这5个点一定处于同一个平面上，我们将这个平面称为 $\pi$ 平面。 $\pi$ 平面和像平面的交线称为极线 $l’$。显然，左片上的每一个像点 $p$ 对应于右片上的一条极线 $l’$，且 $p’$ 一定在 $l’$ 上。两个相机光心的连线与右片像平面的交点称为极点，用 $e’$ 表示。 在右边像平面内，极线 $l’$ 的方程可以表示为 $Ax+By+C=0$。这个平面直线方程的一般式可以视为： $$ (A,B,C)^T \cdot (x,y,1)^T=0 $$ 因此，我们可以用一个三维向量 $(A,B,C)$ 来表示极线 $l’$，并且 $l’$ 的方程可以简单的由 $e’$ 坐标向量与 $p’$ 坐标向量做向量积得到，即 $l’:e’\times p’=[e’]{\times }p’$。其中 $$ [e’]{\times } = \left( \begin{matrix} 0 &amp; -1 &amp; y_0 \ 1 &amp; 0 &amp; -x_0 \ -y_0 &amp; x_0 &amp; 0 \end{matrix} \right) $$ 令 $[e’]x$ 表示向量积的矩阵形式，那么再将同名点之间的变换关系代入，得到极线的方程为： $$ l’:{\frac {Z’{C}}{Z{C}}}[e’]{\times }H{\pi }p $$ 因为 $p’$ 在 $l’$ 上，所以显然有： $$ p’l’=p’[e’]{\times }H{\pi }p=0 $$ 令$ \mathrm{F} =[e’]{\times} H{\pi}$，即得到： $$ {p’}^T\mathrm{F}p = 0 $$ ¶Reference 维基百科-基础矩阵]]></content>
      <categories>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning Explained - Algorithms Are Your Friend]]></title>
    <url>%2F2017%2F08-14-ML-PredictionAlgorithmsSummary%2F</url>
    <content type="text"><![CDATA[文章转载自Dataiku Inc。 We hear the term “machine learning” a lot these days, usually in the context of predictive analysis and artificial intelligence. Machine learning is, more or less, a way for computers to learn things without being specifically programmed. But how does that actually happen? The answer is, in one word, algorithms. Algorithms are sets of rules that a computer is able to follow. Think about how you learned to do long division – maybe you learned to take the denominator and divide it into the first digits of the numerator, then subtracting the subtotal and continuing with the next digits until you were left with a remainder. Well, that’s an algorithm, and it’s the sort of thing we can program into a computer, which can perform these sorts of calculations much, much faster than we can. We’ve put together a brief summary of the top algorithms used in predictive analysis, which you can see just below. Read on for more detail on these algorithms. ¶What Does Machine Learning Look Like? In machine learning, our goal is either prediction or clustering. Today, we’re going to focus on prediction (we’ll cover clustering in a future article). Prediction is a process where, from a set of input variables, we estimate the value of an output variable. For example, using a set of characteristics of a house, we can predict its sale price.Prediction problems are divided into two main categories: Regression problems, where the variable to predict is numerical (e.g., the price of a house) Classification problems, where the variable to predict is a “Yes/No” answer (for example, predict whether a certain piece of equipment will experience a mechanical failure) With that in mind, today we’re not going to reveal a secret to do prediction better than the computers, or even how to be a data scientist! What we are going to do is introduce the most prominent and common algorithms used in machine learning historically and today. Our algorithms come in three groups: linear models, tree-based models, and neural networks. ¶Linear Model Approach A linear model uses simple formulas to find the “best fit” line through a set of data points. This methodology dates back over 200 years, and it has been used widely throughout statistics and machine learning. It is useful for statistics because of its simplicity – the variable you want to predict (the dependent variable) is represented as an equation of variables you know (independent variables), and so prediction is just a matter of inputting the independent variables and having the equation spit out the answer. For example, you might want to know how long it will take to bake a cake, and your regression analysis might yield an equation t = 0.5x + 0.25y, where t is the baking time in hours, x is the weight of the cake batter in kg, and y is a variable which is 1 if it is chocolate and 0 if it is not. If you have 1 kg of chocolate cake batter (we love cake), then you plug your variables into our equation, and you get t = (0.5 x 1) + (0.25 x 1) = 0.75 hours, or 45 minutes. ¶Linear Regression Linear regression, or more specifically “least squares regression,” is the most standard form of linear model. For regression problems, linear regression is the most simple linear model. Its drawback is that there is a tendency for the model to “overfit” – that is, for the model to adapt too exactly to the data on which it has been trained at the expense of the ability to generalize to previously unseen data. For this reason, linear regression (along with logistic regression, which we’ll get to in a second) in machine learning is often “regularized,” which means the model has certain penalties to prevent overfit. Another drawback of linear models is that, since they’re so simple, they tend to have trouble predicting more complex behaviors when the input variables are not independent. ¶Logistic Regression Logistic regression is simply the adaptation of linear regression to classification problems (once again, discussed above). The drawbacks of logistic regression are the same as those of linear regression. Because of its shape, the logistic function is very good for classification problems, as it introduces a threshold effect. ¶Tree-Based Model Approach When you hear tree-based, think decision trees, i.e., a sequence of branching operations. ¶Decision Tree A decision tree is a graph that uses a branching method to show each possible outcome of a decision. Like if you’re ordering a salad, you first decide the type of lettuce, then the toppings, then the dressing. We can represent all possible outcomes in a decision tree. To train a decision tree, we take the train data set (that is, the data set that we use to train the model) and find which attribute best “splits” the train set with regards to the target. For example, in a fraud detection case, we could find that the attribute which best predicts the risk of fraud is the country. After this first split, we have two subsets which are the best at predicting if we only know that first attribute. Then we can iterate on the second-best attribute for each subset and resplit each subset, continuing until we have used enough of the attributes to satisfy our needs. ¶Random Forest A random forest is the average of many decision trees, each of which is trained with a random sample of the data. Each single tree in the forest is weaker than a full decision tree, but by putting them all together, we get better overall performance thanks to diversity. Random forest is a very popular algorithm in machine learning today. It is very easy to train, and it tends to perform quite well. Its downside is that it can be slow to output predictions relative to other algorithms, so you might not use it when you need lightning-fast predictions. ¶Gradient Boosting Gradient boosting, like random forest, is also made from “weak” decision trees. The big difference is that in gradient boosting, the trees are trained one after another. Each subsequent tree is trained primarily with data that had been wrongly identified by previous trees. This allows gradient boost to focus less on the easy-to-predict cases and more on difficult cases. Gradient boosting is also pretty fast to train and performs very well. However, small changes in the training data set can create radical changes in the model, so it may not produce the most explainable results. ¶Neural Networks Neural networks refer to a biological phenomenon comprised of interconnected neurons that exchange messages with each other. This idea has now been adapted to the world of machine learning and is called ANN (Artificial Neural Networks). Deep learning, which you’ve heard a lot about, is just several layers of neural networks put one after the other. ANNs are a family of models that are taught to adopt cognitive skills to function like the human brain. No other algorithms can handle extremely complex tasks, such as image recognition, as well as neural networks. However, just like the human brain, it takes a very long time to train the model, and it requires a lot of power (just think about how much we eat to keep our brains working!). We hope this has been helpful in shedding some light on machine learning. If you’re interested in learning more, you can read about the machine learning features within Dataiku DSS, or even check out a very cool application of machine learning to predict crime rates in London. Enjoy, and keep in touch! ¶Reference Dataiku Inc.]]></content>
      <categories>
        <category>repost</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning Algorithm Summary]]></title>
    <url>%2F2017%2F08-14-ML-AlgorithmsSummary%2F</url>
    <content type="text"><![CDATA[文章转载自think big data。 ¶Which are the best known machine learning algorithms? Infographic Which are the most important machine learning algorithms? Anyone who has been part of this domain must have faced or posed this question at some point of time. I too am asked this often. First things first – there are no winning algorithms. For different circumstances, different algorithms, even though they might be designed for similar outcome, result in differently oriented output. Depending upon what you want with your data analytics, an algorithm might be better suited to you than the others for that situation. Size of the data set also plays a key role in determining the model to apply. Also, iterations in existing algorithms, thereby increasing their relevance to myriad of applications, is also common. What is important to remember is that simpler algorithms aren’t bad or obsolete. So, my suggestion is instead of searching for the best algorithms, one should focus on gaining awareness about fundamentals of different algorithms and their applications. Most of us familiar with the subject would recall that in 2006, IEEE Conference on Data Mining identified the top 10 machine learning algorithms. That list is widely available over the internet, so we’ll not reproduce it here. What we’ll do instead is mention over a dozen algorithms, segregated by their application intent, that should be in the repertoire of every data scientist. For usefulness purposes, I am reproducing the list in an infographic format – that can easily go onto a wall! For suggestions and improvements – please add your comments below. ¶Reference think big data]]></content>
      <categories>
        <category>repost</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯角度看 L1 & L2 正则化]]></title>
    <url>%2F2017%2F08-13-ML-Regularization%2F</url>
    <content type="text"><![CDATA[¶贝叶斯角度看 L1 &amp; L2 正则化 从贝叶斯的角度来看，正则化等价于对模型参数引入先验分布。其中, L1正则化对应于拉普拉斯分布， L2正则化对应于高斯分布。 ¶频率学派 VS 贝叶斯学派 频率学派(Frequentists)与贝叶斯学派(Bayesians)都基于样本数据做分析。 其不同点主要在于对于 $X\sim F(x;\theta)$，概率学派将样本看作随机变量，而将 $\theta$ 看作常数，而贝叶斯学派将样本和 $\theta$ 均看作随机变量。 概率学派的着眼点在样本空间，基本依托于大数定律和中心极限定理，其贵在于得到越多越好的样本，然后计算其频率来逼近该事件的真实概率。 而贝叶斯学派的着眼点在参数空间，更加重视参数 $\theta$ 的分布，表现在对事件有一定的先验知识了解，然后再用似然度去修正之前的知识了解，如果当前的观测值越符合我们的先验知识，那么似然度就越大，得到的后验概率也就越大，反之亦然。 贝叶斯概率论假设观察者对某事件处于某个知识状态中（例如：有一个袋子里面装了红球和黑球，已知这个袋子里面是5黑5红的概率是0.8，是10黑5红的概率是0.2），之后观察者开始新的观测或实验（有放回抽取100次，得到80次黑的，20次红的）。经过中间的独立重复试验，观察者获得了一些新的观测结果，这些新的观测将以含有不确定性的逻辑推断的方式影响观察者原有的信念（即观测者一开始认为袋子里是5黑5红的可能性更大，但是经过了上面的事实之后，修正了原有的信念，认为是10黑5红可能性更大）。 上面的例子用贝叶斯概率论的语言来描述，就是观察者持有某个前置信念（prior belief），通过观测获得统计证据（evidence），通过满足一定条件的逻辑一致推断得出的关于该陈述的「合理性」，从而得出后置信念（posterior belief）来最好的表征观测后的知识状态（state of knowledge）。 看似贝叶斯框架比较的完美，而且可以克服一些频率派困难（比如投骰子次数不多，那么计算的频率显然与真实的分布想去甚远，但是贝叶斯的先验知识可以缓和这种极端情况）。但是贝叶斯的先验知识没有具体、规则化的获得方法，每个人的先验知识都可能是不一样的，而不良的先验概率甚至会使得最终的估计偏离真实的值。对此，贝叶斯的先验知识最好是客观计算出来的，抑或者拿不准时候用弱信息甚至无信息的先验假设来尽可能避免这类问题。 ¶Linear Regression 最原始的 Linear Regression 模型如下 这就导出了我们原始的 least-squares 损失函数，但这是在我们对参数 w 没有加入任何先验分布的情况下。在数据维度很高的情况下，我们的模型参数很多，模型复杂度高，容易发生过拟合。比如我们常说的 “small n, large p problem”。（我们一般用 n 表示数据点的个数，用 p 表示变量的个数 ，即数据维度。当 的时候，不做任何其他假设或者限制的话，学习问题基本上是没法进行的。因为如果用上所有变量的话， p 越大，通常会导致模型越复杂，但是反过来 n 又很小，于是就会出现很严重的 overfitting 问题。 这个时候，我们可以对参数 w 引入先验分布，降低模型复杂度。 ¶Ridge Regression 我们对参数 $w$ 引入协方差为 $\alpha$ 的零均值高斯先验。 看我们得到的参数，在零附近是不是很密集，老实说 ridge regression 并不具有产生稀疏解的能力，也就是说参数并不会真出现很多零。假设我们的预测结果与两个特征相关，L2正则倾向于综合两者的影响，给影响大的特征赋予高的权重；而L1正则倾向于选择影响较大的参数，而舍弃掉影响较小的那个。实际应用中 L2正则表现往往会优于 L1正则，但 L1正则会大大降低我们的计算量。 Typically ridge or $l2$ penalties are much better for minimizing prediction error rather than ℓ1 penalties. The reason for this is that when two predictors are highly correlated, ℓ1 regularizer will simply pick one of the two predictors. In contrast, the ℓ2 regularizer will keep both of them and jointly shrink the corresponding coefficients a little bit. Thus, while the ℓ1 penalty can certainly reduce overfitting, you may also experience a loss in predictive power. 那现在我们知道了，对参数引入 高斯先验 等价于L2正则化。 ¶LASSO ¶Elastic Net ¶总结 正则化参数等价于对参数引入 先验分布，使得 模型复杂度 变小（缩小解空间），对于噪声以及 outliers 的鲁棒性增强（泛化能力）。整个最优化问题从贝叶斯观点来看是一种贝叶斯最大后验估计，其中 正则化项 对应后验估计中的 先验信息，损失函数对应后验估计中的似然函数，两者的乘积即对应贝叶斯最大后验估计的形式。 ¶参考 知乎 Charles Xiao 知乎 bsdelf 统计学之边角料——频率派和贝叶斯派 贝叶斯角度看L1，L2正则化]]></content>
      <categories>
        <category>algorithm</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图像的变换]]></title>
    <url>%2F2017%2F08-13-CV-ImageTransformation%2F</url>
    <content type="text"><![CDATA[¶等距变换 等距变换 (Isometric Transformation) 保持欧氏距离不变。 等距变换就是对图像的旋转和平移。 变换矩阵 $$ H_E = \left( \begin{matrix} R &amp; t\ 0^T &amp; 1 \end{matrix} \right) =\left( \begin{matrix} \epsilon \cos \theta &amp; -\sin \theta &amp; t_x \ \epsilon \sin \theta &amp; \cos \theta &amp; t_y \ 0 &amp; 0 &amp; 1 \end{matrix} \right) $$ 其中 $R$ 是单位旋转矩阵，$t$ 是平移向量，$\epsilon=\pm1$, 当$\epsilon=1$时保向，变换由旋转和平移组成，当$\epsilon=-1$时逆向，变换还包含一个镜像。 不变量：长度，角度，面积 自由度：3个自由度（1个旋转角+2个平移），至少需要2组点共4个方程求解。 ¶相似变换 相似变换（Similarity Transformation）是在等距变换的基础上加上一个缩放。 等距变换就是对图像的旋转+平移+缩放。 变换矩阵 $$ H_S = \left( \begin{matrix} s\cdot R &amp; t\ 0^T &amp; 1 \end{matrix} \right) =\left( \begin{matrix} s \cos \theta &amp; -s\sin \theta &amp; t_x \ s \sin \theta &amp; s\cos \theta &amp; t_y \ 0 &amp; 0 &amp; 1 \end{matrix} \right) $$ 其中 $R$ 是单位旋转矩阵，$t$ 是平移向量, $s$ 是缩放因子。 不变量：角度，长度的比例，面积的比例，平行线关系 自由度：4个自由度（1个旋转角+2个平移+1个缩放尺度），至少需要2组点4个方程求解. ¶仿射变换 仿射变换（Affine Transformation） 仿射变换就是对图像的旋转+平移+缩放+切变（shear），相比前两种变换图像的形状发生了改变，但是原图中的平行线仍然保持平行。 变换矩阵 $$ H_A = \left( \begin{matrix} A &amp; t\ 0 &amp; 1 \end{matrix} \right) =\left( \begin{matrix} a_{11} &amp; a_{12} &amp; t_x \ a_{21} &amp; a_{22} &amp; t_y \ 0 &amp; 0 &amp; 1 \end{matrix} \right) $$ 其中 $A$ 是仿射矩阵，$t$ 是平移向量。 仿射变换的 $A$ 矩阵可以做SVD分解，即 $$ A = UDV^T = (UVT)(VDVT) = R(\theta)R(-\phi)DR(\phi), \quad D=diag(\lambda_1, \lambda_2) $$ 所以仿射变换 $A$ 可以看成先旋转 $\phi$，再沿着 $x, y$ 方向按照比例 $\lambda_1, \lambda_2$ 进行缩放，然后再旋转 $-\phi$，最后旋转 $\theta$。 不变量：平行线关系，平行线长度的比例，面积的比例 自由度：6个自由度（2个旋转角+2个平移+2个缩放因子），至少需要3组点6个方程求解. ¶投影变换 投影变换（Projective Transformation）又叫2D homographies，是把点从一个平面映射到另一个平面，如世界坐标系下的平面到相机的成像平面。 投影变换就是对图像的旋转+平移+缩放+切变+射影，相比前三种变换图像的形变更为自由，原图中的平行线经过变换之后已经不在平行，而可能相交于一点，射影变换就是把理想点（平行直线在无穷远处相交）变换到图像上。 变换矩阵 $$ H_P = \left( \begin{matrix} A &amp; t\ v^T &amp; c \end{matrix} \right) =\left( \begin{matrix} h_{11} &amp; h_{12} &amp; h_{13} \ h_{21} &amp; h_{22} &amp; h_{23} \ h_{31} &amp; h_{32} &amp; h_{33} \end{matrix} \right) $$ 其中 $A$ 是仿射矩阵，$t$ 是平移向量，$v=(v_1, v_2)^T$，$c$ 是一个常数。 不变量：长度的交比（比例的比例） 自由度：8个自由度（2个旋转角+2个平移+2个缩放因子+2个无穷远的线），至少需要4组点8个方程求解. 对于理想点 $(x_1,x_2,0)^T$ 的映射: $$ H_P = \left( \begin{matrix} A &amp; t\ v^T &amp; c \end{matrix} \right) \left( \begin{matrix} x_1 \ x_2 \ 0 \end{matrix} \right) =\left( \begin{matrix} A(x_1,x_2)^T \ v_1x_1+v_2x_2 \end{matrix} \right) $$ 所以对于仿射变换，$v=0$，所有的理想点仍然被映射到理想点，对于投影变换，$v\neq 0$，一些理想点被映射到无穷远处。 ¶参考 图像的等距变换，相似变换，仿射变换，射影变换及其matlab实现 Geometrical Image Analysis, Spring 08 2D projective transformations]]></content>
      <categories>
        <category>algorithm</category>
        <category>cv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MeshViewer框架搭建]]></title>
    <url>%2F2017%2F01-10-Qt-RedesignMeshviewerFrame%2F</url>
    <content type="text"><![CDATA[¶在 VS 中新建 Qt 项目 这个就不废话了。 ¶添加菜单栏 这个很简单，在 VS 中双击 mainwindow.ui，直接在 Qt Designer 中添加就行。 这里就添加一个 File 菜单，下面再添加两个 Action,分别为 Open 和 Save。其他的类似。 ¶添加工具栏 在右侧底部的“动作编辑器”中，选中一个 Action，拖放到窗口的工具栏上即可。 在“动作编辑器”中还能设置快捷方式。 在“资源浏览器”中，点击上面的铅笔标志，添加应用图标的资源文件。 在“动作编辑器”中双击 Action，如 Open，可以添加应用图标，进行其他一些设置。 ¶添加 Render Group Box 首先在 Qt Designer 中拖入几个 Check Box，将对象名作相应修改，如 Point，Edge, Face 等。 然后选中这三个 Check Box，右击，从“布局”中选中“垂直布局”。 再添加一个 Group Box，将对象名改为 Render，结果如下： 然后将 Render CheckBox 整个布局拖到 Group Box 中，使其成为 Group Box 的子对象。 你还可以在 Group Box 中添加其他一些 Widgets。这里添加了一个 PushBottom，对象名为 OK。 此时右侧的对象查看器中的结果是这样的，注意其中的对象包含关系。 最后还要做一个设置，选中 Group Box，右击，从“大小限定”中点击“设置最小宽度”和“设置最小高度”。 然后在 MainWindow 的构造函数中添加一些代码，具体如下。 12345678910111213141516MainWindow::MainWindow(QWidget *parent) : QMainWindow(parent)&#123; ui.setupUi(this); renderingwidget_ = new RenderingWidget(this); QVBoxLayout *layout_left = new QVBoxLayout; layout_left-&gt;addWidget(ui.groupBox_render); layout_left-&gt;addStretch(4); QHBoxLayout *layout_main = new QHBoxLayout; layout_main-&gt;addLayout(layout_left); layout_main-&gt;addWidget(renderingwidget_); layout_main-&gt;setStretch(1, 1); this-&gt;centralWidget()-&gt;setLayout(layout_main);&#125; ¶预览效果 这是目前的预览效果。]]></content>
      <categories>
        <category>coding</category>
        <category>qt</category>
      </categories>
      <tags>
        <tag>qt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Working with Laptop and Desktop via GitHub]]></title>
    <url>%2F2017%2F01-06-Git-WorkWithLaptopAndDesktop%2F</url>
    <content type="text"><![CDATA[¶新建本地和远程仓库 ¶初始化本地仓库 在本地代码所在的文件夹中初始化，即打开powershell，输入下面命令 1git init 此时本地文件夹中会出现一个.git的隐藏文件夹。 ¶新建远程仓库 然后登陆自己的GitHub账户，在右上角点击+号新建一个新的仓库。 ¶推送本地到远端 ¶提交更改 然后将当前的文档commit，在本地commit之前可以先加一个.gitignore文件，忽略一些不必要的文件，如VS的编译文件等等，从其他仓库拷贝一个放在里面就行（需要添加过滤）。然后执行命令 123git statusgit add *git commit -m &quot;first commit&quot; ¶推送本地代码到远程仓库 回到本地，再powershell中键入 12git remote add origin https://github.com/VVingerfly/k-means-plusplus.gitgit push -u origin master ¶同步远端代码到本地 在远程仓库拉取更新到本地 1git pull origin master ¶参考 gitignore参考（Ignore Visual Studio temporary files）]]></content>
      <categories>
        <category>tools</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Simple Tutorial]]></title>
    <url>%2F2017%2F01-05-Git-SimpleTutorial%2F</url>
    <content type="text"><![CDATA[转载自https://try.github.io。 Initializing 1git init To initialize a Git repository locally, and local directory now has an empty repository in /.git/. The repository is a hidden directory where Git operates. Checking the Status 1git status To see what the current state of our project Adding Changes 1git add filename To add filename to the staging area Adding All Changes 1git add &apos;*.txt&apos; To add all the new files using a wildcard with git add. Committing 1git commit -m &quot;Add cute octocat story&quot; The files in the Staging Area are not in our repository yet. We could add or remove files from the stage before we store them in the repository. To store staged changes, run the commit command with a message describing what we’ve changed. Committing All Changes 1git commit -m &apos;Add all the txt files&apos; History 1git log To browse all the commits to see what we changed. Git’s log remembers all the changes we’ve committed so far, in the order we committed them. Remote Repositories 1git remote add origin https://github.com/try-git/try_git.git To push our local repo to the GitHub server. We need first to create a new empty GitHub repository and then add a remote repository. This command takes a remote name and a repository URL, which in your case is https://github.com/try-git/try_git.git. Pushing Remotely 1git push -u origin master To push our local changes to our origin repo (on GitHub). The push command tells Git where to put our commits when we’re ready. The name of our remote is origin and the default local branch name is master. The -u tells Git to remember the parameters, so that next time we can simply run git push and Git will know what to do. Pulling Remotely 1git pull origin master To pull down any new changes on our GitHub repository. Differences 1git diff HEAD To take a look at what is different from our last commit by using the git diff command. In this case we want the diff of our most recent commit, which we can refer to using the HEAD pointer. Staged Differences 1git add filename To look at changes within files that have already been staged. Remember, staged files are files we have told git that are ready to be committed. Staged Differences (cont’d) 1git diff --staged To see the changes you just staged, run git diff with the –staged option. Resetting the Stage 1git reset filename To remove(unstage) a file, use the git reset command. Notice that the file is still there. It’s just not staged anymore. Undo 1git checkout -- filename To change things back to how they were at the last commit by using the command: git checkout – . Branching Out 1git branch clean_up To create a branch called clean_up. When developers are working on a feature or bug they’ll often create a copy (aka. branch) of their code they can make separate commits to. Then when they’re done they can merge this branch back into their main master branch. Switching Branches 1git checkout clean_up To switch branches using the git checkout command. Now if you type git branch you’ll see two local branches: a main branch named master and your new branch named clean_up. Removing All The Things 1git rm &apos;*.txt&apos; To remove all the txt file in the clean_up branch, use the git rm command which will not only remove the actual files from disk, but will also stage the removal of the files for us. Commiting Branch Changes 1git commit -m &quot;Remove all the txt file&quot; To commit changes. Switching Back to master 1git checkout master Preparing to Merge 1git merge clean_up To merge your changes from the clean_up branch into the master branch. Keeping Things Clean 1git branch -d clean_up To delete a branch, use git branch -d command. The Final Push 1git push To push everything you’ve been working on to your remote repository.]]></content>
      <categories>
        <category>tools</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
